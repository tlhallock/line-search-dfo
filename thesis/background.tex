% Within this chapter, we discuss background material relevant to our algorithm.
% This begins with a brief review of the literature within \cref{literature_review}.
% We then discuss our criticality measure $\xi$ and model accuracy $\rho$ within \cref{criticality_measure_section} and \cref{rhosection}.
% The next sections \cref{interpolation}, \cref{geometry}, and \cref{model_improvement_algorithms} are devoted to developing background material for interpolation based methods.
% Finally, in \cref{trust_regions_section} we end with a discussion of trust regions, which we place in the context of our algorithm.



\section{Literature Review}

\label{literature_review}


% Recently, there has been a growth in applications of derivative-free optimization.
% Such applications include

% Model based, trust region, I think no constraints, maybe multi-objective:
% photo-injector optimization \cite{Neveu2017}.

% Direct search, binary constraints, mixed integer (nomad, midaco, glcSolve, CMAES (stochastic))
% circuitry arrangements \cite{PLOSKAS201816},

% For paralellizable methods, kalman filter methods, optimizing networks
% machine learning \cite{KS2018}

% Trust region based, reliability surrogate constraints
% and reliability based optimization \cite{Gao2017}.

% parallel algorim, compares gradient based and dfo, nelder-mead
% volume optimization \cite{Cheng2017},

Several books and survey articles  provide good introductions to the field of derivative-free optimization.
Within \cite{introduction_book}, derivative-free methods are developed in detail.
This is the first textbook devoted to derivative-free optimization.
It contains an explanation of how to ensure good sample set geometry and introduces the concept of 
poisedness for unconstrained problems, and it also covers other direct-search and line-search methods.   A review of derivative-free algorithms and software libraries can be found in \cite{miguel_review}.
This compares several software libraries and reviews the development of derivative-free optimization since it started.
Other recent reviews can be found in \cite{custodio_review2} and \cite{larson_menickelly_wild_2019}.

Most  algorithms for derivative-free optimization fall into two main categories: direct-search methods and model-based methods.   Direct-search methods use comparatively simple strategies to explore the solution space, using only the relative ranks of function values rather than their numerical values.     Early direct search methods for unconstrained optimization include coordinate descent \cite{fermi.metropolis:numerical},  the Nelder-Mead algorithm \cite{10.1093/comjnl/7.4.308},  
and pattern search methods \cite {hooke.jeeves:direct, kolda.lewis.ea:optimization}.   Generalizations of pattern-search methods include the GPS method \cite{torczon:convergence, Audet2002AnalysisOG} and the mesh adaptive direct search (MADS) algorithm \cite{audet.dennis:mesh, abramson.audet:convergence}.

Model-based methods guide the search using surrogate models of the black-box functions, which are constructed by fitting function values on a set of sample points.    Among the more commonly used model functions are linear and quadratic interpolation models \cite{ conn.scheinberg.ea:recent, powell:uobyqa,powell:newuoa}  and radial-basis function interpolation models \cite{oeuvray.bierlaire:boosters,wild.regis.ea:orbit,wild.shoemaker:global}.

The use of model functions allows curvature information to be incorporated into the search.  As such, model-based methods tend to be more efficient than direct-search methods when the black box functions are smooth.  In contrast, direct-search methods can be better suited for handling nonsmooth or noisy functions.   They are also more straightforward to implement, and are easier to parallelize.

Hybrid methods, which incorporate ideas from both direct-search and model-based methods, have also been proposed.    Some examples are described in \cite{booker.dennis.ea:rigorous}, \cite{thi.vaz.ea:optimizing}, and \cite{custodio.vicente:using}.

\paragraph*{Constrained derivative-free algorithms.}
To discuss methods for constrained derivative-free optimization,  we follow the constraint taxonomy      
of Le~Digabel and Wild \cite{ledigabel2015taxonomy} and distinguish between whether constraints are {\em relaxable} or {\em unrelaxable}.    An unrelaxable constraint is one that {\em must} be satisfied in order to obtain meaningful information about the objective function and/or constraint functions.    Thus algorithms for unrelaxable constraints can use function evaluations only for feasible points.   We also distinguish between whether constraints are {\em algebraic} or {\em black-box}.    A constraint is algebraic if the constraint functions can be computed algebraically,  whereas a {\em black-box constraint} can only be evaluated by running simulation software.    

\paragraph*{Relaxable constraints.}   The easiest class of constraints to deal with are the relaxable algebraic constraints.   In this case, ideas from classical nonlinear programming methods can easily be adapted to the derivative-free setting.  Some examples include 
 penalty methods \cite{lewis.torczon:globally, lewis.torczon:direct, bueno.friedlander.ea:inexact},   and filter methods \cite{brekelmans.driessen.ea:constrained, ferreira.karas.ea:global}.     
Both penalty methods and filter methods allow iterates to violate constraints, requiring feasibility only in the limit.  As such, they are viable approaches only when the constraints are relaxable.    
 
For relaxable black-box constraints,  several methods have been proposed that allow the black-box functions to be evaluated at infeasible points.  These include penalty methods
\cite{audet.dennis:progressive, liuzzi.lucidi:derivative-free, liuzzi.lucidi.ea:sequential,fasano.liuzzi.ea:linesearch,diniz-ehrhardt.martinez.ea:derivative-free,picheny2016bayesian}, filter methods \cite{audet.dennis:pattern, pourmohamad:combining,echebest.schuverdt.ea:inexact},  and funnel methods \cite{sampaio.toint:derivative-free,sampaio.toint:numerical}.

Another approach is to construct algebraic models of the constraint functions and then require iterates to be feasible with respect to these modelled constraints.
In \cite{glass.cooper:sequential},  linear models of nearly active constraint functions are constructed and the iterates are accepted only if they are feasible with respect to these modeled constraints.     A similar strategy is employed in the COBYLA method of Powell \cite{powell:direct}, which builds linear models of the objective and constraint functions based on a common set of sample points.    
A variant of the MADS algorithm is proposed in \cite{burmen.olensek.ea:mesh} which uses linear regression models of the constraint functions to guide the choice of search and poll steps.   In \cite{Troltzsch2016},  the classic sequential quadratic programming algorithm is implemented for equality-based constraints.




%Also, \cite{Gao2018} presents  an algorithm for linearly constrained derivative-free optimization that uses a backtracking technique to minimize the number of evaluations required.



\paragraph*{Unrelaxable algebraic constraints.}  

 An algebraic constraint function can always be evaluated, so the only way it is considered unrelaxable is if a black-box function (either the objective or some other constraint function) cannot be evaluated when the constraint is violated.
Note that it is always possible to determine whether a point satisfies an algebraic constraint prior to attempting to evaluate any black-box functions.  As such, it is relatively straightforward to modify direct-search methods to guarantee that only feasible points are considered.     
Many direct-search methods have been proposed that take this approach
\cite{box:new, spendley.hext.ea:sequential,may:linearly,may:solving,lewis.torczon:globally,lewis.torczon:direct,
vandenberghen:condor, lewis.torczon:pattern2000,lucidi.sciandrone:derivative-free,chandramouli.narayanan:scaled,kolda.lewis.ea:stationarity,lucidi.sciandrone.ea:objective, 
audet.ledigabel.ea:linear,gratton.royer.ea:direct2019,gratton.royer.ea:direct2015}
%
% \cite{box:new} \cite{spendley.hext.ea:sequential}, \cite{may:linearly}, \cite{may:solving},\cite{lewis.torczon:globally},  \cite{lewis.torczon:direct}, \cite{vandenberghen:condor}, \cite{lewis.torczon:pattern2000} \cite{lucidi.sciandrone:derivative-free}, \cite{chandramouli.narayanan:scaled},  \cite{kolda.lewis.ea:stationarity}, \cite{lucidi.sciandrone.ea:objective}, 
%\cite{audet.ledigabel.ea:linear},\cite{gratton.royer.ea:direct2019}, \cite{gratton.royer.ea:direct2015}
  
Developing model-based algorithms for unrelaxable constraints is complicated by the fact that the choice of sample points impacts the accuracy of the model functions.     Thus, when restrictions on the choice of sample points are imposed,  it can be difficult to ensure that the model functions are sufficiently accurate to guarantee convergence to a stationary point.    (see \cref{sec:polyhedral} for a more detailed explanation of this difficulty).   In the case of unrelaxable bound constraints, the restrictions on the sample points are not too difficult to mitigate.     The BOBYQA algorithm \cite{powell:BOBYQA} ensures that all points at which the objective function are evaluated satisfy the bound constraints, while still maintaining sufficient model accuracy to guarantee convergence.    In \cite{arouxet.echebest.ea:active-set},  an active set method is used when solving the bound-constrained trust-region subproblems.    In \cite{wild:derivative-free}, Wild proposed a radial basis function method for bound constraints, which enforces the bounds when selecting sample points in the model improvement algorithm and when solving the trust region subproblems.   In \cite{gratton.toint.ea:active-set}, Gratton et al. present a method which restricts the construction of the model functions to subspaces defined by nearly active bound constraints.

There has also been some progress in developing model-based methods for unrelaxable linear constraints.   In  \cite{gumma.hashim.ea:derivative-free},  Gumma et al.  propose the LCOBYQA algorithm which is an extension of Powell's NEWUOA algorithm that enforces the linear constraints both when solving the trust region subproblems and when choosing sample points for constructing the model functions.    However, no convergence analysis is provided for the method.   

\paragraph*{Unrelaxable black-box constraints.}   
We now turn our attention to the hardest case--that of unrelaxable black-box constraints.   In this case,  it is not possible to guarantee that black-box function evaluations will never be attempted at infeasible points.   However, it is desireable to minimize the occurrence of such infeasible attempts.  

There are several strategies for avoiding infeasible evaluations.
The authors of \cite{Galvan2021} use a reformulation strategy by moving the constraints into the objective.
Their work relies on a projection operator to avoid infeasible evaluations and handles non-smooth convex constraints.
The authors of \cite{NOWPAC2014} use a path-augmentation strategy to ensure trial points are feasible.
This is done with a local convexification of the constraints that parameterize a buffer of the constraints.
The authors of \cite{BMNORW2020} apply DFO to optimize the Fayans energy density functional, avoiding possible infeasible evaluations by altering the objective function to include a projection onto an $L_1$ ball.
In \cite{CONORBIT15}, the authors develop a model-based trust region algorithm that uses an envelope to avoid infeasible trial point evaluations.
The algorithm presented within \cite{Conejo2015} is also a model-based trust region method, and it ensures each iterate is feasible, although sample points may not be.
More recently, \cite{Brilli2021interior} uses an interior point algorithm to solve derivative-free problems with unrelaxable, black-box constraints.

Of particular importance for our work is \cite{Conejo:2013:GCT:2620806.2621814}.
This reference provides an elegant convergence proof for a class of algorithms when the constraints are convex.
Our analysis implements abstractions made in this paper and shows the implementation satisfies their requirements.

%We are not aware of any algorithms that use only feasible points to build models of the black-box constraint functions.   However,  a number of algorithms simultaneously handle unrelaxable algebraic constraints and relaxable black-box constraints.  Thus,  \cite{regis:constrained,augustin.marzouk:nowpac,augustin.marzouk:trust-region,regis.ea:conorbit}.



%While care is taken to maintain the non-degeneracy of the sample points,  Powell notes that  ``Our %knowledge of the convergence properties for the algorithm is slight.'' 





\section{Model-Based Trust-Region Methods for DFO}

The main idea of model-based, trust-region methods is that trial points are selected at each iteration by solving a trust-region subproblem.  
Each subproblem has the form 
\[ \begin{array}{ll} \min_{s \in \Rn} & m_f^{(k)}\left(\xk + s\right) \\ 
\st & \xk+s \in \feasiblek \\
& \norm{s} \le \Delta_k
\end{array} \]
where $m_f^{(k)}$ is a model function approximating the objective $f$, $\dk$ is the trust region radius,
and $\feasiblek$ is an approximation of the feasible region.
The solution $\sk$ of the trust-region subproblem determines a {\em trial point} $\xk + \sk$.  
The objective function and constraints are then evaluated at the trial point to determine whether to accept the trial point.
If the trial point is rejected, the trust region radius is decreased and a new trial point is computed by solving a revised trust-region subproblem.     
If the trial point is accepted, then the trust region radius may be increased or decreased for the next iteration 
depending on how well the sample point improved upon the previous iterate.
This will be discussed in \cref{rhosection}.


\section{Assessing Model Accuracy and Trust Region Radius Management}

\label{rhosection}

% We now discuss background material for components of our algorithm.
In trust region methods, each iteration that evaluates a trial point must also test the accuracy of the model functions.
To test the accuracy, we calculate a quantity
\begin{align}
\label{define_rhok}
\rk = \frac{f(\xk) - f(\xk+\sk)}{\mfk(\xk) - \mfk(\xk+\sk)},
\end{align}
which measures the actual improvement of the trial point $\xk+\sk$ divided by the predicted improvement.  If $\rk$ is negative, the trial point is rejected and the trust region radius is decreased.   On the other hand, if the trial point is accepted, the trust region radius for the next iteration may still be decreased since 
a small value of $\rk$ implies that the model functions are not sufficiently accurate.   For larger values of $\rk$ the trial point is accepted and the trust region radius may be increased.
This strategy has been widely used within trust region frameworks such as \cite{Conn:2000:TM:357813} and within a derivative-free context \cite{introduction_book}.

To implement the above strategy,  we define parameters
% \label{define_the_gammas}
% \label{define_the_omegas}
$
0 < \gammasm < \gammabi \le 1
$
as thresholds on $\rk$ and
$
0 < \omegadec < 1 \le \omegainc
$
% $\omegadec, \omegainc$
as decrement and increment factors to determine the trust region update policy.
That is, when $\rk < \gammasm$, the trust region is decreased by a factor of $\omegadec$, and the trust region is increased by a factor of $\omegainc$
during some iterations in which $\rk > \gammabi$.


\section{Interpolation-Based Models}

\label{interpolation}

Model-based methods for derivative-free optimization construct models of a function $f(x)$ from a family of functions spanned by a set of $p + 1 \in \naturals$ basis functions  $\Phi = \{\phi_0, \phi_1, \ldots, \phi_p\}$. Each member of this family has the form $\mf(x) = \sum_{i=0}^p\alpha_i\phi_i(x)$ for some scalar coefficients $\alpha_i, i \in \{0, \ldots, p\}$.

We use interpolation to choose the coefficients $\alpha = [\alpha_0, \ldots, \alpha_p]^T$ so that $\mfk$ agrees with $f$ on a set of $p+1$ sample points $Y = \{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\}$ at which the function $f$ has been evaluated.
Thus, the coefficients $\alpha$ must satisfy the \emph{interpolation condition}
\begin{align}
\label{interpolation_condition}
\mf(y^{(i)}) = \sum^p_{j=0}\alpha_j\phi_j(y^{(i)}) = f(y^{(i)}) \quad \forall \quad 0 \le i \le p.
\end{align}

% We can also write this equation in matrix form.
This equation can be written more compactly in the form
\begin{align}
\label{matrix_form}
V \alpha = \bar{f},
\end{align}
where $\bar{f} = [f(y^{(0)}), f(y^{(1)}), \ldots, f(y^{(p)})]^T$ and the Vandermonde matrix $V$ is defined by 

\begin{align}
\label{vandermonde}
V=M(\Phi,Y) :=
\begin{bmatrix}
    \phi_0(y^{(0)})      & \phi_1(y^{(0)})       & \ldots & \phi_{p}(y^{(0)})      \\
    \phi_0(y^{(1)})      & \phi_1(y^{(1)})       & \dots  & \phi_{p}(y^{(1)})      \\
                     &                   & \vdots &                    \\
    \phi_0(y^{(p)})    & \phi_1(y^{(p)})     & \ldots & \phi_{p}(y^{{(p)}})
\end{bmatrix}.
\end{align}


The interpolation equation \cref{matrix_form} has a unique solution if and only if $V$ is nonsingular.
In this case, we say that the sample set $Y$ is \emph{poised} for interpolation with respect to $\Phi$. 
However, even when $V$ is non-singular but ``close" to singular, as measured by its condition number, 
the model's approximation may become inaccurate.


\section{Sample Set Geometry}

\label{geometry}
The term \emph{geometry} describes how the distribution of points in the sample set $Y$ affects the model's accuracy.

In the case of polynomial model functions, a rigorous analysis of model accuracy can be performed using \emph{Lagrange polynomials}.
Let the space of polynomials on $\Rn$ with degree less than or equal to $d$ be denoted $\polydn$ and have dimension $p+1$.
The Lagrange polynomials $l_0, l_1, \ldots, l_p$ for the sample set $Y$ are a basis of $\polydn$ such that
\begin{align}
l_i(y^{(j)}) = \delta_{i,j}
\end{align}
where $\delta_{i,j} = \{0 \;\text{if}\; i\ne j,\; 1 \;\text{if} \; i = j \}$ is the Kronecker-delta function.
%For example, after this change of basis, note that the Vandermonde matrix becomes the identity matrix.
Thus, as shown in \cite{introduction_book}, we can conveniently write
\begin{align}
\label{reg}
\mf(x) = \sum^p_{j=0}f(y^{(i)})l_i(x).
\end{align}


We say that a set $Y$ is \emph{$\Lambda$-poised} for a fixed constant $\Lambda$ with respect to a basis $\Phi$ on the set 
$B \subset\Rn$ if and only if the Lagrange polynomials $l_i$ associated with $Y$ satisfy
\begin{align}
\Lambda \ge \max_{0\le i\le p}\max_{x\in B}|l_i(x)|.
\end{align}
% \color{red}
% Frequently, the basis $\Phi$ is taken to be the monomial basis of order $d \in \naturals$:
% \begin{align*}
% \phi_0(x) = 1, 
% \phi_1(x) = x_1,
% \phi_2(x) = x_2, 
% \ldots, 
% \phi_{n}(x) = x_n, \\
% \phi_{1+n}(x) = x_1^2,
% \phi_{2+n}(x) = x_1x_2, 
% \phi_{3+n}(x) = x_1x_3, 
% \ldots, 
% \phi_{\frac{(n+1)(n+1)}{2}}(x) = x_n^2, \\
% \phi_{\frac{(n+1)(n+2)}{2} + 1}(x) = x_1^3, 
% \ldots, 
% \phi_{p}(x) = x_n^d
% \end{align*}
% For example, with $n=2$, and $d=2$ we have $p+1=6$ and
% \begin{align*}
% \phi_0(x) = 1,
% \phi_1(x) = x_1,
% \phi_2(x) = x_2,
% \phi_3(x) = x_1^2,
% \phi_4(x) = x_1x_2,
% \phi_5(x) = x_2^2.
% \end{align*}
% \color{black}
In the case of interpolation over the quadratic polynomials, 
$ \mathcal{P}^2_n$, we say that $Y$ is \emph{$\Lambda$-poised for quadratic interpolation}.

The concept of $\Lambda$-poisedness yields the following error bounds, as shown in 
 \cite[Theorem 3.16]{introduction_book}:

\begin{theorem}
\label{quadratic_errors}

Let $Y = \{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\} \subset \Rn$ be a set of $p+1=\frac{(n+1)(n+2)}{2}$ 
sample points and $\Delta = \max_{1 \le j \le p} \|y^{(j)}-y^{(0)}\|$.
Suppose that $Y$ is $\Lambda$-poised for quadratic interpolation on $B_2(y^{(0)}; \Delta)$.
Then, for any constant $L > 0$, there exist constants $\kappa_{h}, \kappa_{g}$, and $\kappa_{f}$ 
such that the following error bounds hold for any function $f:\Rn \rightarrow \reals$ 
that is $LC^2$ with Lipschitz constant $L$ on an open set containing $B_2(y^{(0)};\Delta)$:

\begin{align}
\|\nabla^2 f(y) - \nabla^2 m_f(y)\| \le \kappa_{h} \Delta \quad \forall y \in B_2(y^{(0)}; \Delta), \label{error_in_hessian}\\
\|\nabla f(y) - \nabla m_f(y)\| \le \kappa_{g} \Delta^2 \quad \forall y \in B_2(y^{(0)}; \Delta), \label{error_in_gradient} \\
|f(y) - m_f(y) | \le \kappa_{f} \Delta^3 \quad \forall y \in B_2(y^{(0)}; \Delta), \label{error_in_function} 
\end{align}
where $m_f$ is the quadratic model function interpolating $f$ on $Y$.
\end{theorem}

There is a close connection between the $\Lambda$-poisedness of $Y$ and the condition number of the Vandermonde matrix 
associated with the monomial basis for $\mathcal{P}^2_n$
\begin{align}
\label{define_monomial}
\bar{\Phi} = \{ \bar{\phi}_0, \ldots, \bar{\phi}_p\} =\{1, x_1, \ldots, x_n, x_1^2/2, \ldots x_n^2/2,x_1 x_2, \ldots, x_{n-1}x_{n}\}.
\end{align}
In particular, let $\hat{Y}$ be the shifted and scaled sample set $\left\{\frac{y^{(i)}-y^{(0)}}{\Delta}|y^{(i)} \in Y\right\}$.
Then we have the following result:
% \sbnote{I reworded the theorem to incorporate the assumptions since you never refer to the assumption anywhere else in the thesis.}

\begin{theorem}
\label{Lambda_poised_error_bounds}

(\cite[Theorem 3.14]{introduction_book}) Let $\hat{M} = M(\bar{\Phi},\hat{Y})$.  
If $\hat{M}$ is  non-singular and $\norm{\hat{M}^{-1}} \le \Lambda$,   
then the set $\hat{Y}$ is $\Lambda  \sqrt{p+1}$-poised in the unit ball $B_2(0;1)$.  
Conversely, if the set $\hat{Y}$ is $\Lambda$-poised for quadratic interpolation on the unit ball, 
then $\norm{\hat{M}^{-1}} \le \theta \Lambda \sqrt{p+1}$, where $\theta > 0$ is a 
constant dependent on $n$ but independent of $\hat{Y}$ and $\Lambda$.
\end{theorem}

A limitation of \cref{Lambda_poised_error_bounds} is that it assumes $\hat{Y}$ is contained in the unit ball $B_2(0;1)$.
The following theorem does not make this assumption.

\begin{theorem}
\label{Lambda_poised_error_bounds_delta}

Let $\Delta >0$, $Y$ be a sample set with $Y \subset B_2(0;\Delta)$ and let $M=M(\bar{\Phi},Y)$ where $\bar{\Phi}$ is the monomial basis \cref{define_monomial}.
If $M$ is nonsingular, and $\norm{M^{-1}} \le \Lambda$, then $Y$ is $\hat{\Lambda}$-poised in $B_2(0;\Delta)$,
where $\hat{\Lambda} = \Lambda \sqrt{p+1}\max\{1, \frac 1 2 \Delta^2\}$.
\end{theorem}

\begin{proof}

Let $x \in B_2(0;\Delta)$ be arbitrary and let $\ell(x) = (\ell_0(x), \ldots, \ell_p(x))^T$.
As shown in \cite{introduction_book}, we can write $\ell(x) = M^{-T}\bar{\phi}(x)$, 
where $\bar{\phi}(x) = (\bar{\phi}_0(x), \ldots, \bar{\phi}_p(x))$.
Thus,
\begin{align*}
\norm{\ell(x)}_{\infty} & \le \norm{M^{-T}}_{\infty} \norm{\bar{\phi(x)}}_{\infty} \\
& \le \sqrt{p+1} \norm{M^{-1}}_2 \norm{\bar{\phi}(x)}_{\infty} \\
& \le \Lambda \sqrt{p+1} \max\left\{1, |x_1|, \ldots,|x_n|, \frac 1 2 x_1^2, \ldots, \frac 1 2 x_n^2, x_1x_2, \ldots, x_{n-1}x_n\right\}\\
& \le \Lambda \sqrt{p+1}  \max\left\{1, \frac 1 2 \Delta^2\right\} = \hat{\Lambda}.
\end{align*}

\end{proof}


\section{Model Improvement Algorithms}

\label{model_improvement_algorithms}
Efficient implementations of model-based methods re-use sample points from previous iterations that fall within (or at least near) the current trust region.
New points are then added to the sample set using a model improvement algorithm as described in 
\cite{introduction_book} and stated here within \cref{model_improving_algorithm}.

The model improvement algorithm starts with a set of $p+1$ sample points that have been shifted and scaled so that they lie within a ball $B_2(0;\Delta)$, with $\Delta \ge 1$.   
The algorithm then uses LU factorization with partial pivoting of the 
associated Vandermonde matrix to construct a set of pivot polynomials $\{u_0, \ldots, u_p\}$ that are closely related to the Lagrange polynomials. 


Each iteration of the algorithm identifies a point to include in the final sample set.
In particular, on the $i$th iteration, the points $y^{(0)}, \ldots, y^{(i-1)}$ have already been included.   
If a point $y^{(j)}$,  $j \ge i$ from the original set can be found such that 
$u_i(y^{(j)})$ has a sufficiently large magnitude  (i.e.,  $|u_i(y^{(j)})| \ge \xi_{\min}$),  
then that point is added to the final sample set (by swapping it with $y^{(i)}$).
However, if no such point can be found, 
it indicates that including any of the remaining points in the final sample set would result in a poorly poised set.
Therefore, the point $y^{(i)}$ is replaced by a new point that is obtained by maximizing $|u_i(x)|$ 
over the unit ball $B_2(0;1)$.
The pivot polynomials are then updated so that 
$u_j(y^{(i})) = 0$ for $j > i$.
At the successful completion of the algorithm, the final set of points $Y$ is $\Lambda$-poised over $B_2(0;\Delta)$,
where $\Lambda$ depends on $\Delta$,  $n$ and $\xi_{\min}$,  and is inversely proportional to $\xi_{\min}$
(see \cref{set_is_poised} below).

\paragraph*{Note.}
Typically,  we have fewer than $p+1$ previously evaluated sample points within the trust region at the beginning of each iteration.
Since the Model Improvement Algorithm requires a starting set of $p+1$ points, 
we add copies of $y^{(0)}$ to create a set with $p+1$ points.

{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.25in]
\begin{flushleft}

\begin{algorithm}[H]
    \caption{Model Improvement Algorithm \label{alg:model_improvement} }
    \label{model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Given $\ximin \in (0,1/4]$, $\Delta \ge 1$, a set $Y = \left\{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\right\} \subset B_2(0;\Delta)$ of $p+1$ points,
            initialize $i=0$, and let $u_i(x)= \bar \phi_i(x)$ be the monomial basis for $\polydn$.
		\item[\textbf{Step 1}] \textbf{(Pivot)} \\
			If $i = 0$, go to Step 3. \\
			Compute the next pivot index $j^{\textrm{max}}_i = \argmax_{i \le j \le |Y|-1} \left|u_i\left(y^{(j)}\right)\right|$,
			and swap points $y^{(i)}$ and $y^{(j^{\textrm{max}}_i)}$ within $Y$.
			
        \item[\textbf{Step 2}] \textbf{(Check threshold)} \\
                If $\left|u_i\left(y^{(i)}\right)\right| \ge \ximin$ then go to Step 3. \\
                If $\left|u_i\left(y^{(i)}\right)\right| < \ximin$, then replace $y^{(i)} \gets \argmax_{x \in B_2\left(0; 1 \right)}\left|u_i(x)\right|$. \\
				If $\left|u_i\left(y^{(i)}\right)\right| < \ximin$ after this replacement,  \textbf{Stop}: $\ximin$ was chosen too small.
        \item[\textbf{Step 3}] \textbf{(Gaussian elimination)} \\
        	For $j = i+1, \ldots, p$ \\
        	\hspace{2em} Set $u_j(x) \gets u_j(x) - \frac{u_j\left(y^{(i)}\right)}{u_i\left(y^{(i)}\right)} u_i(x)$ \\
%         \begin{itemize}
%                 \item[] Set $V_i \gets \frac{1}{V_{i,i}} V_i$
%                 \item[] Set $V_{\bullet j} \gets V_{\bullet j} - \frac{V_{i,j}}{V_{i, i}} V_{\bullet j} \forall j=i \ldots p$
%             \end{itemize}
            If $i = p$ then \textbf{Stop}, otherwise.  Set $i \gets i+1$ and go to Step 1
    \end{itemize}
\end{algorithm}

\end{flushleft}
\end{fullwidth}
}

%In \cref{satisfying_accuracy} show how to construct a $\Lambda$-poised set over an ellipsoidal region.

%At the successful completion of the algorithm,  the matrix
%\[U = \left[ \begin{array}{cccc}
%u_0(y^{(0)}) & u_0(y^{(1)}) & \cdots & u_0(y^{(p)}) \\
%u_1(y^{(0)}) & u_1(y^{(1)}) & \cdots & u_1(y^{(p)}) \\
%&& \vdots & \\
%u_p(y^{(0)}) & u_0(y^{(1)}) & \cdots & u_p(y^{(p)}) 
%\end{array}\right\]
%is the upper triangular portion of the $LU$ factorization of the Vandermonde matrix $M =M(\bar{\Phi},Y)$ corresponding to the sample set $Y$ generated by the algorithm.     The following results establishes that $M$ has a bounded condition number:
%
%
%
%
%Since all of the diagonal entries of this matrix have magnitude greater than or equal to $\xi_{\min}$,  we
%we obtain a sample set
% $Y=\{y^{(0)}, \ldots, y^{(p)}\}$ that is $\Lambda$-poised, 
%where $\Lambda$ is inversely proportional to $\xi_{\min}$, as given by \cref{set_is_poised}.
%\sbnote{I changed the last line of Step 2 in the algorithm to include a \textbf{Stop}}

The first instruction of Step 1 of \cref{model_improving_algorithm} ensures that the first point is not replaced.
The first basis polynomial is always $1$, so can be sure that the first pivot will not need to be replaced.

Observe that \cref{model_improving_algorithm} uses a threshold parameter $\xi_{\min}$ to select the next sample point.
If $\xi_{\min}$ is too large, it is possible that there might not exist a point $x \in B_2(0;1)$ 
in the unit ball such that $\|u_i(x)\| \ge \ximin$.
In this case, the algorithm stops prematurely in Step 2 with a certification that $\xi_{\min}$ is too small.
However,  in \cref{terminates} below, we show that this cannot happen as long as $0 < \ximin \le \frac 1 4$.
To establish the result, we first need the following Lemma from \cite{introduction_book}.


%\begin{lemma}
%\label{maximum_value_for_quad}
%Let $v^T\bar \phi(x)$ be a quadratic polynomial of degree at most $d$, where $\|v\|_{\infty} = 1$
%and $\bar \phi(x)$ is the monomial bases for $\polydn$.
%Then, for any $r \ge 1$,
%\begin{align*}
%\max_{x \in B_2(0; r)} \left|v^T\bar\phi(x)\right| \ge \frac 1 4
%\end{align*}
%\end{lemma}
%\begin{proof}
% When $d = 1$,
% we have that $\bar \phi(x) = (1, x_1, x_2, \ldots, x_n)^T$.
% Then by letting $w = (v_2, \ldots, v_{n+1})^T$ and $\hat w = r \frac w {\|w\|}$, we see that
% \begin{align*}
% v^T\bar\phi\left(\pm w\right) = v_1 + r^2
% \end{align*}
% \end{proof}

\begin{lemma}(\cite[Lemma 6.7]{introduction_book})
\label[lemma]{book_lemma6p7}

Let $v^T \bar{\phi}(x)$ be a quadratic polynomial, where $\norm{v}_{\infty}=1$ and $\bar{\phi}$ is the monomial basis.
Then,
\begin{align*}
\max_{x \in B_2(0;1)} \left\|v^T \bar{\phi}(x)\right\| \ge \frac{1}{4}.
\end{align*}
\end{lemma}

\begin{lemma}
\label[lemma]{terminates}

For any given $\xi_{\min} \in (0,1/4]$, \cref{model_improving_algorithm}
computes a set $Y$ of $p+1$ points in the ball $B_2(0;\Delta)$ for which the pivots of the Gaussian elimination of
$M=M(\bar{\phi},Y)$ satisfy
\begin{align*}
\left\|u_i(y^{(i)})\right\| \ge \xi_{\min},  \quad i=0,\ldots,p.
\end{align*}
\end{lemma}

\begin{proof}

The first pivot polynomial is $u_0 = (1, 0, \ldots, 0)$, so that $\left\|u_0\left(y^{(0)}\right)\right\| = 1 \ge \ximin$.
For $i > 1$, the $(i+1)$st pivot polynomial $u_i(x)$ can be expressed as $v^T \bar{\phi}(x)$,
where $v = (v_0, \ldots, v_{i-1},1,0,\ldots,0)^T$.
Observe that $\norm{v}_{\infty} \ge 1$.
Let $\bar{v} = v/\norm{v}_{\infty}$.
Then by \cref{book_lemma6p7},
\[ \max_{x \in B_2(0;1)} u_i(x) = \max_{x \in B_2(0;1)} \left| v^T \bar{\phi}(x)\right| =
\norm{v}_{\infty} \max_{x \in B_2(0;1)}  \left|\bar{v}^T \bar{\phi}(x)\right| \ge \frac{1}{4} \norm{v}_{\infty} \ge \frac{1}{4}.\]

%\max_{x \in B_2(0;1)} \norm{v}_{\infty} \left|\bar{v}^T \bar{\phi}(x)\right|\max_{x \in B_2(0;1)}  \left|\bar{v}^T \bar{\phi}(x)\right|
%\ge 1/4.\]
It follows that the algorithm does not stop in Step 2 for $\ximin \le 1/4$.   Hence, at the end of the $i$th iteration, we have that  $\left| u_i(y^{(i)})\right| \ge \ximin$.  Moreover,  after the $i$ iteration has been completed,  $u_i$,  and $y^{(i)}$ are never altered.  Thus, the algorithm terminates with  $|u_i(y^{(i)}| \ge \ximin$ for $i=0, \ldots, p$. 

Finally,  observe that all points in the final sample set $Y$ are selected either from the original sample set, which is contained in $B_2(0;\Delta)$,  or are obtained in Step 2 from within $B_2(0;1)$.  Since $\Delta  \ge 1$, it follows that $Y \subset B_2(0;\Delta)$.

\end{proof}



\begin{theorem}
\label{set_is_poised}

Let $\Delta > 1$, and suppose that \cref{model_improving_algorithm} is called on a sample set $Y$.
Then the resulting sample set $\hat Y$ is $\Lambda$-poised over $B_2\left(0;\Delta\right)$ for quadratic interpolation, 
where $\Lambda > 0$ is a constant that depends only on $\Delta$, $\xi_{\text{min}}$ and $n$ and is inversely proportional to $\xi_{\text{min}}$.
Furthermore, $y^{(0)} \in \hat Y$.
\end{theorem}

\begin{proof}

Note that \cref{model_improving_algorithm} never swaps or replaces $y^{(0)}$.
By \cref{terminates},  $\hat Y \subset B_2(0;\Delta)$
and the pivots in the LU-factorization of $M(\bar{\phi},Y)$ are bounded below by $\ximin$; that is,
$\left|u_i\left(y^{(i)}\right)\right| \ge \ximin, \; \forall 0 \le i \le p.$
Thus, by 
\cite[Section 6.7, Exercise 3]{introduction_book}, 
 we have that 
\begin{align*}
\left\|M\left(\bar \phi, Y\right)^{-1}\right\| \le \frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}
\end{align*}
where $\epsilon_{growth}$ is a potentially large, but finite estimate of the growth factor in the LU factorizations.   By  \cref{Lambda_poised_error_bounds_delta},  using the fact that $\Delta \ge 1$, we have that $Y$ is $\Lambda$-poised in $B_2(0;\Delta)$,  where 
\[\Lambda = \left(\frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}\right) \sqrt{p+1}  \frac{\Delta^2}{2} = \frac{(p+1) \epsilon_{growth}}{2\ximin}\Delta^2.\]
%
%
%
%
%Our \cref{Lambda_poised_error_bounds} is then a restatement of \cite[Theorem 3.14]{introduction_book} which 
%relates the $\Lambda$-poisedness of $Y$ to $\left\|M\left(\bar \phi, Y\right)^{-1}\right\|$ over the unit ball.
%However, \cite[Lemma 3.8]{introduction_book} and \cite[Lemma 3.9]{introduction_book} establish that $\Lambda$-poisedness is scale and translation invariant.
\end{proof}

% \cref{model_improving_algorithm} produces a shifted and scaled $\Lambda$-poised set over $B_2\left(0, \Delta\right)$.
% We know show how to scale this set, as we will need well poised sets of radius $\dk$ as $\dk \to 0$.
% The first two auxilary results are found in \cite[Lemma 3.10]{introduction_book} and \cite[Lemma 3.13]{introduction_book},
% reproduced here for convenience.

% \begin{lemma}
% \label[lemma]{lemma_3_10}
% There exists a number $\sigma_{\infty} > 0$ such that, for any choice of $v$ satisfying $\|v\|_{\infty} = 1$,
% there exists a $y \in B_2(0; 1)$ such that $\left|v^T\phi(y)\right| \ge \sigma_{\infty}$.
% \end{lemma}
%
% \begin{lemma}
% \label[lemma]{lemma_3_13}
% Let $w$ be a normalized right-singular vector of a nonsingular $n \times n$ matrix $A$ corresponding to its largest singular value.
% Then, for any vector $r \in \Rn$,
% \begin{align*}
% \|Ar\| \ge |w^T r| \|A\|.
% \end{align*}
% \end{lemma}

% \begin{lemma}
% \label{scale_the_radius}
% Let $\Delta \ge 1$ be fixed, and supposed $\delta \in \left(0, \Delta^{-1}\right]$.
% Suppose that a shifted and scaled set
% $\hat Y \subset B_2\left(0;\Delta\right)$ is $\Lambda$-poised over the ball $B_2\left(0;\Delta\right)$.
% Then, the set $Y = \delta \hat Y$ is $\hat \Lambda$ poised over $B_2\left(0, \delta \Delta\right)$,
% where $\hat \Lambda$ depends only on $p$, $\Lambda$, and $\Delta$.
% \end{lemma}
%
%
% \begin{proof}
% By \cref{Lambda_poised_error_bounds_delta} and $\delta \le 1$, we must only bound $\|M^{-1}\left(\bar \Phi, Y\right)\|$
% where $\bar{\Phi}$ is the monomial basis \cref{define_monomial}.
% Let $\bar v$ be a normalized right singular vector of $M^{-1}\left(\bar \Phi, Y\right)$ corresponding to its largest singular value.
% % Because $\left\|\bar v\right\| = 1$, we know from \cref{lemma_3_10} that there exists a $y \in B_2\left(0; 1\right) \subseteq B_2\left(0; \Delta\right)$ such that
% \begin{align*}
% \left| {\bar v}^T \bar {\phi}(y) \right| \ge \sigma_2 \ge \frac {\sigma_{\infty}}{\sqrt{p_1}}.
% \end{align*}
% By applying \cref{lemma_3_13} with $A={\bar M}^{-1}$, $w = \bar v$, and $r = \bar \phi(y)$,
% \begin{align*}
% \left\|M^{-1}\left(\bar \Phi, Y\right) \bar{\phi}(y)\right\| \ge |\bar v^T \bar \phi(y)| \left\|M^{-1}\left(\bar \Phi, Y\right)\right\|,
% \end{align*}
% \end{proof}



















%
%\begin{theorem}
%\label{set_is_poised}
%The sample set $Y$ obtained from \cref{model_improving_algorithm} is $\Lambda$-poised over $B_2\left(\ck, \delta\right)$ for quadratic interpolation, 
%where $\Lambda > 0$ is a constant that depends only on $\xi_{\text{min}}$ and $n$ and is inversely proportional to $\xi_{\text{min}}$.
%\end{theorem}
%
%\begin{proof}
%This result is shown through a sequence of results in \cite{introduction_book}.
%Namely,  \cite[Theorem 6.5]{introduction_book} shows the pivots in the LU-factorization are bounded below by $\ximin$:
%$
%\left|u_i\left(y^{(i)}\right)\right| \ge \ximin \; \forall 0 \le i \le p.
%$
%\cite[Section 6.7, Exercise 3]{introduction_book}
% bounds the condition number of the Vandermonde matrix in terms of these pivots:
%\begin{align*}
%\left\|M\left(\bar \phi, Y\right)^{-1}\right\| \le \frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}
%\end{align*}
%where $\epsilon_{growth}$ is a large, but finite estimate of the growth factor in LU factorizations.
%Our \cref{Lambda_poised_error_bounds} is then a restatement of \cite[Theorem 3.14]{introduction_book} which 
%relates the $\Lambda$-poisedness of $Y$ to $\left\|M\left(\bar \phi, Y\right)^{-1}\right\|$ over the unit ball.
%However, \cite[Lemma 3.8]{introduction_book} and \cite[Lemma 3.9]{introduction_book} establish that $\Lambda$-poisedness is scale and translation invariant.
%\end{proof}

%Note that \cite[Theorem 6.5]{introduction_book} explicitly states an upper bound $\xi_{\textrm{alg}} > 0$ on $\ximin$, so that $\ximin \in \left(0 , \xi_{\textrm{alg}}\right)$.
%This bound depends on the choice of basis $\Phi$: $\xi_{\textrm{alg}} = 1$ for the linear case and $\xi_{\textrm{alg}} = \frac 1 4$ for the quadratic case.
%As a practical matter, these bounds are not restrictive because $\ximin$ is usually chosen small: on the order of $0.001$ for example.

%\sbnote{The following is a nice discussion!}
%
%This bound on $\ximin$ is complicated by our construction of the sample set:
%we choose points {\em near} the current iterate, although the current sample region does not necessarily include the current iterate.
%This is developed later in the thesis, and our requirements for the sample set are formalized in \cref{define_suitable_ellipsoid} for the linear case and \cref{ellipsoids_notation_definitions} for the non-linear case.
%The takeaway from these requirements is that after an affine transformation to the unit ball, \cref{model_improving_algorithm} 
%will be called to construct sample points within the unit ball $B_2(0; 1)$, with an additional requirement that one of the sample points (the transformed $\xk$)
% lies within $B_2\left(0, \sqrt{2}\right)$.
%Although most practical implementations of \cref{model_improving_algorithm} choose a small $\ximin$, 
%this additional requirement further limits $\ximin$ in theory.
%This raises a question:
%for what values of $\Lambda$ (and therefore $\ximin$) can a sample set be $\Lambda$-poised if one point is chosen outside the unit ball?
%Namely, given $y^{(0)} \in B_2\left(0, \sqrt{2}\right)$:
%\begin{align*}
%\begin{array}{ccc}
%\min\limits_{\Lambda>0, y^{(i)}\in\Rn, l_i\in\polydn} & \Lambda & \\
%\textrm{s.t.} & |l_i(x)| \le \Lambda & \forall \; x \in B_2(0; 1), 0 \le i \le p \\
%& l_i\left(y^{(j)}\right) = \delta^i_j & \forall \; 0 \le i,j \le p \\
%& y^{(i)} \in B_2(0; 1) & \forall \; 1 \le i \le p.
%\end{array}
%\end{align*}
%We have not encountered an issue choosing $\ximin$ too large,
%but we are interested in bounding this program's solution.
%
%% \begin{comment}
%% I think it is straightforward to come up with a simple bound to this problem:
%% construct a perfectly poised set with a point at the center, shifted it.
%% What is the maximum value at $\sqrt 2$ of a quadratic that is strictly between $(-1, 1)$ in $B_2(0; 1)$?
%% Seems like it would be $2$.
%% \end{comment}



\section{Criticality Measure}

\label{criticality_measure_section}
\label{criticallity_measure_section}

A key component of any optimization algorithm is the {\em criticality measure}, which is used to define stopping criteria for the algorithm.
The criticality measure $\chi(x^{(k)})$ at an iterate $x^{(k)}$ is a nonnegative quantity that is zero if and only if $x^{(k)}$ satisfies necessary optimality conditions.
For unconstrained problems,  a typical choice of criticality measure for classical (gradient-based) algorithms is given by $\chi(x) = \norm{\nabla f(x)}$
since the first order optimality condition is $\nabla f(x)=0$.
The algorithm then terminates when $\chi(x) < \tolcrit$, where $\tolcrit >0$ is a stopping tolerance.

For derivative-free optimization,  $\nabla f(x)$ is not available,  so the true criticality measure is replaced by the model criticality measure
$\chik(x) = \norm{\nabla \mfk\left(x\right)}.$
Note however that $\chik$ is only an accurate approximation of $\chi(x)$ if the gradient of the model function $\nabla \mfk(x)$ is a close approximation to $\nabla f(x)$.
For this reason, derivative-free algorithms require not only that $\chik(x)$ is small, but also that the model functions are accurate.
To accomplish this, we require poised sample sets as discussed in \cref{geometry} with a trust-region converging to zero.
Once the criticality measure has reached a small enough threshold $\tolcrit > 0$ and the trust region is small enough ($\dk < \tau_{\Delta}$), we can terminate the algorithm.



%In the presence of convex constraints,
If the feasible region $\feasible$ is convex, a classic criticality measure (see, for example \cite{Conejo:2013:GCT:2620806.2621814} \cite{Conn:2000:TM:357813}) is given by
\begin{align*}
\chi(x) = \left\|x - \proj_{\feasible}\left(x- \nabla f\left(x\right)\right)\right\|.
\end{align*}
If the feasible region is not convex, the projection operation is not well-defined, so this criticality measure is not helpful.
Moreover,  even with a convex feasible region, we need a way to determine the projection, so we prefer a criticality measure based on the  functions defining the constraints.   In particular, for
a first order criticality measure at $\xk$, we define
\begin{align}
\truefeasiblek &= \left\{ x \in \Rn \bigg| c_i\left(\xk\right) + \nabla c_i\left(\xk\right)^T \left(x - \xk\right) \le 0 \; \forall i \in [m] \right\} \label{define_truefeasiblek}
\end{align}
and use
\begin{align}
\chi_c^{(k)}(x) = \left\|x - \proj_{\truefeasiblek}\left(x- \nabla f\left(x\right)\right)\right\|. \label{define_true_criticality}
\end{align}

Note that $\chi_c^{(k)}(\xk) = 0$ if and only if $\xk$ satisfies the first order Karush-Kuhn-Tucker conditions.
% This condition is necessary under regularity assumptions and with convex
% For a convex problem convex constraints with a convex objective, this condition would be necessary and sufficient for local optimality under regularity assumptions.
Unfortunately,  without derivative information, we cannot calculate $\chi_c^{(k)}$ directly, so in our algorithms we approximate it with
\begin{align}
\label{define_criticality_measure}
\chik = \left\|\xk - \proj_{\feasiblek}\left(\xk- \nabla \mfk\left(\xk\right)\right)\right\|,
\end{align}
where $\feasiblek$ is the model feasible region defined by
\begin{align}
\feasiblek = \left\{x \in \Rn \big| \mcik(x) \le 0 \quad \forall 1 \le i \le m \right\}.  \label{define_feasiblek}
\end{align}

This quantity measures how far the current iterate $\xk$ is from satisfying the first order optimality conditions for the model function $\mfk$.
In turn, as $\dk \to 0$, the model $\mfk$ better approximates $f$, $\feasiblek$ better approximates $\feasible$ and $\xk$ approaches a critical point for $f$.

%With general constraints, we cannot use $\proj_{\feasible}$ because the projection is not well defined.
%However, the linearization \cref{define_truefeasiblek} is still well defined.
%Thus, it is possible to use \cref{define_criticality_measure} with general constraints to satisfy the first order necessary conditions.
% However, unlike for convex constraints, points with a linearized criticality measure of $0$ are not necessarily local extremum.



% For now, our algorithm is designed to work with convex constraints, so we employ a classic criticality measure discussed in  of
% The first order optimality conditions for $x^{\star} \in \Rn$ to by a local optimum of $f$ is that $x^{\star}$ satisfies
% \begin{align*}
% x^{\star} = \proj_{\feasiblek}\left(x^{\star} - \gradf(x^{\star})\right).
% \end{align*}
% % that we use as thresholds to determine when the criticallity measure and trust region radius are sufficiently small.

%
% We still employ thresholds
% \begin{align}
%
% \end{align}
% for stopping conditions.
%





% \color{red}
% \begin{comment}
% Citation?
% \end{comment}
% For general constraints the first order necessary conditions are the Karush-Kun-Tucker conditions.
% These state, under regularity assumptions, that for any critical point $x^{\star}$ there exists of a dual variable $\lambda \in \Rm$ such that
% \begin{align*}
% \nabla f(x) + \nabla c(x)^T \lambda  = 0, \;
% c(x) \le 0, \;
% \lambda \ge 0, \;
% c(x)^T\lambda = 0. \;
% \end{align*}
% \color{black}






%
%%A set of poised points are chosen for some radius $\Delta_k>0$ about the current iterate.
%The objective value and derivatives are approximated in a trust region around the current iterate to construct their model functions.
%Next, this model function is minimized over the trust region and the minimum argument becomes the trial point.
%The objective is evaluated at the trial point and a measure of reduction $\rho$ is computed.
%If $\rho$ implies that sufficient reduction has been made and that the model approximates the function well, the trial point is accepted as the new iterate.
%Otherwise, the trust region is reduced to increase model accuracy.
%The algorithm terminates when both a criticality measure $\chik$ and the trust region radius $\Delta_k$ reach sufficiently small thresholds of $\tau_{\chi}$ and $\tau_{\Delta}$.

% \sbnote{I don't think we need to state the trust-region algorithm for unconstrained dfo, so I have commented it out.}

%For unconstrained optimization, the algorithmic framework is described in \cref{unconstrained_dfo}.
%
%\begin{algorithm}[H]
%    \caption{Unconstrained Derivative Free Algorithm}
%    \label{unconstrained_dfo}
%    \begin{itemize}
%        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
%            Initialize tolerance constants $\tau_{\chi} \ge 0$, $\tau_{\Delta} \ge 0$, starting point $\xinit$, initial radius $\Delta_0 > 0$, iteration counter $k=0$, and constants $\omegadec \in (0, 1)$, $ \gammasm \in (0, 1)$, $\gammabi \in (\gammasm, 1)$.
%
%        \item[\textbf{Step 1}] \textbf{(Construct the model function)} \\
%            Call the model improvement ``\cref{model_improving_algorithm}" to provide a set of sample points $Y^{(k)}$.
%            Evaluate the objective on these points and use interpolation \cref{interpolation_formula} to construct the model function $\mfk(x)$.
%
%        \item[\textbf{Step 2}] \textbf{(Check stopping criteria)} \\
%            Compute the criticality measure $\chik$ such as $\chik = \|\nabla\mfk(\xk)\|$. \begin{itemize}
%                \item[] If $ \chik < \tau_{\chi} $ and $\Delta_k<\tau_{\Delta}$ then return solution $\xk$.
%                \item[] If $ \chik < \tau_{\chi} $ but $\Delta_k\ge\tau_{\Delta}$ then
%                set $\Delta_{k+1} \gets \omegadec\Delta_{k}$,
%                $x^{(k+1)} \gets \xk$,
%                $k \gets k+1$ and go to Step 1.
%            \end{itemize}
%
%        \item[\textbf{Step 3}] \textbf{(Solve the trust region subproblem)} \\
%            Compute $\sk = \argmin_{s\in B_2(0; \Delta_k)} \mfk (\xk + s)$ where $B_2(0; \Delta_k)$ is the ball of radius $\Delta_k$ defined in \cref{define_ball}.
%
%        \item[\textbf{Step 4}] \textbf{(Test for improvement)} \\
%            Compute $\rk$ with \cref{define_rhok} \begin{itemize}
%                \item[] If $\rk < \gammasm$ then $\xkpo \gets \xk$ (reject) and $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammasm$ and $\rk < \gammabi$ then $\xkpo\gets\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammabi$ and $\|\sk\| = \Delta_{k}$ then $\xkpo=\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegainc\Delta_{k}$
%                % and either increase the radius or decrease if $\nabla \mfk(\xk)$ is small
%            \end{itemize}
%            $k \gets k+1$ and go to Step 1.
%    \end{itemize}
%\end{algorithm}
%
%This derivative-free optimization algorithm differs from the classical trust region algorithm in two important respects:
%\begin{enumerate}
%    \item Models are constructed without derivative information.
%    \item The trust region radius $\Delta_k$ must go to zero as $k\to\infty$.
%\end{enumerate}
%
%This is required to ensure that the gradient of the model function closely approximates the gradient of $f$.
%Our goal is to generalize this framework to handle constraints,
%where we must ensure no constraint violation occurs
%while also ensuring the accuracy of the models of the constraints.



\section{Trust Regions}

\label{trust_regions_section}

To define our algorithms, we distinguish between three types of trust regions: 
the {\em sample region} $\sampletrk$,
the {\em search region} $\searchtrk$,
and the {\em outer trust region} $\outertrk$.
For unconstrained optimization,  these trust regions are typically identical and are chosen to be an $L_2$-ball of radius $\Delta_k$.
However, for constrained optimization, it is useful to distinguish between the two regions.



The sample region is where the algorithm chooses sample points, constraining them to ensure their feasibility.
The search region defines the feasible region for the trust region subproblem.
Both $\sampletrk$ and $\searchtrk$ lie within the {\em outer trust region},
$\outertrk = B_{\infty}\left(\xk, \dk\right)$, which is an $L_{\infty}$-ball of radius $\dk$ centered at the current iterate $\xk$:
\begin{align}
\label{define_outer_trust_region}
\outertrk = B_{\infty}\left(\xk,\dk\right) = \left\{x\in \Rn | \; \xki - \dk \le x_i \le \xki + \dk \quad \forall i \in [m] \right \}.
\end{align}

To allow for the best possible trial point, we would like the search region to be as large as possible within the outer trust region while remaining feasible.
Ideally, we would set $\searchtrk=\outertrk \cap \feasible$.
However, this is only possible when the constraints are known.
In \cref{chap:general}, we can only take $\searchtrk = \outertrk \cap \feasiblek$.
Observe that using an $L_{\infty}$ ball instead of an $L_2$ ball results in linear constraints for the model problem,
so that that $\searchtrk$ is a polytope.
% Observe that linear constraint models with an $L_{\infty}$-ball instead of an $L_2$-ball ensure $\searchtrk$ is a polytope.



% \begin{comment}
% This paragraph addresses a comment, but I don't think it is needed.
% 
% 
% We do not spend time on the approach of choosing $\searchtrk = \sampletrk$.
% Although our choices $\sampletrk \subseteq \feasible$ must remain close to the current iterate, 
% they do not ensure $\sampletrk$ contains a point decreasing the objective.
% \end{comment}

% are required to lie within the feasible region 
% $\feasible := \{x|\lca x \le \lcb\}$


% \begin{itemize}
% \item The {\em Sample Region} is denoted by $\sampletrk$ and constrains sample points to ensure their feasibility.
% \item The {\em Search Region} is denoted by $\searchtrk$ and constrains the search iterate within the trust region subproblem.
% \item The {\em Outer Trust region} is an $L-\infty$ ball of radius $\dk$ and denoted by $\outertrk$.
% \end{itemize}
% To define our algorithms, we distinguish between three types of trust regions:
% a {\em sample trust region}, $\sampletrk$, from which the sample points are chosen, 
% and a {\em search trust region}, $\searchtrk$, which is the feasible region for the trust region subproblem.

% 
% The outer trust region is an $L_{\infty}$ ball of radius $ \dk $ defined by
% \begin{align}
% \outertrk = \tr = \{x\in \Rn | \; \xk_i - \dk \le x_i \le \xk_i + \dk \quad \forall i \in [n]\}. \label{define_outer_trust_region}
% \end{align}

% Note that the outer trust region may include infeasible points.
% To ensure feasibility of all sample points, we construct an inner trust region for sample points $ \sampletrk $  satisfying 
% $\sampletrk \subset \outertrk \cap \feasible$ and $\xk \in \sampletrk $.
% However, we do not want to limit the search for a new iterate to the same trust region we use to construct the model.
% This means we introduce another trust region $ \searchtrk $ that also satisfies $ \searchtrk \subset \outertrk \cap \feasible$ and $\xk \in \searchtrk $ for the trust region subproblem.
