\section{Literature Review}

Recently, there has been a growth in applications of derivative free optimization.
Such applications include photo-injector optimization \cite{1742-6596-874-1-012062}, 
circuitry arrangements \cite{PLOSKAS201816}, machine learning \cite{KS2018}, volume optimization \cite{Cheng2017}, 
and reliability based optimization \cite{Gao2017}.

As the number of applications grow, so do the number of Derivative-free algorithms.
Most of these algorithms fall into two main categories:  direct-search methods and model-based methods.
Direct-search methods use comparatively simple strategies to explore the solution space 
using only the relative ranks of function values rather than their numerical values.
A classic example is the popular Nelder-Mead algorithm \cite{10.1093/comjnl/7.4.308} for unconstrained optimization.

Model-based methods guide the search with approximate derivative information from models of the black box functions.
Our work is model-based.
The main idea of model-based, trust-region methods is that trial points are selected at each iteration by solving a trust-region subproblem.  
Each subproblem has the form 
\[ \begin{array}{ll} \min_{s \in \Rn} & m_f^{(k)}(x^{(k)}_s) \\ 
\st & x^{(k)}+s \in \mathcal{F}_k \\
& \norm{s} \le \Delta_k
\end{array} \]
where $m_f^{(k)}$ is a model function approximating the objective $f$,   $\dk$ is the trust region radius,  
and $\mathcal{F}_k$ is an approximation of the feasible region. 
The solution $\sk$ of the trust-region subproblem determines a {\em trial point} $\xk + \sk$.  
The objective function and constraints are then evaluated at the trial point to determine whether to accept the trial point.   
If the trial point is rejected, the trust region radius is decreased and a new trial point is computed by solving a revised trust-region subproblem.     
If the trial point is accepted, then the trust region radius may be increased or decreased for the next iteration 
depending on how well the sample point improved upon the previous iterate.
This will be discussed in \cref{rhosection}.

\paragraph*{Reviews}
There are a number of books and survey articles that provide good introductions to the field of derivative-free optimization.
Within \cite{introduction_book} derivative-free methods are developed in detail.
This is the first text book devoted to derivative free optimization.
It contains a good explanation of ensuring geometry of the current set with poisedness for unconstrained problems and also covers other derivative-free methods including direct-search and line search.

A good review of derivative free algorithms and software libraries can be found in \cite{miguel_review}.
This compares several software libraries, and reviews the development of derivative free optimization since it started.
Another recent review can be found in \cite{custodio_review2} and \cite{larson_menickelly_wild_2019}.


\paragraph*{Constrained derivative free algorithms}
The development of DFO algorithms for constrained optimization has been relatively recent,
with much of the early work in this area was focused on direct-search methods.

The coordinate descent algorithm is among the simplest direct-search methods, 
which can be generalized to pattern searches \cite{Audet2002AnalysisOG}. 
We compare our results to the popular Mesh Adaptive Search algorithm implemented within the NOMAD software
\cite{Le2011a}.

\paragraph*{Model-Based Trust-Region Methods for DFO}
The literature on model-based DFO methods for constrained optimization is smaller. 

COBYLA \cite{pub.1046127469} was one of the first model-based approaches for solving constrained black-box problems.
The classic sequential quadratic programming algorithm is implemented for equality based constraints within \cite{Troltzsch2016}.
A two-phased, feasibility and optimization approach that handles infeasible starting points is developed within \cite{BAJAJ2018306}.
\cite{Gao2018} also presents an algorithm for linearly constrained derivative free optimization that uses a backtracking technique to minimize the number of evaluations required.



\paragraph*{}
The algorithm presented within \cite{doi:10.1080/10556788.2015.1026968} even ensures that each iterate is feasible, 
although sample points may not be.

Of particular importance for our work is \cite{Conejo:2013:GCT:2620806.2621814}.
This reference provides a convergence proof for a class algorithms when the constraints are convex.


\section{Criticality Measure}
\label{criticallity_measure_section}
A key component of any optimization algorithm is the {\em criticality measure}, which is used to define stopping criteria for the algorithm.
The criticality measure $\chi(x^{(k)})$ at an iterate $x^{(k)}$ is a nonnegative quantity that is zero if and only if $x^{(k)}$ satisfies necessary optimality conditions. 
For unconstrained problems,  a typical choice of criticality measure for classical (gradient-based) algorithms is $\chi(x) = \norm{\nabla f(x)}$ 
since the first order optimality condition is $\nabla f(x)=0$.
The algorithm then terminates when $\chi(x) < \tolcrit$, where $\tolcrit >0$ is a stopping tolerance.

For derivative-free optimization,  $\nabla f(x)$ is not available,  so the true criticality measure is replaced by the model criticality measure 
$\chik(x) = \norm{\nabla \mfk\left(x\right)}.$
Note however that $\chik$ is only an accurate approximation of $\chi(x)$ if the gradient of the model function $\nabla \mfk(x)$ is a close approximation to $\nabla f(x)$.
For this reason, derivative-free algorithms require not only that $\chik(x)$ is small, but also that the model functions are accurate.
To accomplish this, we require that the trust-region radius must converge to zero.
Once the criticality measure has reached a small enough threshold $\tolcrit > 0$ and the trust region is small enough ($\dk < \tau_{\Delta}$), we can terminate the algorithm.



In the presence of convex constraints, a classic \cite{Conejo:2013:GCT:2620806.2621814} \cite{ConnGoulToin00} criticallity measure is
\begin{align*}
\chi^{(k)}(x) = \left\|\xk - \text{Proj}_{\feasible}\left(x- \nabla f\left(x\right)\right)\right\|.
\end{align*}
For a first order criticallity measure at $\xk$, we can define
\begin{align}
\truefeasiblek &= \left\{ x \in \Rn \bigg| c_i\left(\xk\right) + \nabla c_i\left(\xk\right)^T \left(x - \xk\right) \le 0 \; \forall i \in [m] \right\}. \label{define_truefeasiblek}
\end{align}
and use
\begin{align*}
\chi_c^{(k)} = \left\|\xk - \text{Proj}_{\truefeasiblek}\left(x- \nabla f\left(x\right)\right)\right\|.
\end{align*}
% This condition is necessary under regularity assumptions, and with convex 
% For a convex problemconvex constraints with a convex objective, this condition would be necessary and sufficient for local optimality under regularity assumptions.
Without derivative information, we model this by
\begin{align}
\label{define_criticality_measure}
\chik = \left\|\xk - \text{Proj}_{\feasiblek}\left(\xk- \nabla \mfk\left(\xk\right)\right)\right\|.
\end{align}
Recall that $\feasiblek$ was defined by \cref{define_feasiblek}.
For convex constraints, this quantity measures how far the current iterate $\xk$ is from satisfying the first order optimality conditions for of $\mfk$.
In turn, as $\dk \to 0$, the model $\mfk$ better approximates $f$, $\feasiblek$ better approximates $\feasible$ and $\xk$ approaches an optimum of $f$.

With general constraints, we cannot use $\text{Proj}_{\feasible}$ because the projection is not well defined.
However, the linearization \cref{define_truefeasiblek} is still well defined.
Thus, it is possible to use \cref{define_criticality_measure} with general constraints to satisfy the first order necessary conditions.
% However, unlike for convex constraints, points with a linearized criticality measure of $0$ are not necessarily local extremum.



% For now, our algorithm is designed to work with convex constraints, so we employ a classic criticality measure discussed in  of
% The first order optimality conditions for $x^{\star} \in \Rn$ to by a local optimum of $f$ is that $x^{\star}$ satisfies
% \begin{align*}
% x^{\star} = \text{Proj}_{\feasiblek}\left(x^{\star} - \gradf(x^{\star})\right).
% \end{align*}
% % that we use as thresholds to determine when the criticallity measure and trust region radius are sufficiently small.

% 
% We still employ thresholds 
% \begin{align}
% 
% \end{align}
% for stopping conditions.
% 





% \color{red}
% \begin{boxedcomment}
% Citation?
% \end{boxedcomment}
% For general constraints the first order necessary conditions are the Karush-Kun-Tucker conditions.
% These state, under regularity assumptions, that for any critical point $x^{\star}$ there exists of a dual variable $\lambda \in \Rm$ such that
% \begin{align*}
% \nabla f(x) + \nabla c(x)^T \lambda  = 0, \;
% c(x) \le 0, \;
% \lambda \ge 0, \;
% c(x)^T\lambda = 0. \;
% \end{align*}
% \color{black}






%  
%%A set of poised points are chosen for some radius $\Delta_k>0$ about the current iterate.
%The objective value and derivatives are approximated in a trust region around the current iterate to construct their model functions.
%Next, this model function is minimized over the trust region and the minimum argument becomes the trial point.
%The objective is evaluated at the trial point and a measure of reduction $\rho$ is computed.
%If $\rho$ implies that sufficient reduction has been made and that the model approximates the function well, the trial point is accepted as the new iterate.
%Otherwise, the trust region is reduced to increase model accuracy.
%The algorithm terminates when both a criticality measure $\chik$ and the trust region radius $\Delta_k$ reach sufficiently small thresholds of $\tau_{\chi}$ and $\tau_{\Delta}$.

% \sbnote{I don't think we need to state the trust-region algorithm for unconstrained dfo, so I have commented it out.}

%For unconstrained optimization, the algorithmic framework is described in \cref{unconstrained_dfo}.
%
%\begin{algorithm}[H]
%    \caption{Unconstrained Derivative Free Algorithm}
%    \label{unconstrained_dfo}
%    \begin{itemize}
%        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
%            Initialize tolerance constants $\tau_{\chi} \ge 0$, $\tau_{\Delta} \ge 0$, starting point $\xinit$, initial radius $\Delta_0 > 0$, iteration counter $k=0$, and constants $\omegadec \in (0, 1)$, $ \gammasm \in (0, 1)$, $\gammabi \in (\gammasm, 1)$.
%            
%        \item[\textbf{Step 1}] \textbf{(Construct the model function)} \\
%            Call the model improvement ``\cref{model_improving_algorithm}" to provide a set of sample points $Y^{(k)}$.
%            Evaluate the objective on these points and use interpolation \cref{interpolation_formula} to construct the model function $\mfk(x)$.
%        
%        \item[\textbf{Step 2}] \textbf{(Check stopping criteria)} \\
%            Compute the criticality measure $\chik$ such as $\chik = \|\nabla\mfk(\xk)\|$. \begin{itemize}
%                \item[] If $ \chik < \tau_{\chi} $ and $\Delta_k<\tau_{\Delta}$ then return solution $\xk$.
%                \item[] If $ \chik < \tau_{\chi} $ but $\Delta_k\ge\tau_{\Delta}$ then  
%                set $\Delta_{k+1} \gets \omegadec\Delta_{k}$, 
%                $x^{(k+1)} \gets \xk$,
%                $k \gets k+1$ and go to Step 1.
%            \end{itemize}
%        
%        \item[\textbf{Step 3}] \textbf{(Solve the trust region subproblem)} \\
%            Compute $\sk = \argmin_{s\in B_2(0; \Delta_k)} \mfk (\xk + s)$ where $B_2(0; \Delta_k)$ is the ball of radius $\Delta_k$ defined in \cref{define_ball}.
%            
%        \item[\textbf{Step 4}] \textbf{(Test for improvement)} \\
%            Compute $\rk$ with \cref{define_rhok} \begin{itemize}
%                \item[] If $\rk < \gammasm$ then $\xkpo \gets \xk$ (reject) and $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammasm$ and $\rk < \gammabi$ then $\xkpo\gets\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammabi$ and $\|\sk\| = \Delta_{k}$ then $\xkpo=\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegainc\Delta_{k}$
%                % and either increase the radius or decrease if $\nabla \mfk(\xk)$ is small
%            \end{itemize}
%            $k \gets k+1$ and go to Step 1.
%    \end{itemize}
%\end{algorithm}
%
%This derivative-free optimization algorithm differs from the classical trust region algorithm in two important respects:
%\begin{enumerate}
%    \item Models are constructed without derivative information.
%    \item The trust region radius $\Delta_k$ must go to zero as $k\to\infty$.
%\end{enumerate}
%
%This is required to ensure that the gradient of the model function closely approximates the gradient of $f$.
%Our goal is to generalize this framework to handle constraints, 
%where we must ensure no constraint violation occurs
%while also ensuring the accuracy of the models of the constraints.



\section{Assessing Model Accuracy and Radius Management}
\label{rhosection}
Each iteration that evaluates a trial point must also test the accuracy of the model functions.
To test the accuracy, we calculate a quantity
\begin{align}
\label{define_rhok}
\rk = \frac{f(\xk) - f(\xk+\sk)}{\mfk(\xk) - \mfk(\xk+\sk)}
\end{align}
which measures the actual improvement over the predicted improvement.
A small $\rk$ implies the model functions are not sufficiently accurate.
Values of $\rk$ close to $1$ imply that the model accurately predicted the new objective value.
A large $\rk$ implies progress in minimizing the objective, although the model was not accurate.
This has been widely used within trust region frameworks such as \cite{Conn:2000:TM:357813} and within a derivative free context \cite{introduction_book}.

The user supplies fixed constants
% \label{define_the_gammas}
% \label{define_the_omegas}
$
0 < \gammasm < \gammabi \le 1
$
as thresholds on $\rk$ and
$
0 < \omegadec < 1 \le \omegainc
$
% $\omegadec, \omegainc$
as decrement and increment factors to determine the trust region update policy.
That is, when $\rk < \gammasm$, the trust region is decreased by a factor of $\omegadec$, and the trust region is increased by a factor of $\omegainc$
during some iterations in which $\rk > \gammabi$.


\section{Interpolation}
\label{interpolation} 
Model-based methods for derivative free optimization construct models of a function $f(x)$ from a family of functions spanned by a set of $p + 1 \in \naturals$ basis functions  $\Phi = \{\phi_0, \phi_1, \ldots, \phi_p\}$. Each member of this family has the form $\mf(x) = \sum_{i=0}^p\alpha_i\phi_i(x)$ for some scalar coefficients $\alpha_i, i \in \{0, \ldots, p\}$.

We use interpolation to choose the coefficients $\alpha = [\alpha_0, \ldots, \alpha_p]^T$ so that $\mfk$ agrees with $f$ on a set of $p+1$ sample points $Y = \{y^0, y^1, \ldots, y^p\}$ at which the function $f$ has been evaluated.
Thus, the coefficients $\alpha$ must satisfy the \emph{interpolation condition}
\begin{align}
\label{interpolation_condition}
    \mf(y^i) = \sum^p_{j=0}\alpha_j\phi_j(y^i) = f(y^i) \quad \forall \quad 0 \le i \le p.
\end{align}

% We can also write this equation in matrix form.
This equation can be written more compactly in the form
\begin{equation}\label{matrix_form}
V \alpha = \bar{f},
\end{equation}
where $\bar{f} = [f(y^0), f(y^1), \ldots, f(y^p)]^T$ and the Vandermonde matrix $V$ is defined by 

\begin{align}
\label{vandermonde}
V=M(\Phi,Y) :=
\begin{bmatrix}
    \phi_0(y^0)      & \phi_1(y^0)       & \ldots & \phi_{p}(y^0)      \\
    \phi_0(y^1)      & \phi_1(y^1)       & \dots  & \phi_{p}(y^1)      \\
                     &                   & \vdots &                    \\
    \phi_0(y^{p})    & \phi_1(y^{p})     & \ldots & \phi_{p}(y^{p})
\end{bmatrix},
\end{align}


The interpolation equation \cref{matrix_form} has a unique solution if and only if $V$ is nonsingular.  In this case, we say that the sample set $Y$ is \emph{poised} for interpolation with respect to the basis functions $\phi_i$. 
However, even when $V$ is nonsingular but ``close" to singular, as measured by its condition number, the model's approximation may become inaccurate.


\section{Sample set geometry}
\label{geometry}
The term \emph{geometry} describes how the distribution of points in the sample set $Y$ affects the model's accuracy.

In the case of polynomial model functions, a careful analysis of model accuracy can be performed using \emph{Lagrange polynomials}.
Let the space of polynomials with degree less than or equal to $d$ be denoted $\polydn$ and have dimension $p+1$.
The Lagrange polynomials $l_0, l_1, \ldots, l_p$ for the sample set $Y$ are a basis of $\polydn$ such that
\begin{align}
l_i(y^j) = \delta_{i,j}
\end{align}
where $\delta_{i,j} = \{0 \;\text{if}\; i\ne j,\; 1 \;\text{if} \; i = j \}$ is the Kronecker-delta function.
%For example, after this change of basis, note that the Vandermonde matrix becomes the identity matrix.
Thus, as shown in \cite{introduction_book}, we can conveniently write
\begin{align}
\label{reg}
\mf(x) = \sum^p_{j=0}f(y^i)l_i(x).
\end{align}


We say that a set $Y$ is \emph{$\Lambda$-poised} for a fixed constant $\Lambda$ with respect to a basis $\Phi$ on the set 
$B \subset\Rn$ if and only if the Lagrange polynomials $l_i$ associated with $Y$ satisfy
\begin{align}
\Lambda \ge \max_{0\le i\le p}\max_{x\in B}|l_i(x)|.
\end{align}
% \color{red}
% Frequently, the basis $\Phi$ is taken to be the monomial basis of order $d \in \naturals$:
% \begin{align*}
% \phi_0(x) = 1, 
% \phi_1(x) = x_1,
% \phi_2(x) = x_2, 
% \ldots, 
% \phi_{n}(x) = x_n, \\
% \phi_{1+n}(x) = x_1^2,
% \phi_{2+n}(x) = x_1x_2, 
% \phi_{3+n}(x) = x_1x_3, 
% \ldots, 
% \phi_{\frac{(n+1)(n+1)}{2}}(x) = x_n^2, \\
% \phi_{\frac{(n+1)(n+2)}{2} + 1}(x) = x_1^3, 
% \ldots, 
% \phi_{p}(x) = x_n^d
% \end{align*}
% For example, with $n=2$, and $d=2$ we have $p+1=6$ and
% \begin{align*}
% \phi_0(x) = 1,
% \phi_1(x) = x_1,
% \phi_2(x) = x_2,
% \phi_3(x) = x_1^2,
% \phi_4(x) = x_1x_2,
% \phi_5(x) = x_2^2.
% \end{align*}
% \color{black}
In the case of interpolation over the quadratic polynomials, 
$ \mathcal{P}^2_n$, we say that $Y$ is \emph{$\Lambda$-poised for quadratic interpolation}.

The concept of $\Lambda$-poisedness allows us to establish the following error bounds, as shown in 
 \cite[Theorem 3.16]{introduction_book}:

\begin{theorem}
\label{quadratic_errors}  
Let $Y = \{y^0, y^1, \ldots, y^p\} \subset \Rn$ be a set of $p+1=\frac{(n+1)(n+2)}{2}$ sample points and $\Delta = \max_{1 \le j \le p} \|y^j-y^0\|$.  Suppose that $Y$ is $\Lambda$-poised for quadratic interpolation on $B(y^0; \Delta)$.    Then, for any constant $L > 0$, there exist constants $\kappa_{h}, \kappa_{g}$, and $\kappa_{f}$ such that the following error bounds hold for any function $f:\Rn \rightarrow \reals$ that is $LC^2$ with Lipschitz constant $L$ on an open set containing $B(y^0;\Delta)$:

\begin{align}
\|\nabla^2 f(y) - \nabla^2 m_f(y)\| \le \kappa_{h} \Delta \quad \forall y \in B_2(y^0; \Delta) \label{error_in_hessian}\\
\|\nabla f(y) - \nabla m_f(y)\| \le \kappa_{g} \Delta^2 \quad \forall y \in B_2(y^0; \Delta) \label{error_in_gradient} \\
|f(y) - m_f(y) | \le \kappa_{f} \Delta^3 \quad \forall y \in B_2(y^0; \Delta). \label{error_in_function} 
\end{align}
where $m_f$ is the quadratic model function interpolating $f$ on $Y$.
\end{theorem}

There is a close connection between the $\Lambda$-poisedness of $Y$ and the condition number of the Vandermonde matrix associated with the monomial basis $\bar{\Phi}$ $= \{ \bar{\phi}_0, \ldots, \bar{\phi}_p\}$ $=\{1, x_1, \ldots, x_n, x_1^2/2, \ldots x_n^2/2,x_1 x_2, \ldots, x_{n-1}x_{n}\}$.  In particular, let $\hat{Y}$ be the shifted and scaled sample set $\left\{\frac{(y^i-y^0)}{\Delta}|y^i \in Y\right\}$.
Then we have the following result:
% \sbnote{I reworded the theorem to incorporate the assumptions since you never refer to the assumption anywhere else in the thesis.}

\begin{theorem}\label{Lambda_poised_error_bounds}
(\cite[Theorem 3.14]{introduction_book}) Let $\hat{M} = M(\bar{\Phi},\hat{Y})$.  
If $\hat{M}$ is  nonsingular and $\norm{\hat{M}^{-1}} \le \Lambda$,   
then the set $\hat{Y}$ is $\Lambda  \sqrt{p+1}$-poised in the unit ball $B(0;1)$.  
Conversely, if the set $\hat{Y}$ is $\Lambda$-poised for quadratic interpolation on the unit ball, 
then $\norm{\hat{M}^{-1}} \le \theta \Lambda \sqrt{p+1}$, where $\theta > 0$ is a 
constant dependent on $n$ but independent of $\hat{Y}$ and $\Lambda$.
\end{theorem}

% \begin{boxedcomment}
% Is this result important to discuss?
% \end{boxedcomment}





\section{Model Improvement Algorithms}

Efficient implementations of model-based methods re-use sample points from previous iterations that fall within (or at least near) the current trust region.
New points are then added to the sample set using a model improvement algorithm as described in 
\cite{introduction_book}  and stated here in \cref{model_improving_algorithm}.

The model improvement algorithm starts with a set of $p+1$ sample points and then uses LU factorization with partial pivoting of the 
associated Vandermonde matrix to construct a set of pivot polynomials $\{u_0, \ldots, u_p\}$ that are closely related to the Lagrange polynomials.  

Each iteration of the algorithm identifies a point in the sample set to include in the final sample set.
In particular, on the $i$th iteration, the points $y^0, \ldots, y^{i-1}$ have already been included.
If a point $y^j$, $j \ge i$ can be found such that $u_i(y^j)$ has sufficiently large magnitude, 
then that point is added to the final sample set (by swapping it with $y^{i}$).
However, if no such point can be found, it indicates that including any of the remaining points in the final sample set would result in a poorly poised set.
Therefore, the point $y^i$ is replaced by a new point which is obtained by maximizing $|u_i(x)|$ over the trust region.

\paragraph*{Note:}  Typically, we have fewer than $p+1$ previously evaluated sample points within the trust region at the beginning of each iteration.  Since the Model Improvement Algorithm requires a starting set of $p+1$ points, we add copies of $y^0$ to create a set with $p+1$ points.

\begin{algorithm}[H]
    \caption{Model Improvement Algorithm \label{alg:model_improvement} }
    \label{model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Given a center $\ck\in\Rn$, a radius $\delta >0$, and set $Y$ of $p+1$ points,
            initialize $i=1$, $\ximin > 0$, and let $\bar \phi_i(x)$ be the monomial basis
%             Construct the Vandermonde matrix $V_{i,j} = \bar{\phi}_j(\frac 1 {\Delta}(y^i - y^0))$.
		\item[\textbf{Step 1}] \textbf{(Pivot)} \\
			Compute the next pivot index $j^{\textrm{max}}_i = \argmax_{i \le j \le |Y|-1} \left|u_i\left(y^j\right)\right|$,
			and swap points $i$ and $j^{\textrm{max}}_i$ within $Y$.
			
        \item[\textbf{Step 2}] \textbf{(Check threshold)} \begin{itemize}
                \item[] If $\left|u_i\left(y^i\right)\right| \ge \ximin$ then go to Step 3.
                \item[] If $\left|u_i\left(y^i\right)\right| < \ximin$, then replace $y^i \gets \argmax_{x \in B_2\left(\ck, \delta\right)}\left|u_i(x)\right|$
%                 \item[] $Y \gets Y \cup \{\hat y \}\setminus \{y^i\}$
				\item[] If $\left|u_i\left(y^i\right)\right| < \ximin$ after this replacement, then $\ximin$ was chosen too small.
            \end{itemize}
        \item[\textbf{Step 3}] \textbf{(Gaussian elimination)} \\
        	Set $u_j(x) \gets u_j(x) - \frac{u_j\left(y^i\right)}{u_i\left(y^i\right)} u_i(x)$ \\
%         \begin{itemize}
%                 \item[] Set $V_i \gets \frac{1}{V_{i,i}} V_i$
%                 \item[] Set $V_{\bullet j} \gets V_{\bullet j} - \frac{V_{i,j}}{V_{i, i}} V_{\bullet j} \forall j=i \ldots p$
%             \end{itemize}
            If $i = p$ then \textbf{Stop}, otherwise Set $i \gets i+1$ and go to Step 1
    \end{itemize}
\end{algorithm}


At the completion of the algorithm, we obtain a  sample set $Y=\{y^0, \ldots, y^p\}$ that is $\Lambda$-poised, 
where $\Lambda$ is inversely proportional to $\xi_{\min}$, as given by the following result.
\begin{theorem}
\label{set_is_poised}
The sample set $Y$ obtained from \cref{model_improving_algorithm} is $\Lambda$-poised over $B_2\left(\ck, \delta\right)$ for quadratic interpolation, 
where $\Lambda > 0$ is a constant that depends only on $\xi_{\text{min}}$ and $n$ and is inversely proportional to $\xi_{\text{min}}$.
\end{theorem}

\begin{proof}
This result is shown through a sequence of results in \cite{introduction_book}.
Namely,  \cite[Theorem 6.5]{introduction_book} shows the pivots in the LU-factorization are bounded below by $\ximin$:
$
\left|u_i\left(y^{(i)}\right)\right| \ge \ximin \; \forall 0 \le i \le p.
$
\cite[Section 6.7, Exercise 3]{introduction_book}
 bounds the condition number of the vandermonde matrix in terms of these pivots:
\begin{align*}
\left\|M\left(\bar \phi, Y\right)^{-1}\right\| \le \frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}.
\end{align*}
where $\epsilon_{growth}$ is a large, but finite estimate of the growth factor in LU factorizations.
Our \cref{Lambda_poised_error_bounds} is then a restatement of \cite[Theorem 3.14]{introduction_book} which 
relates the $\Lambda$-poisedness of $Y$ to $\left\|M\left(\bar \phi, Y\right)^{-1}\right\|$ over the unit ball.
However, \cite[Lemma 3.8]{introduction_book} and \cite[Lemma 3.9]{introduction_book} establish that $\Lambda$-poisedness is scale and translation invariant.
\end{proof}

In \cref{satisfying_accuracy} we will show how to modify this algorithm to construct a $\Lambda$-poised set over an ellipsoidal region.


\section{Trust Regions}

To define our algorithms, we distinguish between three types of trust regions: 
the {\em sample region} $\sampletrk$,
the {\em search region} $\searchtrk$,
and the {\em outer trust region} $\outertrk$.
For unconstrained optimization,  these trust regions are typically identical,  and are chosen to be an $L_2$-ball of radius $\Delta_k$.
However, for constrained optimization, it is useful to distinguish between the two regions.



The sample region is where the algorithm chooses sample points: it constrains sample points to ensure their feasibility.
The search region is used as the feasible region for trust region subproblem.
Both the $\sampletrk$ and the $\searchtrk$ lie within the {\em outer trust region}, 
$\outertrk = B_{\infty}\left(\xk, \dk\right)$, which is an $L_{\infty}$-ball of radius $\dk$ centered at the current iterate $\xk$:
\begin{align}
\label{define_outer_trust_region}
\outertrk = B_{\infty}\left(\xk,\dk\right) = \left\{x\in \Rn | \; \xki - \dk \le x_i \le \xki + \dk \quad \forall i \in [m] \right \}.
\end{align}

To allow for the best possible trial point, we would like the search region to be as large as possible within the outer trust region while still remaining feasible.
Ideally, we would set $\searchtrk=\outertrk \cap \feasible$.
However, this is only possible when the constraints are known.
In \cref{chap:general}, we can only take $\searchtrk = \outertrk \cap \feasiblek$.
Observe that by using an $L_{\infty}$-ball instead of an $L_2$-ball, $\searchtrk$ is a polytope.



% \begin{boxedcomment}
% This paragraph addresses a comment, but I don't think it is needed.
% 
% 
% We do not spend time on the approach of choosing $\searchtrk = \sampletrk$.
% Although our choices $\sampletrk \subseteq \feasible$ must remain close to the current iterate, 
% they do not ensure $\sampletrk$ contains a point decreasing the objective.
% \end{boxedcomment}

% are required to lie within the feasible region 
% $\feasible := \{x|\lca x \le \lcb\}$


% \begin{itemize}
% \item The {\em Sample Region} is denoted by $\sampletrk$ and constrains sample points to ensure their feasibility.
% \item The {\em Search Region} is denoted by $\searchtrk$ and constrains the search iterate within the trust region subproblem.
% \item The {\em Outer Trust region} is an $L-\infty$ ball of radius $\dk$ and denoted by $\outertrk$.
% \end{itemize}
% To define our algorithms, we distinguish between three types of trust regions:
% a {\em sample trust region}, $\sampletrk$, from which the sample points are chosen, 
% and a {\em search trust region}, $\searchtrk$, which is the feasible region for the trust region subproblem.

% 
% The outer trust region is an $L_{\infty}$ ball of radius $ \dk $ defined by
% \begin{align}
% \outertrk = \tr = \{x\in \Rn | \; \xk_i - \dk \le x_i \le \xk_i + \dk \quad \forall i \in [n]\}. \label{define_outer_trust_region}
% \end{align}

% Note that the outer trust region may include infeasible points.
% To ensure feasibility of all sample points, we construct an inner trust region for sample points $ \sampletrk $  satisfying 
% $\sampletrk \subset \outertrk \cap \feasible$ and $\xk \in \sampletrk $.
% However, we do not want to limit the search for a new iterate to the same trust region we use to construct the model.
% This means we introduce another trust region $ \searchtrk $ that also satisfies $ \searchtrk \subset \outertrk \cap \feasible$ and $\xk \in \searchtrk $ for the trust region subproblem.
