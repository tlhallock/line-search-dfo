
% \section{Derivative Free Optimization}

Derivative free optimization (DFO) refers to mathematical programs involving functions for which derivative information is not explicitly available.
Such problems arise, for example, when the functions are evaluated by simulations or by laboratory experiments.
In such applications, function evaluations are expensive, so it is sensible to invest significant computational resources to minimize the number of function evaluations.

This work is ultimately aimed at developing algorithms to solve constrained optimization problems of the form 
\begin{align}
\begin{array}{ccl} \min_{x \in \Rn} & f(x) \\
\mbox{subject to} \quad & c_i(x) \le 0 & 1 \le i \le m,
\end{array}
\label{the_dfo_problem}
\end{align}
where 
% $\domain$ is a subset of $\Rn$, and
$f$ and $c_i, \forall 1 \le i \le m$ are real-valued functions on $\Rn$ with at least one of these functions being a {\em black-box} function, meaning that derivatives cannot be evaluated directly.
We will let the feasible set be represented as 
\begin{align}
\feasible = \{x \in \Rn | c_i(x) \le 0 \; \forall 1 \le i \le m \}. \label{define_feasible}
\end{align}

We are interested in developing {\em model-based} {\em trust-region} algorithms for solving these problems.
Model-based methods work by constructing model functions to approximate the black box functions at each iteration.
The model functions are determined by fitting previously evaluated function values on a set of sample points.
In trust-region methods, the model-functions are used to define a trust-region subproblem whose solution determines the next iterate.
For example, the trust-region subproblem might have the form

\begin{align*}
\begin{array}{ccl} \min_{\|s\| \le \dk}
 & \mfk \left(\xk+s\right) \\
\mbox{subject to} \quad & \mcik\left(\xk + s\right) \le 0 & 1 \le i \le m, \\
& \|s\| \le \dk \\
\end{array}
\end{align*}

where $\xk$ is the current iterate, $\mfk$ is the model function approximating $f$, 
and $\mcik$ are the model functions approximating the constraint functions $c_i, \forall 1 \le i \le m$, and $\dk$ is the radius of the trust-region.
The key differences between this problem and the original is that all functions are replaced with their model functions, and a trust region constraint has been added.
We are using the models of the constraints to approximate the feasible region during each iteration:
\begin{align}
\feasiblek = \left\{x \in \Rn \big| \mcik(x) \le 0 \; \forall 1 \le i \le m \right\} \label{define_feasiblek}
\end{align}
Conceptually, the model functions are ``trusted'' only within a distance $ \dk $ of the current iterate $\xk$; so the trust-region subproblem restricts the length of step $s$ to be no larger than $\dk$.
To ensure that the model functions are good approximations of the true functions over the trust region, the sample points are typically chosen to lie within, or at least near, the trust-region.


We are specifically interested in applications where some of the black box functions cannot be evaluated outside the feasible region.
As in \cite{digabel2015taxonomy}, {\em quantifiable} means the functions can be evaluated at any point in $X$ and that the values returned for the constraint functions provide meaningful information about how close the point is to a constraint boundary.
We assume that the black-box functions return meaningful numerical values \emph{only} when evaluated at feasible points.
In this case, the constraints are called {\em partially quantifiable}.   
As such, we impose the requirement that all sample points must be feasible.

An important consideration in fitting the model functions is the ``geometry'' of the sample set.
This will be discussed in more detail in \cref{geometry}, but the key point is that the relative positions of the sample points within the trust region have a significant effect on the accuracy of the model functions over the trust region.
When the geometry of the sample set is poor, it is sometimes necessary to evaluate the functions at new points within the trust region to improve the geometry of the sample set.
It is well understood how to do this for unconstrained problems; but for constrained problems with all feasible sample points, some interesting challenges must be overcome.
In particular, ensuring feasibility limits the geometry of sample points.
We consider ellipsoidal and polyhedral sample region strategies to ensure sample points are feasible.

As a first step toward developing an algorithm to solve such problems, \emph{we first consider a simplified problem where all of the constraints are linear, then generalize to convex constraints}.
