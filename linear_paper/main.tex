\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{epsfig}
\usepackage{theorem}
\usepackage{longtable}

\usepackage{url}
\usepackage{moreverb}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{times}
\usepackage{titlesec}
\usepackage{ragged2e}
\usepackage{graphicx}
\usepackage{color}
\usepackage{comment}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\usepackage[normalem]{ulem} % For \sout
\usepackage[ruled]{algorithm2e}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

% \usepackage{hyperref}
\usepackage{xspace}
\usepackage{cite}
\usepackage{framed}
\usepackage{algpseudocode} 
\usepackage{longtable}
\usepackage[capitalise,nameinlink,noabbrev]{cleveref}
\usepackage{url}
\usepackage{etoolbox}
\usepackage{fullwidth}

\newbool{showcomments}
\booltrue{showcomments}% comment this to hide comments

\input{definitions}
\input{environment}
\newcommand{\outerfritr}{D_{\text{out}}}



\newcommand{\real}{\mathbb R}

\newcommand{\trialk}{{{s}^{(k)}}}



%=========================================

\title{Model-Based Trust Region Methods for Derivative-Free Optimization with Unrelaxable Linear Constraints}
\author{Trever Hallock and Stephen C. Billups}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\let\oldref\ref
\renewcommand{\ref}[1]{(\oldref{#1})}
\def\INCLUDEOMITTED{0}
\begin{document}


\maketitle

\begin{abstract}

We propose a model-based trust-region algorithm for constrained optimization problems with linear constraints in which derivatives of the objective function are not available and the objective function values outside the feasible region are not available.
In each iteration, the objective function is approximated by an interpolation model, which is then minimized over a trust region.
To ensure feasibility of all sample points and iterates, we consider two trust region strategies in which the trust regions are contained in the feasible region.
Computational results are presented on a suite of test problems.

\end{abstract}

\newpage

% \tableofcontents

\newpage
\section{TO DO}
\begin{enumerate}
\item Shorten literature review
\item Consider removing material on finding the maximum volume ellipsoid
\item Remove ellipsoid searches.  Instead, just use the one center defined in the analysis.  
\item Remove polyhedral trust region method.
\end{enumerate}
\section{Introduction}
Derivative-free optimization (DFO) refers to mathematical programs involving functions for which derivative information is not explicitly available.
Such problems arise, for example, when the functions are evaluated by simulations or by laboratory experiments.
Applications of DFO appear in many fields, including photo-injector optimization \cite{Neveu2017},
circuitry arrangements \cite{PLOSKAS201816}, machine learning \cite{KS2018}, volume optimization \cite{Cheng2017}, and reliability-based optimization \cite{Gao2017}.
In such applications, function evaluations are typically expensive, 
so it is sensible to invest significant computational resources to minimize the number of function evaluations required.

This work is aimed at developing algorithms to solve constrained optimization problems of the form 
\begin{align}
\begin{array}{ccl} \min_{x \in \Rn} & f(x) \\
\mbox{subject to} \quad & c_i(x) \le 0, &\quad \forall 1 \le i \le m,
\end{array}
\label{the_dfo_problem}
\end{align}
where 
% $\domain$ is a subset of $\Rn$, and
$f$ and $c_i$ for $1 \le i \le m$ are real-valued functions on $\Rn$ with at least one of these functions being a {\em black-box} function, meaning that derivatives cannot be evaluated directly.
We let the feasible set be represented as
\begin{align}
\feasible = \{x \in \Rn | c_i(x) \le 0, \; \forall 1 \le i \le m \}.
\end{align}

We are interested in developing {\em model-based}, {\em trust-region} algorithms for solving these problems.
Model-based methods work by constructing model functions to approximate the black box functions at each iteration.
The model functions are determined by fitting previously evaluated function values on a set of sample points.
In trust-region methods, the model functions are used to define a trust-region subproblem whose solution determines the next iterate.
For example, the trust-region subproblem might have the form
\begin{align*}
\begin{array}{ccl} \min_{\|s\| \le \dk}
 & \mfk \left(\xk+s\right) \\
\mbox{subject to} \quad & \mcik\left(\xk + s\right) \le 0 & \quad 1 \le i \le m, \\
& \|s\| \le \dk \\
\end{array}
\end{align*}
where $\xk$ is the current iterate, $\mfk$ is the model function approximating $f$, 
and $\mcik$ are the model functions approximating the constraint functions $c_i, \forall 1 \le i \le m$, and $\dk$ is the radius of the trust-region.
The key differences between the trust-region subproblem problem and the original are that all functions are replaced with their model functions, 
and a trust region constraint ($\|s\| \le \dk$) has been added.

%Note that we are using models of the constraint functions to approximate the feasible region during each iteration.  In particular, we define the {\em model feasible region} by
%\begin{align}
%\feasiblek = \left\{x \in \Rn \big| \mcik(x) \le 0 \quad \forall 1 \le i \le m \right\}.  \label{define_feasiblek}
%\end{align}



Conceptually, the model functions are ``trusted'' only within a distance $ \dk $ of the current iterate $\xk$; 
so the trust-region subproblem restricts the length of step $s$ to be no larger than $\dk$.
To ensure that the model functions are good approximations of the true functions over the trust region, 
the sample points are typically chosen to lie within the trust-region.

%
% {\em quantifiable} means the functions can be evaluated at any point in $\feasible$
% and that the values returned for the constraint functions provide meaningful information about how close the point is to a constraint boundary.
% This means the constraints
% For example, the authors of  apply derivative-free optimization to rapid-cycling synchrotron lattice design.
% The problem has a non-smooth objective and both linear and simulation based unrelaxable constraints.
% These constraints are unrelaxable, because simulation is not possible with overlapping synchrotron elements.
% In this case,  the constraints are called {\em unrelaxable}.
% \sbnote{Can we find an example of an unrelaxable constraint?}
We are specifically interested in applications where some of the black box functions cannot be evaluated outside the feasible region.  Constraints of this type can arise in several ways, such as when a simulation cannot be carried out on particular inputs.
For example, the authors of \cite{Padidar2021} optimize rapid-cycling synchroton lattice design,
but some overlapping synchrotron elements cannot be simulated.  Following the taxonomy in \cite{ledigabel2015taxonomy},  such constraints are called {\em unrelaxable}.    

For problems involving unrelaxable constraints,  we require all iterates and sample points to be feasible.  \replace{Notice that this feasibility requirement means that if the algorithm is stopped at any time, it will still produce a feasible output. }{}  As a first step toward developing algorithms to solve such problems,  this paper considers a simplified problem where all of the constraints are linear and unrelaxable; namely:
\begin{align}
\begin{array}{ccl} \min_{x \in \Rn} & f(x) \\
& \lca x \le \lcb, & 
\end{array}
\label{LD_dfo_problem}
\end{align}
where $\lca$ is an $m \times n$ matrix and $\lcb \in \Rm$.


An important consideration in fitting the model functions is the ``geometry'' of the sample set.
This will be discussed in more detail in \cref{geometry}, but the key point is that the relative positions of the sample points within the trust region have a significant effect on the accuracy of the model functions over the trust region.
When the geometry of the sample set is poor, it is sometimes necessary to evaluate the functions at new points within the trust region to improve the geometry of the sample set.
It is well understood how to do this for unconstrained problems, but for constrained problems
our requirement that the sample points must be feasible poses some interesting challenges to maintaining good geometry.   



We propose an algorithm for solving this problem whose main idea is to construct a feasible ellipsoid at each iteration that lies within the intersection of the feasible region and the current trust region.   We call this ellipsoid the {\em sample trust region}.
To choose well-poised sample points for this ellipsoidal region,  we adapt a model improvement algorithm presented in \cite{introduction_book} for spherical trust regions and establish error bounds on the accuracy of the model functions over this region.    

Our convergence analysis is based on an algorithmic framework presented \cite{Conejo:2013:GCT:2620806.2621814},  which describes a class of trust-region algorithms for convex constrained minimization without derivatives.   This framework assumes that a model of the objective function can be constructed at each iteration that satisfies certain accuracy assumptions, but does not specify how to construct such a model function.    Here, we show that the model functions constructed by our algorithm satisfy these assumptions.  Hence,  using the results from \cite{Conejo:2013:GCT:2620806.2621814}, we show that
the criticality measure for the iterates generated by our algorithm converges to zero.  In particular, any accumulation point of the iterates satisfies the Karush-Kuhn-Tucker first order optimality conditions.  




 

We then discuss several variants to improve on the algorithm, as well as provide numerical results.
 We present several variants of how to construct the feasible ellipsoid.
 We first show how to find the maximum volume ellipsoid contained within a polytope given a fixed center.
 We then explore several strategies for shifting the center of the ellipsoid.    
 

\paragraph{New paragraph about geometry}  In unconstrained optimization, it is typical and natural that the sample trust region be centered set at the current iterate.   Thus, much of the theory presented  
 in \cite{introduction_book} about the geometry of the sample set assumes that the sample points are chosen within a ball centered at the current iterate.  However, for constrained problems,  this is no longer a useful assumption.   In particular, when iterates are close to the boundary of the feasible region, it is advantageous to shift the center of the sample trust region away from the current iterate.     Because of this, we rework some of the standard results so that they don't require that one of the sample points be at the center of the sample trust region.


\section{Notation}
Throughout the thesis, we use the following notational conventions.
Any variables that depend on the iteration will be super-scripted by $k$.
For example, the $k$-th iterate is given by $\xk$,
and the model of the objective function for iteration $k$ is given by $\mfk$.
Subscripts on vectors are used as an index into the vector, while vectors in a sequence of vectors use superscripts:
that is, $\xki$ is the $i$-th component of the $k$-th vector in the sequence $\{\xk\}_k$.
We use $\proj_X(x) = \argmin_{x' \in X}\left\|x' - x\right\|$ to denote the projection of $x$ onto a convex set $X$.
For any $m \in \naturals$, we define $[m] = \left\{i \in \naturals | 1 \le i \le m\right\}$.

\paragraph*{Matrices.}
Matrices are denoted with capital letters.
The $i$-th row of the matrix $A$ is denoted $A_i$.
For any index set $S \subseteq \{i \in \naturals | 1 \le i \le m\}$, the $|S| \times n$ matrix formed by only using
rows of the $m\times n$ matrix $A$ from the set $S$ is $A_S$.
Let the condition number of a matrix $Q$ be denoted $\condition(Q)$.
% , while the $i$-th column is denoted $A_{\bullet i}$.
We use $e_i$ to denote the $i$-th unit vector and $e$ to denote the vector of all ones.
$B_k\left(c; \Delta\right)$ is the ball of radius $\Delta$ in the $k$ norm, centered at point $c$.  That is,
\begin{align}
\label{define_ball}
B_k\left(c; \Delta\right) = \left\{x \in \Rn \bigg | \left\|x - c\right\|_k \le \Delta \right\}.
\end{align}
Note that some of the common norms are:
\begin{align*}
\|x\|_{\infty} = \max_{1\le i\le n}|x_i|, \quad
\|x\|_{2} = \sqrt{\sum_{i=1}^n x_i^2}, \quad \textrm{and} \quad
\|x\|_1 = \sum_{i = 1}^n |x_i|.
\end{align*}
When a norm is presented without a subscript, it is assumed to be the $2$ norm: $\|x\| = \|x\|_2$ for any $x \in \Rn$.
For matrices, we will also use the Frobenius norm $\left\|\cdot\right\|_F$ which is $\left\|A\right\|_F = \sqrt{\sum_i\sum_jA_{i, j}^2}$.
% The norm of matrices
% Also, if $A$ is an $n \times n$ matrix, $\|A\|

\paragraph*{Sets.}
The complement of a set $S$ is denoted as $\bar S$.
Define a point $x$ subtracted from a set $S$ as $S - x = \left\{s \in \Rn | s - x \in S\right\}$.
Set addition is $X + Y = \left\{x + y | x \in X, y \in Y\right\}$.

$\delta_{i,j}$ is the Kronecker delta, $\delta_{i, j} = \begin{cases} 1 & \textrm{if} \; i = j \\ 0 & \textrm{if} \; i \ne j \end{cases}$.
We define the positive part of a real number to be
\begin{align*}
a^+ = \begin{cases} a & \textrm{if} \quad a \ge 0 \\ 0 & \textrm{otherwise} \end{cases}.\\
\end{align*}

% For any matrix $A$, we let $A^{\dagger}$ be the Moore-Penrose inverse.


\section{Background}
\subsection{Literature Review}

\label{literature_review}


% Recently, there has been a growth in applications of derivative-free optimization.
% Such applications include

% Model based, trust region, I think no constraints, maybe multi-objective:
% photo-injector optimization \cite{Neveu2017}.

% Direct search, binary constraints, mixed integer (nomad, midaco, glcSolve, CMAES (stochastic))
% circuitry arrangements \cite{PLOSKAS201816},

% For paralellizable methods, kalman filter methods, optimizing networks
% machine learning \cite{KS2018}

% Trust region based, reliability surrogate constraints
% and reliability based optimization \cite{Gao2017}.

% parallel algorim, compares gradient based and dfo, nelder-mead
% volume optimization \cite{Cheng2017},

Several books and survey articles  provide good introductions to the field of derivative-free optimization.
Within \cite{introduction_book}, derivative-free methods are developed in detail.
This is the first textbook devoted to derivative-free optimization.
It contains an explanation of how to ensure good sample set geometry and introduces the concept of 
poisedness for unconstrained problems, and it also covers other direct-search and line-search methods.   A review of derivative-free algorithms and software libraries can be found in \cite{miguel_review}.
This compares several software libraries and reviews the development of derivative-free optimization since it started.
Other recent reviews can be found in \cite{custodio_review2} and \cite{larson_menickelly_wild_2019}.

Most  algorithms for derivative-free optimization fall into two main categories: direct-search methods and model-based methods.   Direct-search methods use comparatively simple strategies to explore the solution space, using only the relative ranks of function values rather than their numerical values.     Early direct search methods for unconstrained optimization include coordinate descent \cite{fermi.metropolis:numerical},  the Nelder-Mead algorithm \cite{10.1093/comjnl/7.4.308},  
and pattern search methods \cite {hooke.jeeves:direct, kolda.lewis.ea:optimization}.   Generalizations of pattern-search methods include the GPS method \cite{torczon:convergence, Audet2002AnalysisOG} and the mesh adaptive direct search (MADS) algorithm \cite{audet.dennis:mesh, abramson.audet:convergence}.

Model-based methods guide the search using surrogate models of the black-box functions, which are constructed by fitting function values on a set of sample points.    Among the more commonly used model functions are linear and quadratic interpolation models \cite{ conn.scheinberg.ea:recent, powell:uobyqa,powell:newuoa}  and radial-basis function interpolation models \cite{oeuvray.bierlaire:boosters,wild.regis.ea:orbit,wild.shoemaker:global}.

The use of model functions allows curvature information to be incorporated into the search.  As such, model-based methods tend to be more efficient than direct-search methods when the black box functions are smooth.  In contrast, direct-search methods can be better suited for handling nonsmooth or noisy functions.   They are also more straightforward to implement, and are easier to parallelize.

Hybrid methods, which incorporate ideas from both direct-search and model-based methods, have also been proposed.    Some examples are described in \cite{booker.dennis.ea:rigorous}, \cite{thi.vaz.ea:optimizing}, and \cite{custodio.vicente:using}.

\paragraph*{Constrained derivative-free algorithms.}
To discuss methods for constrained derivative-free optimization,  we follow the constraint taxonomy      
of Le~Digabel and Wild \cite{ledigabel2015taxonomy} and distinguish between whether constraints are {\em relaxable} or {\em unrelaxable}.    An unrelaxable constraint is one that {\em must} be satisfied in order to obtain meaningful information about the objective function and/or constraint functions.    Thus algorithms for unrelaxable constraints can use function evaluations only for feasible points.   We also distinguish between whether constraints are {\em algebraic} or {\em black-box}.    A constraint is algebraic if the constraint functions can be computed algebraically,  whereas a {\em black-box constraint} can only be evaluated by running simulation software.    

\paragraph*{Relaxable constraints.}   The easiest class of constraints to deal with are the relaxable algebraic constraints.   In this case, ideas from classical nonlinear programming methods can easily be adapted to the derivative-free setting.  Some examples include 
 penalty methods \cite{lewis.torczon:globally, lewis.torczon:direct, bueno.friedlander.ea:inexact},   and filter methods \cite{brekelmans.driessen.ea:constrained, ferreira.karas.ea:global}.     
Both penalty methods and filter methods allow iterates to violate constraints, requiring feasibility only in the limit.  As such, they are viable approaches only when the constraints are relaxable.    
 
For relaxable black-box constraints,  several methods have been proposed that allow the black-box functions to be evaluated at infeasible points.  These include penalty methods
\cite{audet.dennis:progressive, liuzzi.lucidi:derivative-free, liuzzi.lucidi.ea:sequential,fasano.liuzzi.ea:linesearch,diniz-ehrhardt.martinez.ea:derivative-free,picheny2016bayesian}, filter methods \cite{audet.dennis:pattern, pourmohamad:combining,echebest.schuverdt.ea:inexact},  and funnel methods \cite{sampaio.toint:derivative-free,sampaio.toint:numerical}.

Another approach is to construct algebraic models of the constraint functions and then require iterates to be feasible with respect to these modelled constraints.
In \cite{glass.cooper:sequential},  linear models of nearly active constraint functions are constructed and the iterates are accepted only if they are feasible with respect to these modeled constraints.     A similar strategy is employed in the COBYLA method of Powell \cite{powell:direct}, which builds linear models of the objective and constraint functions based on a common set of sample points.    
A variant of the MADS algorithm is proposed in \cite{burmen.olensek.ea:mesh} which uses linear regression models of the constraint functions to guide the choice of search and poll steps.   In \cite{Troltzsch2016},  the classic sequential quadratic programming algorithm is implemented for equality-based constraints.




%Also, \cite{Gao2018} presents  an algorithm for linearly constrained derivative-free optimization that uses a backtracking technique to minimize the number of evaluations required.



\paragraph*{Unrelaxable algebraic constraints.}  

 An algebraic constraint function can always be evaluated, so the only way it is considered unrelaxable is if a black-box function (either the objective or some other constraint function) cannot be evaluated when the constraint is violated.
Note that it is always possible to determine whether a point satisfies an algebraic constraint prior to attempting to evaluate any black-box functions.  As such, it is relatively straightforward to modify direct-search methods to guarantee that only feasible points are considered.     
Many direct-search methods have been proposed that take this approach
\cite{box:new, spendley.hext.ea:sequential,may:linearly,may:solving,lewis.torczon:globally,lewis.torczon:direct,
vandenberghen:condor, lewis.torczon:pattern2000,lucidi.sciandrone:derivative-free,chandramouli.narayanan:scaled,kolda.lewis.ea:stationarity,lucidi.sciandrone.ea:objective, 
audet.ledigabel.ea:linear,gratton.royer.ea:direct2019,gratton.royer.ea:direct2015}
%
% \cite{box:new} \cite{spendley.hext.ea:sequential}, \cite{may:linearly}, \cite{may:solving},\cite{lewis.torczon:globally},  \cite{lewis.torczon:direct}, \cite{vandenberghen:condor}, \cite{lewis.torczon:pattern2000} \cite{lucidi.sciandrone:derivative-free}, \cite{chandramouli.narayanan:scaled},  \cite{kolda.lewis.ea:stationarity}, \cite{lucidi.sciandrone.ea:objective}, 
%\cite{audet.ledigabel.ea:linear},\cite{gratton.royer.ea:direct2019}, \cite{gratton.royer.ea:direct2015}
  
Developing model-based algorithms for unrelaxable constraints is complicated by the fact that the choice of sample points impacts the accuracy of the model functions.     Thus, when restrictions on the choice of sample points are imposed,  it can be difficult to ensure that the model functions are sufficiently accurate to guarantee convergence to a stationary point.    (see \cref{sec:polyhedral} for a more detailed explanation of this difficulty).   In the case of unrelaxable bound constraints, the restrictions on the sample points are not too difficult to mitigate.     The BOBYQA algorithm \cite{powell:BOBYQA} ensures that all points at which the objective function are evaluated satisfy the bound constraints, while still maintaining sufficient model accuracy to guarantee convergence.    In \cite{arouxet.echebest.ea:active-set},  an active set method is used when solving the bound-constrained trust-region subproblems.    In \cite{wild:derivative-free}, Wild proposed a radial basis function method for bound constraints, which enforces the bounds when selecting sample points in the model improvement algorithm and when solving the trust region subproblems.   In \cite{gratton.toint.ea:active-set}, Gratton et al. present a method which restricts the construction of the model functions to subspaces defined by nearly active bound constraints.

There has also been some progress in developing model-based methods for unrelaxable linear constraints.   In  \cite{gumma.hashim.ea:derivative-free},  Gumma et al.  propose the LCOBYQA algorithm which is an extension of Powell's NEWUOA algorithm that enforces the linear constraints both when solving the trust region subproblems and when choosing sample points for constructing the model functions.    However, no convergence analysis is provided for the method.   

\paragraph*{Unrelaxable black-box constraints.}   
We now turn our attention to the hardest case--that of unrelaxable black-box constraints.   In this case,  it is not possible to guarantee that black-box function evaluations will never be attempted at infeasible points.   However, it is desireable to minimize the occurrence of such infeasible attempts.  

There are several strategies for avoiding infeasible evaluations.
The authors of \cite{Galvan2021} use a reformulation strategy by moving the constraints into the objective.
Their work relies on a projection operator to avoid infeasible evaluations and handles non-smooth convex constraints.
The authors of \cite{NOWPAC2014} use a path-augmentation strategy to ensure trial points are feasible.
This is done with a local convexification of the constraints that parameterize a buffer of the constraints.
The authors of \cite{BMNORW2020} apply DFO to optimize the Fayans energy density functional, avoiding possible infeasible evaluations by altering the objective function to include a projection onto an $L_1$ ball.
In \cite{CONORBIT15}, the authors develop a model-based trust region algorithm that uses an envelope to avoid infeasible trial point evaluations.
The algorithm presented within \cite{Conejo2015} is also a model-based trust region method, and it ensures each iterate is feasible, although sample points may not be.
More recently, \cite{Brilli2021interior} uses an interior point algorithm to solve derivative-free problems with unrelaxable, black-box constraints.

Of particular importance for our work is \cite{Conejo:2013:GCT:2620806.2621814}.
This reference provides an elegant convergence proof for a class of algorithms when the constraints are convex.
Our analysis implements abstractions made in this paper and shows the implementation satisfies their requirements.

%We are not aware of any algorithms that use only feasible points to build models of the black-box constraint functions.   However,  a number of algorithms simultaneously handle unrelaxable algebraic constraints and relaxable black-box constraints.  Thus,  \cite{regis:constrained,augustin.marzouk:nowpac,augustin.marzouk:trust-region,regis.ea:conorbit}.



%While care is taken to maintain the non-degeneracy of the sample points,  Powell notes that  ``Our %knowledge of the convergence properties for the algorithm is slight.'' 




\pagebreak
\subsection{Model-Based Trust-Region Methods for DFO}

The main idea of model-based, trust-region methods is that trial points are selected at each iteration by solving a trust-region subproblem.  
Each subproblem has the form 
\[ \begin{array}{ll} \min_{s \in \Rn} & m_f^{(k)}\left(\xk + s\right) \\ 
\st & \xk+s \in \feasiblek \\
& \norm{s} \le \Delta_k
\end{array} \]
where $m_f^{(k)}$ is a model function approximating the objective $f$, $\dk$ is the trust region radius,
and $\feasiblek$ is an approximation of the feasible region.
The solution $\sk$ of the trust-region subproblem determines a {\em trial point} $\xk + \sk$.  
The objective function and constraints are then evaluated at the trial point to determine whether to accept the trial point.
If the trial point is rejected, the trust region radius is decreased and a new trial point is computed by solving a revised trust-region subproblem.     
If the trial point is accepted, then the trust region radius may be increased or decreased for the next iteration 
depending on how well the sample point improved upon the previous iterate.
This will be discussed in \cref{rhosection}.


\subsection{Assessing Model Accuracy and Trust Region Radius Management}

\label{rhosection}

% We now discuss background material for components of our algorithm.
In trust region methods, each iteration that evaluates a trial point must also test the accuracy of the model functions.
To test the accuracy, we calculate a quantity
\begin{align}
\label{define_rhok}
\rk = \frac{f(\xk) - f(\xk+\sk)}{\mfk(\xk) - \mfk(\xk+\sk)},
\end{align}
which measures the actual improvement of the trial point $\xk+\sk$ divided by the predicted improvement.  If $\rk$ is negative, the trial point is rejected and the trust region radius is decreased.   On the other hand, if the trial point is accepted, the trust region radius for the next iteration may still be decreased since 
a small value of $\rk$ implies that the model functions are not sufficiently accurate.   For larger values of $\rk$ the trial point is accepted and the trust region radius may be increased.
This strategy has been widely used within trust region frameworks such as \cite{Conn:2000:TM:357813} and within a derivative-free context \cite{introduction_book}.

To implement the above strategy,  we define parameters
% \label{define_the_gammas}
% \label{define_the_omegas}
$
0 < \gammasm < \gammabi \le 1
$
as thresholds on $\rk$ and
$
0 < \omegadec < 1 \le \omegainc
$
% $\omegadec, \omegainc$
as decrement and increment factors to determine the trust region update policy.
That is, when $\rk < \gammasm$, the trust region is decreased by a factor of $\omegadec$, and the trust region is increased by a factor of $\omegainc$
during some iterations in which $\rk > \gammabi$.


\subsection{Interpolation-Based Models}

\label{interpolation}

Model-based methods for derivative-free optimization construct models of a function $f(x)$ from a family of functions spanned by a set of $p + 1 \in \naturals$ basis functions  $\Phi = \{\phi_0, \phi_1, \ldots, \phi_p\}$. Each member of this family has the form $\mf(x) = \sum_{i=0}^p\alpha_i\phi_i(x)$ for some scalar coefficients $\alpha_i, i \in \{0, \ldots, p\}$.

We use interpolation to choose the coefficients $\alpha = [\alpha_0, \ldots, \alpha_p]^T$ so that $\mfk$ agrees with $f$ on a set of $p+1$ sample points $Y = \{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\}$ at which the function $f$ has been evaluated.
Thus, the coefficients $\alpha$ must satisfy the \emph{interpolation condition}
\begin{align}
\label{interpolation_condition}
\mf(y^{(i)}) = \sum^p_{j=0}\alpha_j\phi_j(y^{(i)}) = f(y^{(i)}) \quad \forall \quad 0 \le i \le p.
\end{align}

% We can also write this equation in matrix form.
This equation can be written more compactly in the form
\begin{align}
\label{matrix_form}
V \alpha = \bar{f},
\end{align}
where $\bar{f} = [f(y^{(0)}), f(y^{(1)}), \ldots, f(y^{(p)})]^T$ and the Vandermonde matrix $V$ is defined by 

\begin{align}
\label{vandermonde}
V=M(\Phi,Y) :=
\begin{bmatrix}
    \phi_0(y^{(0)})      & \phi_1(y^{(0)})       & \ldots & \phi_{p}(y^{(0)})      \\
    \phi_0(y^{(1)})      & \phi_1(y^{(1)})       & \dots  & \phi_{p}(y^{(1)})      \\
                     &                   & \vdots &                    \\
    \phi_0(y^{(p)})    & \phi_1(y^{(p)})     & \ldots & \phi_{p}(y^{{(p)}})
\end{bmatrix}.
\end{align}


The interpolation equation \cref{matrix_form} has a unique solution if and only if $V$ is non-singular.
In this case, we say that the sample set $Y$ is \emph{poised} for interpolation with respect to $\Phi$. 
However, even when $V$ is non-singular but ``close" to singular, as measured by its condition number, 
the model's approximation may become inaccurate.


\subsection{Sample Set Geometry}

\label{geometry}
The term \emph{geometry} describes how the distribution of points in the sample set $Y$ affects the accuracy of the model function.       In the case of polynomial model functions, a rigorous analysis of model accuracy can be performed using \emph{Lagrange polynomials}.
Let the space of polynomials on $\Rn$ with degree less than or equal to $d$ be denoted $\polydn$ and have dimension $p+1$.
The Lagrange polynomials $l_0, l_1, \ldots, l_p$ for the sample set $Y$ are a basis of $\polydn$ such that
\begin{align}
l_i(y^{(j)}) = \delta_{i,j}
\end{align}
where $\delta_{i,j} = \{0 \;\text{if}\; i\ne j,\; 1 \;\text{if} \; i = j \}$ is the Kronecker-delta function.
%For example, after this change of basis, note that the Vandermonde matrix becomes the identity matrix.
Thus, as shown in \cite{introduction_book}, we can conveniently write
\begin{align}
\label{reg}
\mf(x) = \sum^p_{j=0}f(y^{(i)})l_i(x).
\end{align}


We say that a set $Y$ is \emph{$\Lambda$-poised} for a fixed constant $\Lambda$ with respect to a basis $\Phi$ on the set 
$B \subset\Rn$ if and only if the Lagrange polynomials $l_i$ associated with $Y$ satisfy
\begin{align}
\Lambda \ge \max_{0\le i\le p}\max_{x\in B}|l_i(x)|.
\end{align}
% \color{red}
% Frequently, the basis $\Phi$ is taken to be the monomial basis of order $d \in \naturals$:
% \begin{align*}
% \phi_0(x) = 1, 
% \phi_1(x) = x_1,
% \phi_2(x) = x_2, 
% \ldots, 
% \phi_{n}(x) = x_n, \\
% \phi_{1+n}(x) = x_1^2,
% \phi_{2+n}(x) = x_1x_2, 
% \phi_{3+n}(x) = x_1x_3, 
% \ldots, 
% \phi_{\frac{(n+1)(n+1)}{2}}(x) = x_n^2, \\
% \phi_{\frac{(n+1)(n+2)}{2} + 1}(x) = x_1^3, 
% \ldots, 
% \phi_{p}(x) = x_n^d
% \end{align*}
% For example, with $n=2$, and $d=2$ we have $p+1=6$ and
% \begin{align*}
% \phi_0(x) = 1,
% \phi_1(x) = x_1,
% \phi_2(x) = x_2,
% \phi_3(x) = x_1^2,
% \phi_4(x) = x_1x_2,
% \phi_5(x) = x_2^2.
% \end{align*}
% \color{black}
In the case of interpolation over the quadratic polynomials, 
$ \mathcal{P}^2_n$, we say that $Y$ is \emph{$\Lambda$-poised for quadratic interpolation}.

% \color{red}
% The concept of $\Lambda$-poisedness yields the following error bounds, as shown in
%  \cite[Theorem 3.16]{introduction_book}:

% \begin{theorem}
% \label{quadratic_errors}

% Let $Y = \{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\} \subset \Rn$ be a set of $p+1=\frac{(n+1)(n+2)}{2}$
% sample points and $\Delta = \max_{1 \le j \le p} \|y^{(j)}-y^{(0)}\|$.
% Suppose that $Y$ is $\Lambda$-poised for quadratic interpolation on $B_2(y^{(0)}; \Delta)$.
% Then, for any constant $L > 0$, there exist constants $\kappa_{h}, \kappa_{g}$, and $\kappa_{f}$
% such that the following error bounds hold for any function $f:\Rn \rightarrow \reals$
% that is $LC^2$ with Lipschitz constant $L$ on an open set containing $B_2(y^{(0)};\Delta)$:
% 
% \begin{align}
% \|\nabla^2 f(y) - \nabla^2 m_f(y)\| \le \kappa_{h} \Delta \quad \forall y \in B_2(y^{(0)}; \Delta), \\
% \|\nabla f(y) - \nabla m_f(y)\| \le \kappa_{g} \Delta^2 \quad \forall y \in B_2(y^{(0)}; \Delta),  \\
% |f(y) - m_f(y) | \le \kappa_{f} \Delta^3 \quad \forall y \in B_2(y^{(0)}; \Delta), 
% \end{align}
% where $m_f$ is the quadratic model function interpolating $f$ on $Y$.
% \end{theorem}
% 
% \color{black}

As shown in \cite[Lemmas 3.8 and 3.9], the poisedness constant $\Lambda$ in the above definition does not depend on the scaling of the sample set and it is invariant with respect to a shift of coordinates.    Thus, for any vector $\bar{y} \in \Rn$ and positive scalar $\Delta > 0$,  a sample set $Y=\left\{ y^{(0)}, \ldots,y^{(p)}\right\}$ is $\Lambda$-poised on a set $B$ if and only if the shifted and scaled sample set 
$\hat{Y} := \frac{1}{\Delta}\left(Y-\bar{y}\right)$ is $\Lambda$-poised on set $\hat{B} = 
\frac{1}{\Delta} \left(B-\bar{y}\right)$.  

The analysis presented in \cite{introduction_book} constructs $\hat{Y}$ by choosing $\bar{y} = y^{(0)}$ and $\Delta = \max_{1 \le i \le p} \| y^{(i)}-y^{(0)}\|$.  The resulting sample set $\hat{Y}$  is contained in the ball of radius one centered at $\hat{y}^{(0)} = 0$ and has at least one point on the boundary of the ball.     The following result establishes a relationship between the $\Lambda$-poisedness of $\hat{Y}$ on the ball $B_2(0;1)$ (hence also of $Y$ on $B_2(y^{(0)};\Delta)$ and the condition number of the Vandermonde matrix $\hat{M} = M(\bar{\Phi},\hat{Y})$, where $\bar{\Phi}$ denotes the monomial basis for $\mathcal{P}^2_n$.  Specifically,
\begin{align}
\label{define_monomial}
\bar{\Phi} = \{ \bar{\phi}_0, \ldots, \bar{\phi}_p\} =\{1, x_1, \ldots, x_n, x_1^2/2, \ldots x_n^2/2,x_1 x_2, \ldots, x_{n-1}x_{n}\}.
\end{align}

\begin{theorem}
\label{Lambda_poised_error_bounds}

(\cite[Theorem 3.14]{introduction_book})
Let $\hat{M} = M(\bar{\Phi},\hat{Y})$, and $p + 1 = \frac{(n+1)(n+2)}{2}$.
If $\hat{M}$ is non-singular and $\left\|\hat{M}^{-1}\right\|_2 \le \Lambda$,   
then the set $\hat{Y}$ is $\Lambda  \sqrt{p+1}$-poised for quadratic interpolation on the unit ball $B_2(0;1)$.  
Conversely, if the set $\hat{Y}$ is $\Lambda$-poised for quadratic interpolation on the unit ball, 
then $\left\|\hat{M}^{-1}\right\|_2 \le \theta \Lambda \sqrt{p+1}$, where $\theta > 0$ is a 
constant dependent on $n$ but independent of $\hat{Y}$ and $\Lambda$.
\end{theorem}

This approach is sensible for unconstrained optimization, where we typically choose $y^{(0)}$ to be the current iterate and we are interested in constructing sample sets that are well-poised over the trust region $B_2(y^{(0)};\Delta)$.    However, for constrained optimization, it is disadvantageous to require the current iterate to be at the center of our sample trust region.    We therefore consider a different transformation by specifying an arbitrary center $\bar{y}$ and radius $\Delta$.    We have the following results:

\begin{theorem}
\label{Lambda_poised_error_bounds_delta}

Let $\Delta >0$, $Y$ be a sample set with $Y \subset B_2(0;\Delta)$ and let $M=M(\bar{\Phi},Y)$ where $\bar{\Phi}$ is the monomial basis \cref{define_monomial}.
If $M$ is non-singular, and $\left\|{M^{-1}}\right\|_2 \le \Lambda$, then $Y$ is $\hat{\Lambda}$-poised in $B_2(0;\Delta)$,
where $\hat{\Lambda} = \Lambda \left(p+1\right)^{-\frac 1 2}\max\left\{1, \Delta, \frac 1 2 \Delta^2\right\}$.
\end{theorem}

\begin{proof}

Let $x \in B_2(0;\Delta)$ be arbitrary and let $\ell(x) = (\ell_0(x), \ldots, \ell_p(x))^T$.
As shown in \cite{introduction_book}, we can write $\ell(x) = M^{-T}\bar{\phi}(x)$, 
where $\bar{\phi}(x) = (\bar{\phi}_0(x), \ldots, \bar{\phi}_p(x))$.
Thus,
\begin{align*}
\norm{\ell(x)}_{\infty} & \le \norm{M^{-T}}_{\infty} \norm{\bar{\phi(x)}}_{\infty} \\
& \le \left(p+1\right)^{-\frac 1 2} \norm{M^{-1}}_2 \norm{\bar{\phi}(x)}_{\infty} \\
& \le \Lambda \left(p+1\right)^{-\frac 1 2} \max\left\{1, |x_1|, \ldots,|x_n|, \frac 1 2 x_1^2, \ldots, \frac 1 2 x_n^2, x_1x_2, \ldots, x_{n-1}x_n\right\}\\
& \le \Lambda \left(p+1\right)^{-\frac 1 2}  \max\left\{1, \Delta, \frac 1 2 \Delta^2\right\} = \hat{\Lambda}.
\end{align*}

\end{proof}


To show the converse, we use the two auxilary results are found in \cite[Lemma 3.10]{introduction_book} and \cite[Lemma 3.13]{introduction_book}.
\begin{lemma}
\label[lemma]{lemma_3_10}
Let $\bar \Phi$ be the monomial basis \cref{define_monomial}.
There exists a number $\sigma_{\infty} > 0$ such that, for any choice of $v$ satisfying $\|v\|_{\infty} = 1$,
there exists a $y \in B_2(0; 1)$ such that $\left|v^T\bar \Phi(y)\right| \ge \sigma_{\infty}$.
\end{lemma}

\begin{lemma}
\label[lemma]{lemma_3_13}
Let $w$ be a normalized right-singular vector of a nonsingular $n \times n$ matrix $A$ corresponding to its largest singular value.
Then, for any vector $r \in \Rn$,
\begin{align*}
\|Ar\| \ge |w^T r| \|A\|.
\end{align*}
\end{lemma}

\begin{lemma}
\label[lemma]{scale_the_radius}
Let $\bar \Phi$ be the monomial basis \cref{define_monomial}.
Suppose that a set $Y \subseteq B_2(0; \Delta)$ of $p+1 = \frac{(n+1)(n+2)}2$ points is $\Lambda$ poised over the ball $B_2(0; \Delta)$.
Let $\hat Y = \frac 1 {\Delta} Y$ be the scaled sample set.
Then there exists a constant $\kappa_{\Lambda}$ depending only on $p$ such that 
$ M\left(\bar \Phi, \hat Y\right)$ as defined in \cref{vandermonde}, satisfies
$\left\| M\left(\bar \Phi, \hat Y\right)^{-1}\right\| \le \kappa_{\Lambda} \Lambda$.
\end{lemma}

\begin{proof}
% By \cref{Lambda_poised_error_bounds_delta} and $\delta \le 1$, we must only bound $\|M^{-1}\left(\bar \Phi, Y\right)\|$
% where $\bar{\Phi}$ is the monomial basis \cref{define_monomial}.
Because $\Lambda$-poisedness is scale invariant (this is an immediate consequence of \cite[Lemma 3.8]{introduction_book}), 
$\hat Y$ is $\Lambda$-poised on $B(0, 1)$.
Let $v$ be a right singular vector of $M^{-1}\left(\bar \Phi, Y\right)$ 
corresponding to its largest singular value normalized so that $\left\|v\right\|_{\infty} = 1$.
We know from \cref{lemma_3_10} that there exists $y \in B_2\left(0; 1\right)$ such that
$\left| v^T \bar {\Phi}(y) \right| \ge {\sigma_{\infty}}$.
Then, because $\hat Y$ is $\Lambda$-poised on $B_2(0; 1)$, we have that 
\begin{align*}
\Lambda 
\ge \left\|l(y)\right\|_{\infty} 
= \left\|M\left(\bar \Phi, Y\right)^{-T} \bar \Phi(y)\right\|_{\infty}
\ge \left(p+1\right)^{-\frac1 2 }\left\|M\left(\bar \Phi, \hat Y\right)^{-T} \bar{\Phi}(y)\right\|.
\end{align*}
By applying \cref{lemma_3_13} with $A\gets{\bar M}\left(\bar \Phi, \hat Y\right)^{-T}$, $w \gets v$, and $r \gets \bar \Phi(y)$, we have
\begin{align*}
\Lambda 
\ge \left(p+1\right)^{-\frac1 2 }\left\|M\left(\bar \Phi, \hat Y\right)^{-T} \bar{\Phi}(y)\right\|
&\ge \left(p+1\right)^{-\frac1 2 }|v^T \bar \Phi(y)| \left\|M\left(\bar \Phi, Y\right)^{-T}\right\| \\
&\ge \left(p+1\right)^{-\frac1 2 }\sigma_{\infty} \left\|M\left(\bar \Phi, Y\right)^{-T}\right\|.
\end{align*}
The conclusion follows with $\kappa_{\Lambda} = \frac {\sqrt{p+1}}{\sigma_{\infty}}$.

\end{proof}


Another limitation of \cref{Lambda_poised_error_bounds} is its requirement to have a point evaluated at the origin.
We remove this assumption in \cref{3_16_replacement} by performing the same analysis as in \cite[Theorem 3.16]{introduction_book}.
First, we state the following lemma, found in \cite[Lemma 4.1.14]{dennisschnabel1983}.

\begin{theorem}
\label{4_1_14}
Let $f : \Rn \to \reals$ be twice continuously differentiable in an open convex set $D \subset \Rn$,
and let $\nabla^2 f(x)$ be Lipschitz continuous in $D$ with constant $\gamma$.
Then, for any $x + p\in D$,
\begin{align*}
\left|f(x + p) - \left(f(x) + \nabla f(x)^T p + \frac 1 2 p^T \nabla^2 f(x)p\right) \right|
\le \frac {\gamma} 6 \left\|p\right\|^3.
\end{align*}
\end{theorem}

\begin{theorem}
\label{3_16_replacement}
Suppose that $f$ is twice continuously differentiable, and has a Lipschitz continuous Hessian with constant $\liphess$.
For some $\Delta > 0$, let $Y = \left\{y^{(0)}, y^{(1)}, \ldots y^{(p)} \right\}$ be a set of
$p+1=\frac{(n+1)(n+2)}{2}$ points contained in $B_2\left(0; \Delta\right)$.
% , where $p +1 $ is the dimension of $\polydn$.
For some $c \in \reals, g \in \Rn, H \in \reals^{n \times n}$, consider a quadratic model $m(y) = c + g^T y + \frac 1 2 y^T H y$  satisfying
\begin{align}
f\left(y^{(i)}\right) = m\left(y^{(i)}\right) \quad \forall 0 \le i \le p. \label{nce_interpolation_condition}
\end{align}
Let $M(\bar \Phi,Y)$ be constructed as in \cref{vandermonde} and $\bar \Phi$ is the monomial basis \cref{define_monomial}.
Suppose that $M(\bar \Phi,Y)$ is non-singular, and define the scaled matrix
\begin{align}
\hat M\left(\bar \Phi, Y\right) = M\left(\bar \Phi, \frac 1 {\Delta} Y\right) = M\left(\bar \Phi,Y\right) \begin{pmatrix}
1 & 0 & 0 \\
0 & \Delta^{-1} I_n & 0 \\
0 & 0 & \Delta^{-2} I_{n + \frac{n(n-1)}{2}}
\end{pmatrix}. \label{nce_scale}
\end{align}
Then, there exist constants $\kappa_f, \kappa_g, \kappa_h>0$ that depend only on $p$ and $\liphess$ such that
for any $y \in B_2\left(0; \Delta\right)$:
\begin{align}
\left|m(y) - f(y)\right| &\le \kappa_f \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta^3, \label{error_in_function}  \\
\left\|\nabla m(y) - \nabla f(y)\right\| &\le \kappa_g \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2\Delta^2, \label{error_in_gradient} \\
\left\|\nabla^2 m(y) - \nabla^2 f(y)\right\| &\le \kappa_h \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2\Delta. \label{error_in_hessian}
\end{align}
\end{theorem}

\begin{proof}
Let $y \in B_2(0; \Delta)$.
Let us define error functions $e_f$, $e_g$ and $e_h$ so that
\begin{align}
m(y) = c + g^T y + \frac 1 2 y^T H y = f(y) + e_f(y) \label{define_e_f}, \\
\nabla m(y) = g + H y = \nabla f(y) + e_g(y), \nonumber \\
\nabla^2 m(y) = H = \nabla^2 f(y) + e_h(y). \nonumber
\end{align}
For a fixed $0 \le i \le p$, we can subtract \cref{define_e_f} from \cref{nce_interpolation_condition} to find that
\begin{align}
f\left(y^{(i)}\right) - f(y) - e_f(y)
= m\left(y^{(i)}\right) - m(y) \nonumber \\
= \left(y^{(i)} - y\right)^Tg + \frac 1 2 \left(y^{(i)}\right)^T H \left(y^{(i)}\right) - \frac 1 2 y^T H y \nonumber \\
= \left(y^{(i)} - y\right)^T g  + \frac 1 2 \left(y^{(i)} - y\right)^T H \left(y^{(i)} - y\right) + \left(y^{(i)} - y\right)^TH y. \label{nec_eqn2}
\end{align}
% With
% \begin{align*}
% e_T(x; y) = \sum_{
% \substack{0 \le j,k,l \le n \\ j \le k \le l}}
% \frac{\partial^3}{\partial_{x_j}\partial_{x_k}\partial_{x_l}}f(y)
% \frac{(x_j - y_j)(x_k - y_k)(x_l - y_l)}{(\delta_j^k + \delta_j^l + \delta_k^l)!},
% \end{align*}
By defining
\begin{align*}
e^{(i)}_O(y) = 
f\left(y^{(i)}\right) - \left[f(y) + \nabla f(y)^T \left(y^{(i)} - y\right) + \frac 1 2 \left(y^{(i)} - y\right)^T \nabla^2 f(y) \left(y^{(i)} - y\right)\right],
\end{align*}
we can use \cref{4_1_14} with $\gamma = \liphess$ and $p = y^{(i)} - y$ to conclude
\begin{align}
\left|e^{(i)}_O\left(y\right) \right| \le \frac 1 6 \liphess \left\|y^{(i)} - y\right\|^3 \le \frac 4 3 \liphess \Delta^3 \label{nce_bound_rhs}.
\end{align}
Furthermore, we notice that
\begin{align*}
f\left(y^{(i)}\right) - f(y)
= \nabla f(y)^T \left(y^{(i)} - y\right) + \frac 1 2 \left(y^{(i)} - y\right)^T \nabla^2 f(y) \left(y^{(i)} - y\right) + e^{(i)}_O\left(y\right) \\
= \left(y^{(i)} - y\right)^T \left(Hy + g - e_g(y)\right) + \frac 1 2 \left(y^{(i)} - y\right)^T \nabla^2 f(y) \left(y^{(i)} - y\right) + e^{(i)}_O\left(y\right).
\end{align*}
% where we know by \cite[Lemma 4.1.14]{dennisschnabel1983} that $e_O$ is a difference of two terms that
% can be bounded by can be bounded by $\frac 1 6 \liphess \left\|y^{(i)} - y\right\|^3$ and $\frac 1 6 \liphess \left\|y\right\|^3$.
% Because $\left\|y^{(i)} - y\right\| \le 2 \Delta$ and $\left\|y\right\| \le \Delta$,
% where
If we subtract this from \cref{nec_eqn2}, we find
\begin{align*}
e^{(i)}_O\left(y\right) - e_f(y) = \left(y^{(i)} - y\right)^Te_g(y) +
\frac 1 2 \left(y^{(i)} - y\right)^T \left[H - \nabla^2 f(y)\right]\left(y^{(i)} - y\right)
\end{align*}
or
\begin{align}
e^{(i)}_O\left(y\right) &= \bigg[e_f(y) - y^T e_g(y) + \frac 1 2 y^T \left[H - \nabla^2f(y)\right]y \bigg] \nonumber \\
&+ \bigg[e_g(y) + \left(H - \nabla^2 f(y)\right)y\bigg]^T y^{(i)}
+ \frac 1 2 \left(y^{(i)}\right)^T \left[H - \nabla^2 f(y)\right]\left(y^{(i)}\right).
\label{nec_eqn1}
\end{align}
To put this equation in matrix form, we introduce some notation.
Given some $n \times n$ matrix $A$, let $e_U : \reals^n \times \reals^n \to \reals^{n + \frac {n(n-1)} 2}$
linearize the upper triangular portion of $A$:
\begin{align*}
e_U\left(A\right) =
\left(\frac 1 2 A_{1, 1} \;,\; \frac 1 2 A_{2, 2} \;,\; \ldots \;,\; \frac 1 2 A_{n, n} \;,\; A_{1, 2} \;,\; A_{1, 3} \;,\; \ldots \;,\; A_{n-1, n} \right)^T
% \begin{pmatrix}
% \frac 1 2 A_{1, 1} \\ \frac 1 2 A_{2, 2} \\ \vdots \\ \frac 1 2 A_{n, n} \\ A_{1, 2} \\ A_{1, 3} \\ \vdots \\ A_{n-1, n}
% \end{pmatrix}
\end{align*}
in a similar order to that used in $\bar \Phi$ (see \cref{define_monomial}).
% \begin{pmatrix}
% e^{(0)}_O\left(\Delta^3\right) \\
% e^{(1)}_O\left(\Delta^3\right) \\
% \vdots \\
% e^{(p)}_O\left(\Delta^3\right)
% \end{pmatrix}
Then, with $e_O\left(y \right) = \left(
e^{(0)}_O\left(y\right),
e^{(1)}_O\left(y\right),
\ldots ,
e^{(p)}_O\left(y\right)
\right)^T$,
we have that \cref{nec_eqn1} becomes
\begin{align*}
M\left(\Phi, Y\right)
\begin{pmatrix}
e_f(y) + y^Te_g(y) + y^Te_h(y) y \\
e_g(y) + e_h(y) y \\
e_U\left(e_h(y)\right)
\end{pmatrix}
= e_O\left(y \right).
% \begin{pmatrix}
% e^{(0)}_O\left(\Delta^3\right) \\
% e^{(1)}_O\left(\Delta^3\right) \\
% \vdots \\
% e^{(p)}_O\left(\Delta^3\right)
% \end{pmatrix}
%  = O\left(\Delta^3\right)
% = \begin{pmatrix}
% e_T\left(\xi^{(0)}; y\right) \\
% e_T\left(\xi^{(1)}; y\right) \\
% \vdots \\
% e_T\left(\xi^{(p)}; y\right)
% \end{pmatrix}
\end{align*}
% After taking the norm, and simplifying with $\kappa_0 = \frac 4 3 \sqrt{p+1}\liphess$, we have
Thus,
\begin{align*}
\left\|M(\bar \Phi,Y)
\begin{pmatrix}
e_f(y) + y^Te_g(y) + y^Te_h(y) y \\
e_g(y) + e_h(y) y \\
e_Q\left(e_h(y)\right)
\end{pmatrix}\right\|_2
&\le \left\|e_O\left(y\right)\right\|_2 \\
&\le \sqrt{p+1} \left\|e_O\left(y\right)\right\|_{\infty} \\
% \begin{pmatrix}
% e^{(0)}_O\left(\Delta^3\right) \\
% e^{(1)}_O\left(\Delta^3\right) \\
% \vdots \\
% e^{(p)}_O\left(\Delta^3\right)
% \end{pmatrix}
&\le
\frac 4 3 \sqrt{p+1} L_{\nabla^2} \Delta^3 \\
&= \kappa_0 \Delta^3,
\end{align*}
where $\kappa_0 = \frac 4 3 \sqrt{p+1}\liphess$.
To remove the dependence of $\Delta$ on $M(\bar \Phi,Y)$, we rewrite this with a scaling matrix:
\begin{align*}
\left\|M\left(\bar \Phi, Y\right)\begin{pmatrix}
1 & 0 & 0 \\
0 & \Delta^{-1} I_n & 0 \\
0 & 0 & \Delta^{-2} I_{n + \frac{n(n-1)}{2}}
\end{pmatrix}
\begin{pmatrix}
e_f(y) + y^Te_g(y) + y^Te_H(y) y \\
\Delta\left(e_g(y) + e_H(y) y\right) \\
\Delta^2\left(e_Q\left(e_H(y)\right)\right)
\end{pmatrix} \right\|_2
\le \kappa_0 \Delta^3.
\end{align*}
With \cref{nce_scale}, this provides
\begin{align}
\left\|e_f(y) + y^Te_g(y) + y^Te_H(y) y \right\|_2\le \kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta^3, \label{nce_first}\\
\Delta \left\|e_g(y) + e_H(y) y \right\|_2 \le \kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2  \Delta^3, \label{nce_second} \\
\Delta^2 \left\|e_Q\left(e_H(y)\right)\right\|_2 \le \kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2  \Delta^3. \label{nce_third}
\end{align}
We see that \cref{nce_third} immediately provides
\begin{align*}
\left\|e_H(y)\right\|_2 
\le \left\|e_H(y)\right\|_F 
\le \sqrt{2} \left\|e_Q\left(e_H(y)\right)\right\|_2
\le \sqrt{2}\kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta
\end{align*}
where $\left\|\cdot\right\|_F$ is the Frobenius norm $\left\|A\right\|_F = \sqrt{\sum_i\sum_jA_{i, j}^2}$.
Similarily, the triangle inequality and \cref{nce_second} imply
\begin{align*}
\left\|e_g\left(y\right)\right\|_2 &\le \left\|e_g(y) + e_H(y) y \right\|_2 + \left\|e_H\left(y\right)\right\|_2\left\| y\right\|_2 \\
&\le \kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta^2
+ \left[\sqrt{2}\kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta\right]
\Delta \\
&\le\left(1 + \sqrt 2\right)\kappa_0\left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta^2.
\end{align*}
Finally, using \cref{nce_first},
\begin{align*}
\left|e^f\left(y\right)\right| &\le \left\|e_g(y)\right\| \Delta + \left\|e_H(y)\right\|\Delta^2
+ \kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|_2 \Delta^3 \\
&\le\left[\left(1 + \sqrt 2\right) + \sqrt{2} + 1\right]\kappa_0 \left\|\hat M^{-1}(\bar \Phi, Y) \right\|\Delta^3.
\end{align*}
\end{proof}

\subsection{Model Improvement Algorithms}

\label{model_improvement_algorithms}
Efficient implementations of model-based methods re-use sample points from previous iterations that fall within (or at least near) the current trust region.
New points are then added to the sample set using a model improvement algorithm as described in 
\cite{introduction_book} and stated here within \cref{model_improving_algorithm}.

The model improvement algorithm starts with a set of $p+1$ sample points that have been shifted and scaled so that they lie within a ball $B_2(0;\Delta)$, with $\Delta \ge 1$.   
The algorithm then uses LU factorization with partial pivoting of the 
associated Vandermonde matrix to construct a set of pivot polynomials $\{u_0, \ldots, u_p\}$ that are closely related to the Lagrange polynomials. 


Each iteration of the algorithm identifies a point to include in the final sample set.
In particular, on the $i$th iteration, the points $y^{(0)}, \ldots, y^{(i-1)}$ have already been included.   
If a point $y^{(j)}$,  $j \ge i$ from the original set can be found such that 
$u_i(y^{(j)})$ has a sufficiently large magnitude  (i.e.,  $|u_i(y^{(j)})| \ge \xi_{\min}$),  
then that point is added to the final sample set (by swapping it with $y^{(i)}$).
However, if no such point can be found, 
it indicates that including any of the remaining points in the final sample set would result in a poorly poised set.
Therefore, the point $y^{(i)}$ is replaced by a new point that is obtained by maximizing $|u_i(x)|$ 
over the unit ball $B_2(0;1)$.
The pivot polynomials are then updated so that 
$u_j(y^{(i})) = 0$ for $j > i$.
At the successful completion of the algorithm, the final set of points $Y$ is $\Lambda$-poised over $B_2(0;\Delta)$,
where $\Lambda$ depends on $\Delta$,  $n$ and $\xi_{\min}$,  and is inversely proportional to $\xi_{\min}$
(see \cref{set_is_poised} below).

\paragraph*{Note.}
Typically,  we have fewer than $p+1$ previously evaluated sample points within the trust region at the beginning of each iteration.
Since the Model Improvement Algorithm requires a starting set of $p+1$ points, 
we add copies of $y^{(0)}$ to create a set with $p+1$ points.

{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.5in]
\begin{flushleft}

\begin{algorithm}[H]
    \caption{Model Improvement Algorithm \label{alg:model_improvement} }
    \label{model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Given $\ximin \in (0,1/4]$, $\Delta \ge 1$, a set $Y = \left\{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\right\} \subset B_2(0;\Delta)$ of $p+1$ points,
            initialize $i=0$, and let $u_i(x)= \bar \phi_i(x)$ be the monomial basis for $\polydn$.
		\item[\textbf{Step 1}] \textbf{(Pivot)} \\
			If $i = 0$, go to Step 3. \\
			Compute the next pivot index $j^{\textrm{max}}_i = \argmax_{i \le j \le |Y|-1} \left|u_i\left(y^{(j)}\right)\right|$,
			and swap points $y^{(i)}$ and $y^{(j^{\textrm{max}}_i)}$ within $Y$.
			
        \item[\textbf{Step 2}] \textbf{(Check threshold)} \\
                If $\left|u_i\left(y^{(i)}\right)\right| \ge \ximin$ then go to Step 3. \\
                If $\left|u_i\left(y^{(i)}\right)\right| < \ximin$, then replace $y^{(i)} \gets \argmax_{x \in B_2\left(0; 1 \right)}\left|u_i(x)\right|$. \\
				If $\left|u_i\left(y^{(i)}\right)\right| < \ximin$ after this replacement,  \textbf{Stop}: $\ximin$ was chosen too small.
        \item[\textbf{Step 3}] \textbf{(Gaussian elimination)} \\
        	For $j = i+1, \ldots, p$ \\
        	\hspace{2em} Set $u_j(x) \gets u_j(x) - \frac{u_j\left(y^{(i)}\right)}{u_i\left(y^{(i)}\right)} u_i(x)$ \\
%         \begin{itemize}
%                 \item[] Set $V_i \gets \frac{1}{V_{i,i}} V_i$
%                 \item[] Set $V_{\bullet j} \gets V_{\bullet j} - \frac{V_{i,j}}{V_{i, i}} V_{\bullet j} \forall j=i \ldots p$
%             \end{itemize}
            If $i = p$ then \textbf{Stop}, otherwise.  Set $i \gets i+1$ and go to Step 1
    \end{itemize}
\end{algorithm}

\end{flushleft}
\end{fullwidth}
}

%In \cref{satisfying_accuracy} show how to construct a $\Lambda$-poised set over an ellipsoidal region.

%At the successful completion of the algorithm,  the matrix
%\[U = \left[ \begin{array}{cccc}
%u_0(y^{(0)}) & u_0(y^{(1)}) & \cdots & u_0(y^{(p)}) \\
%u_1(y^{(0)}) & u_1(y^{(1)}) & \cdots & u_1(y^{(p)}) \\
%&& \vdots & \\
%u_p(y^{(0)}) & u_0(y^{(1)}) & \cdots & u_p(y^{(p)}) 
%\end{array}\right\]
%is the upper triangular portion of the $LU$ factorization of the Vandermonde matrix $M =M(\bar{\Phi},Y)$ corresponding to the sample set $Y$ generated by the algorithm.     The following results establishes that $M$ has a bounded condition number:
%
%
%
%
%Since all of the diagonal entries of this matrix have magnitude greater than or equal to $\xi_{\min}$,  we
%we obtain a sample set
% $Y=\{y^{(0)}, \ldots, y^{(p)}\}$ that is $\Lambda$-poised, 
%where $\Lambda$ is inversely proportional to $\xi_{\min}$, as given by \cref{set_is_poised}.
%\sbnote{I changed the last line of Step 2 in the algorithm to include a \textbf{Stop}}


Notice that \cref{model_improving_algorithm} constructs a set of pivot polynomials $u = \left\{u_0, u_1, \ldots, u_p\right\}$,
and that $M(u, Y)$ is the upper triangular factor of the LU factorization of $M(\bar \Phi, Y)$.
The first instruction of Step 1 of \cref{model_improving_algorithm} ensures that the first point is not replaced.
The first basis polynomial is always $1$, so we can be sure that the first pivot will not need to be replaced.

Observe that \cref{model_improving_algorithm} uses a threshold parameter $\xi_{\min}$ to select the next sample point.
If $\xi_{\min}$ is too large, it is possible that there might not exist a point $x \in B_2(0;1)$ 
in the unit ball such that $\|u_i(x)\| \ge \ximin$.
In this case, the algorithm stops prematurely in Step 2 with a certification that $\xi_{\min}$ is too small.
However,  in \cref{terminates} below, we show that this cannot happen as long as $0 < \ximin \le \frac 1 4$.
To establish the result, we first need the following Lemma from \cite{introduction_book}.


%\begin{lemma}
%\label{maximum_value_for_quad}
%Let $v^T\bar \phi(x)$ be a quadratic polynomial of degree at most $d$, where $\|v\|_{\infty} = 1$
%and $\bar \phi(x)$ is the monomial bases for $\polydn$.
%Then, for any $r \ge 1$,
%\begin{align*}
%\max_{x \in B_2(0; r)} \left|v^T\bar\phi(x)\right| \ge \frac 1 4
%\end{align*}
%\end{lemma}
%\begin{proof}
% When $d = 1$,
% we have that $\bar \phi(x) = (1, x_1, x_2, \ldots, x_n)^T$.
% Then by letting $w = (v_2, \ldots, v_{n+1})^T$ and $\hat w = r \frac w {\|w\|}$, we see that
% \begin{align*}
% v^T\bar\phi\left(\pm w\right) = v_1 + r^2
% \end{align*}
% \end{proof}

\begin{lemma}(\cite[Lemma 6.7]{introduction_book})
\label[lemma]{book_lemma6p7}

Let $v^T \bar{\Phi}(x)$ be a quadratic polynomial, where $\norm{v}_{\infty}=1$ and $\bar{\Phi}$ is the monomial basis.
Then,
\begin{align*}
\max_{x \in B_2(0;1)} \left\|v^T \bar{\Phi}(x)\right\| \ge \frac{1}{4}.
\end{align*}
\end{lemma}

\begin{lemma}
\label[lemma]{terminates}

For any given $\xi_{\min} \in (0,1/4]$, \cref{model_improving_algorithm}
computes a set $Y$ of $p+1$ points in the ball $B_2(0;\Delta)$ for which the pivots of the LU factorization of
$M=M(\bar{\Phi},Y)$ satisfy
\begin{align*}
\left\|u_i(y^{(i)})\right\| \ge \xi_{\min},  \quad i=0,\ldots,p.
\end{align*}
\end{lemma}

\begin{proof}

The first pivot polynomial is $u_0(x) = 1 = (1, 0, \ldots, 0)\cdot \bar\Phi(x)$, so that $\left\|u_0\left(y^{(0)}\right)\right\| = 1 \ge \ximin$.
For $i > 1$, the $(i+1)$st pivot polynomial $u_i(x)$ can be expressed as $v^T \bar{\Phi}(x)$,
where $v = (v_0, \ldots, v_{i-1},1,0,\ldots,0)^T$.
Observe that $\norm{v}_{\infty} \ge 1$.
Let $\bar{v} = v/\norm{v}_{\infty}$.
Then by \cref{book_lemma6p7},
\[ \max_{x \in B_2(0;1)} u_i(x) = \max_{x \in B_2(0;1)} \left| v^T \bar{\phi}(x)\right| =
\norm{v}_{\infty} \max_{x \in B_2(0;1)}  \left|\bar{v}^T \bar{\phi}(x)\right| \ge \frac{1}{4} \norm{v}_{\infty} \ge \frac{1}{4}.\]

%\max_{x \in B_2(0;1)} \norm{v}_{\infty} \left|\bar{v}^T \bar{\phi}(x)\right|\max_{x \in B_2(0;1)}  \left|\bar{v}^T \bar{\phi}(x)\right|
%\ge 1/4.\]
It follows that the algorithm does not stop in Step 2 for $\ximin \le 1/4$.   Hence, at the end of the $i$-th iteration, we have that  $\left| u_i\left(y^{(i)}\right)\right| \ge \ximin$.  Moreover,  after the $i$ iteration has been completed,  $u_i$,  and $y^{(i)}$ are never altered.  Thus, the algorithm terminates with  $\left| u_i\left(y^{(i)}\right)\right| \ge \ximin$ for $i=0, \ldots, p$.

Finally,  observe that all points in the final sample set $Y$ are selected either from the original sample set, which is contained in $B_2(0;\Delta)$,  or are obtained in Step 2 from within $B_2(0;1)$.  Since $\Delta  \ge 1$, it follows that $Y \subset B_2(0;\Delta)$.

\end{proof}



\begin{theorem}
\label{set_is_poised}

Let $\Delta \ge 1$, and suppose that \cref{model_improving_algorithm} is called on a sample set 
$Y = \left\{y^{(0)}, y^{(1)}, \ldots, y^{(p)}\right\} \subset B_2(0; \Delta)$ 
resulting in a new sample set $\hat Y$,
and let $\bar{\Phi}$ be the monomial basis \cref{define_monomial}.
Then,
\begin{itemize}
\item $\left\|M(\bar \Phi, \hat Y)^{-1}\right\|_2$ as defined by \cref{vandermonde}, is bounded by a constant depending only on $p$ and $\ximin$.
\item The resulting sample set $\hat Y$ is $\Lambda$-poised over $B_2\left(0;\Delta\right)$ for quadratic interpolation,
where $\Lambda > 0$ is a constant that depends only on $\Delta$, $\xi_{\text{min}}$ and $n$ and is inversely proportional to $\xi_{\text{min}}$.
\item The initial point $y^{(0)}$ is retained in the resulting sample set: $y^{(0)} \in \hat Y$.
\end{itemize}
\end{theorem}

\begin{proof}

Note that \cref{model_improving_algorithm} never swaps or replaces $y^{(0)}$.
By \cref{terminates},  $\hat Y \subset B_2(0;\Delta)$
and the pivots in the LU-factorization of $M(\bar{\phi},Y)$ are bounded below by $\ximin$; that is,
$\left|u_i\left(y^{(i)}\right)\right| \ge \ximin, \; \forall 0 \le i \le p.$
Thus, by 
\cite[Section 6.7, Exercise 3]{introduction_book}, 
 we have that 
\begin{align*}
\left\|M\left(\bar \Phi, Y\right)^{-1}\right\| \le \frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}
\end{align*}
where $\epsilon_{growth}$ is a potentially large, but finite estimate of the growth factor in the LU factorizations.   By  \cref{Lambda_poised_error_bounds_delta},  using the fact that $\Delta \ge 1$, we have that $Y$ is $\Lambda$-poised in $B_2(0;\Delta)$,  where 
\[\Lambda = \left(\frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}\right) \sqrt{p+1}  \frac{\Delta^2}{2} = \frac{(p+1) \epsilon_{growth}}{2\ximin}\Delta^2.\]
%
%
%
%
%Our \cref{Lambda_poised_error_bounds} is then a restatement of \cite[Theorem 3.14]{introduction_book} which 
%relates the $\Lambda$-poisedness of $Y$ to $\left\|M\left(\bar \phi, Y\right)^{-1}\right\|$ over the unit ball.
%However, \cite[Lemma 3.8]{introduction_book} and \cite[Lemma 3.9]{introduction_book} establish that $\Lambda$-poisedness is scale and translation invariant.
\end{proof}

%
%\begin{theorem}
%\label{set_is_poised}
%The sample set $Y$ obtained from \cref{model_improving_algorithm} is $\Lambda$-poised over $B_2\left(\ck, \delta\right)$ for quadratic interpolation, 
%where $\Lambda > 0$ is a constant that depends only on $\xi_{\text{min}}$ and $n$ and is inversely proportional to $\xi_{\text{min}}$.
%\end{theorem}
%
%\begin{proof}
%This result is shown through a sequence of results in \cite{introduction_book}.
%Namely,  \cite[Theorem 6.5]{introduction_book} shows the pivots in the LU-factorization are bounded below by $\ximin$:
%$
%\left|u_i\left(y^{(i)}\right)\right| \ge \ximin \; \forall 0 \le i \le p.
%$
%\cite[Section 6.7, Exercise 3]{introduction_book}
% bounds the condition number of the Vandermonde matrix in terms of these pivots:
%\begin{align*}
%\left\|M\left(\bar \phi, Y\right)^{-1}\right\| \le \frac{\sqrt{p+1}\epsilon_{growth}}{\ximin}
%\end{align*}
%where $\epsilon_{growth}$ is a large, but finite estimate of the growth factor in LU factorizations.
%Our \cref{Lambda_poised_error_bounds} is then a restatement of \cite[Theorem 3.14]{introduction_book} which 
%relates the $\Lambda$-poisedness of $Y$ to $\left\|M\left(\bar \phi, Y\right)^{-1}\right\|$ over the unit ball.
%However, \cite[Lemma 3.8]{introduction_book} and \cite[Lemma 3.9]{introduction_book} establish that $\Lambda$-poisedness is scale and translation invariant.
%\end{proof}

%Note that \cite[Theorem 6.5]{introduction_book} explicitly states an upper bound $\xi_{\textrm{alg}} > 0$ on $\ximin$, so that $\ximin \in \left(0 , \xi_{\textrm{alg}}\right)$.
%This bound depends on the choice of basis $\Phi$: $\xi_{\textrm{alg}} = 1$ for the linear case and $\xi_{\textrm{alg}} = \frac 1 4$ for the quadratic case.
%As a practical matter, these bounds are not restrictive because $\ximin$ is usually chosen small: on the order of $0.001$ for example.

%\sbnote{The following is a nice discussion!}
%
%This bound on $\ximin$ is complicated by our construction of the sample set:
%we choose points {\em near} the current iterate, although the current sample region does not necessarily include the current iterate.
%This is developed later in the thesis, and our requirements for the sample set are formalized in \cref{define_suitable_ellipsoid} for the linear case and \cref{ellipsoids_notation_definitions} for the non-linear case.
%The takeaway from these requirements is that after an affine transformation to the unit ball, \cref{model_improving_algorithm} 
%will be called to construct sample points within the unit ball $B_2(0; 1)$, with an additional requirement that one of the sample points (the transformed $\xk$)
% lies within $B_2\left(0, \sqrt{2}\right)$.
%Although most practical implementations of \cref{model_improving_algorithm} choose a small $\ximin$, 
%this additional requirement further limits $\ximin$ in theory.
%This raises a question:
%for what values of $\Lambda$ (and therefore $\ximin$) can a sample set be $\Lambda$-poised if one point is chosen outside the unit ball?
%Namely, given $y^{(0)} \in B_2\left(0, \sqrt{2}\right)$:
%\begin{align*}
%\begin{array}{ccc}
%\min\limits_{\Lambda>0, y^{(i)}\in\Rn, l_i\in\polydn} & \Lambda & \\
%\textrm{s.t.} & |l_i(x)| \le \Lambda & \forall \; x \in B_2(0; 1), 0 \le i \le p \\
%& l_i\left(y^{(j)}\right) = \delta^i_j & \forall \; 0 \le i,j \le p \\
%& y^{(i)} \in B_2(0; 1) & \forall \; 1 \le i \le p.
%\end{array}
%\end{align*}
%We have not encountered an issue choosing $\ximin$ too large,
%but we are interested in bounding this program's solution.
%
%% \begin{comment}
%% I think it is straightforward to come up with a simple bound to this problem:
%% construct a perfectly poised set with a point at the center, shifted it.
%% What is the maximum value at $\sqrt 2$ of a quadratic that is strictly between $(-1, 1)$ in $B_2(0; 1)$?
%% Seems like it would be $2$.
%% \end{comment}


\subsection{Criticality Measure}

\label{criticality_measure_section}
\label{criticallity_measure_section}

A key component of any optimization algorithm is the {\em criticality measure}, which is used to define stopping criteria for the algorithm.
The criticality measure $\chi(x^{(k)})$ at an iterate $x^{(k)}$ is a nonnegative quantity that is zero if and only if $x^{(k)}$ satisfies necessary optimality conditions.
For unconstrained problems,  a typical choice of criticality measure for classical (gradient-based) algorithms is given by $\chi(x) = \norm{\nabla f(x)}$
since the first order optimality condition is $\nabla f(x)=0$.
The algorithm then terminates when $\chi(x) < \tolcrit$, where $\tolcrit >0$ is a stopping tolerance.

For derivative-free optimization,  $\nabla f(x)$ is not available,  so the true criticality measure is replaced by the model criticality measure
$\chik(x) = \norm{\nabla \mfk\left(x\right)}.$
Note however that $\chik$ is only an accurate approximation of $\chi(x)$ if the gradient of the model function $\nabla \mfk(x)$ is a close approximation to $\nabla f(x)$.
For this reason, derivative-free algorithms require not only that $\chik(x)$ is small, but also that the model functions are accurate.
To accomplish this, we require poised sample sets as discussed in \cref{geometry} with a trust-region converging to zero.
Once the criticality measure has reached a small enough threshold $\tolcrit > 0$ and the trust region is small enough ($\dk < \tau_{\Delta}$),
we can terminate the algorithm.



%In the presence of convex constraints,
If the feasible region $\feasible$ is convex, a classic criticality measure (see, for example \cite{Conejo:2013:GCT:2620806.2621814} \cite{Conn:2000:TM:357813}) is given by
\begin{align*}
\chi(x) = \left\|x - \proj_{\feasible}\left(x- \nabla f\left(x\right)\right)\right\|.
\end{align*}
If the feasible region is not convex, the projection operation is not well-defined, so this criticality measure is not helpful.
Moreover,  even with a convex feasible region, we need a way to determine the projection, so we prefer a criticality measure based on the  functions defining the constraints.   In particular, for
a first order criticality measure at $\xk$, we define
\begin{align}
\truefeasiblek &= \left\{ x \in \Rn \bigg| c_i\left(\xk\right) + \nabla c_i\left(\xk\right)^T \left(x - \xk\right) \le 0 \; \forall i \in [m] \right\} \label{define_truefeasiblek}
\end{align}
and use
\begin{align}
\chi_c^{(k)}(x) = \left\|x - \proj_{\truefeasiblek}\left(x- \nabla f\left(x\right)\right)\right\|. \label{define_true_criticality}
\end{align}

Note that $\chi_c^{(k)}(\xk) = 0$ if and only if $\xk$ satisfies the first order Karush-Kuhn-Tucker conditions.
% This condition is necessary under regularity assumptions and with convex
% For a convex problem convex constraints with a convex objective, this condition would be necessary and sufficient for local optimality under regularity assumptions.
Unfortunately,  without derivative information, we cannot calculate $\chi_c^{(k)}$ directly, so in our algorithms we approximate it with
\begin{align}
\label{define_criticality_measure}
\chik = \left\|\xk - \proj_{\feasiblek}\left(\xk- \nabla \mfk\left(\xk\right)\right)\right\|,
\end{align}
where $\feasiblek$ is the model feasible region defined by
\begin{align}
\feasiblek = \left\{x \in \Rn \big| \mcik(x) \le 0 \quad \forall 1 \le i \le m \right\}.  \label{define_feasiblek}
\end{align}

This quantity measures how far the current iterate $\xk$ is from satisfying the first order optimality conditions for the model function $\mfk$.
In turn, as $\dk \to 0$, the model $\mfk$ better approximates $f$, $\feasiblek$ better approximates $\feasible$ and $\xk$ approaches a critical point for $f$.

%With general constraints, we cannot use $\proj_{\feasible}$ because the projection is not well defined.
%However, the linearization \cref{define_truefeasiblek} is still well defined.
%Thus, it is possible to use \cref{define_criticality_measure} with general constraints to satisfy the first order necessary conditions.
% However, unlike for convex constraints, points with a linearized criticality measure of $0$ are not necessarily local extremum.



% For now, our algorithm is designed to work with convex constraints, so we employ a classic criticality measure discussed in  of
% The first order optimality conditions for $x^{\star} \in \Rn$ to by a local optimum of $f$ is that $x^{\star}$ satisfies
% \begin{align*}
% x^{\star} = \proj_{\feasiblek}\left(x^{\star} - \gradf(x^{\star})\right).
% \end{align*}
% % that we use as thresholds to determine when the criticallity measure and trust region radius are sufficiently small.

%
% We still employ thresholds
% \begin{align}
%
% \end{align}
% for stopping conditions.
%





% \color{red}
% \begin{comment}
% Citation?
% \end{comment}
% For general constraints the first order necessary conditions are the Karush-Kun-Tucker conditions.
% These state, under regularity assumptions, that for any critical point $x^{\star}$ there exists of a dual variable $\lambda \in \Rm$ such that
% \begin{align*}
% \nabla f(x) + \nabla c(x)^T \lambda  = 0, \;
% c(x) \le 0, \;
% \lambda \ge 0, \;
% c(x)^T\lambda = 0. \;
% \end{align*}
% \color{black}






%
%%A set of poised points are chosen for some radius $\Delta_k>0$ about the current iterate.
%The objective value and derivatives are approximated in a trust region around the current iterate to construct their model functions.
%Next, this model function is minimized over the trust region and the minimum argument becomes the trial point.
%The objective is evaluated at the trial point and a measure of reduction $\rho$ is computed.
%If $\rho$ implies that sufficient reduction has been made and that the model approximates the function well, the trial point is accepted as the new iterate.
%Otherwise, the trust region is reduced to increase model accuracy.
%The algorithm terminates when both a criticality measure $\chik$ and the trust region radius $\Delta_k$ reach sufficiently small thresholds of $\tau_{\chi}$ and $\tau_{\Delta}$.

% \sbnote{I don't think we need to state the trust-region algorithm for unconstrained dfo, so I have commented it out.}

%For unconstrained optimization, the algorithmic framework is described in \cref{unconstrained_dfo}.
%
%\begin{algorithm}[H]
%    \caption{Unconstrained Derivative Free Algorithm}
%    \label{unconstrained_dfo}
%    \begin{itemize}
%        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
%            Initialize tolerance constants $\tau_{\chi} \ge 0$, $\tau_{\Delta} \ge 0$, starting point $\xinit$, initial radius $\Delta_0 > 0$, iteration counter $k=0$, and constants $\omegadec \in (0, 1)$, $ \gammasm \in (0, 1)$, $\gammabi \in (\gammasm, 1)$.
%
%        \item[\textbf{Step 1}] \textbf{(Construct the model function)} \\
%            Call the model improvement ``\cref{model_improving_algorithm}" to provide a set of sample points $Y^{(k)}$.
%            Evaluate the objective on these points and use interpolation \cref{interpolation_formula} to construct the model function $\mfk(x)$.
%
%        \item[\textbf{Step 2}] \textbf{(Check stopping criteria)} \\
%            Compute the criticality measure $\chik$ such as $\chik = \|\nabla\mfk(\xk)\|$. \begin{itemize}
%                \item[] If $ \chik < \tau_{\chi} $ and $\Delta_k<\tau_{\Delta}$ then return solution $\xk$.
%                \item[] If $ \chik < \tau_{\chi} $ but $\Delta_k\ge\tau_{\Delta}$ then
%                set $\Delta_{k+1} \gets \omegadec\Delta_{k}$,
%                $x^{(k+1)} \gets \xk$,
%                $k \gets k+1$ and go to Step 1.
%            \end{itemize}
%
%        \item[\textbf{Step 3}] \textbf{(Solve the trust region subproblem)} \\
%            Compute $\sk = \argmin_{s\in B_2(0; \Delta_k)} \mfk (\xk + s)$ where $B_2(0; \Delta_k)$ is the ball of radius $\Delta_k$ defined in \cref{define_ball}.
%
%        \item[\textbf{Step 4}] \textbf{(Test for improvement)} \\
%            Compute $\rk$ with \cref{define_rhok} \begin{itemize}
%                \item[] If $\rk < \gammasm$ then $\xkpo \gets \xk$ (reject) and $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammasm$ and $\rk < \gammabi$ then $\xkpo\gets\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegadec\Delta_{k}$
%                \item[] If $\rk \ge \gammabi$ and $\|\sk\| = \Delta_{k}$ then $\xkpo=\xk+\sk$ (accept) $\Delta_{k+1} \gets \omegainc\Delta_{k}$
%                % and either increase the radius or decrease if $\nabla \mfk(\xk)$ is small
%            \end{itemize}
%            $k \gets k+1$ and go to Step 1.
%    \end{itemize}
%\end{algorithm}
%
%This derivative-free optimization algorithm differs from the classical trust region algorithm in two important respects:
%\begin{enumerate}
%    \item Models are constructed without derivative information.
%    \item The trust region radius $\Delta_k$ must go to zero as $k\to\infty$.
%\end{enumerate}
%
%This is required to ensure that the gradient of the model function closely approximates the gradient of $f$.
%Our goal is to generalize this framework to handle constraints,
%where we must ensure no constraint violation occurs
%while also ensuring the accuracy of the models of the constraints.



\subsection{Trust Regions}

\label{trust_regions_section}

To define our algorithms, we distinguish between three types of trust regions: 
the {\em sample region} $\sampletrk$,
the {\em search region} $\searchtrk$,
and the {\em outer trust region} $\outertrk$.
For unconstrained optimization,  these trust regions are typically identical and are chosen to be an $L_2$-ball of radius $\Delta_k$.
However, for constrained optimization, it is useful to distinguish between the two regions.



The sample region is where the algorithm chooses sample points, constraining them to ensure their feasibility.
The search region defines the feasible region for the trust region subproblem.
Both $\sampletrk$ and $\searchtrk$ lie within the {\em outer trust region},
$\outertrk = B_{\infty}\left(\xk, \dk\right)$, which is an $L_{\infty}$-ball of radius $\dk$ centered at the current iterate $\xk$:
\begin{align}
\label{define_outer_trust_region}
\outertrk = B_{\infty}\left(\xk,\dk\right) = \left\{x\in \Rn | \; \xki - \dk \le x_i \le \xki + \dk \quad \forall i \in [m] \right \}.
\end{align}

To allow for the best possible trial point, we would like the search region to be as large as possible within the outer trust region while remaining feasible.
Ideally, we would set $\searchtrk=\outertrk \cap \feasible$.
However, this is only possible when the constraints are known.
In \cref{chap:general}, we can only take $\searchtrk = \outertrk \cap \feasiblek$.
Observe that using an $L_{\infty}$ ball instead of an $L_2$ ball results in linear constraints for the model problem,
so that that $\searchtrk$ is a polytope.
% Observe that linear constraint models with an $L_{\infty}$-ball instead of an $L_2$-ball ensure $\searchtrk$ is a polytope.


\section{linear constraints}
\label{sec:linear}
This chapter considers the case of linear constraints.
Specifically, we present an algorithm for solving
\begin{align}
\label{eq:DFO-linear}
\begin{array}{ccl} \min_{x \in \Rn} & f(x) \\
\textrm{s.t.} & \lca x \le \lcb & 
\end{array}
\end{align}
where $f:\Rn\rightarrow\reals$ is a black-box function, 
$\lca$ is an $m \times n$ matrix and $\lcb \in \Rm$.
For convenience, we assume that $\left\|\lca_i\right\| = 1$ for each $i \in [m]$.

We consider two main strategies for defining $\sampletrk$.
The first method,  which is described in \cref{sec:ellipsoidal},  
defines $\sampletrk$ to be an ellipsoidal region
\begin{align}
\label{define_the_sample_region}
\sampletrk = \left\{x \in \Rn \bigg | \left(x - \ck\right)^T \qk \left(x - \ck\right) \le \frac 1 2 \sdk^2 \right\}.
\end{align}
We choose the positive definite, symmetric matrix $\qk$, vector $\ck \in \Rn$, and constant $\sdk > 0$ so that
the sample region lies within the intersection of the feasible region and the outer trust region:
$\sampletrk \subseteq \feasible \cap \outertrk$.
This is referred to as the {\em ellipsoidal trust region approach}.
For this approach, we present a method for selecting a well-poised set of sample points by a straightforward application 
of the model-improvement algorithm \cref{model_improving_algorithm} to a transformed problem in which 
the ellipsoidal region is mapped onto a ball.
% The advantage of this approach is that it is relatively straightforward to modify the model-improvement algorithm \cref{model_improving_algorithm} 
% to construct a well-poised sample set over an ellipsoidal region.


% Note that by using an $L_{\infty}$-ball instead of an $L_2$-ball, the search trust region is a bounded polyhedron,  
% which makes the trust region subproblem a quadratic program with linear constraints.


In the second method,  described in \cref{sec:polyhedral}, we define 
\begin{align*}
\sampletrk = \searchtrk = \outertrk \cap \feasible.
\end{align*}
Since this trust region is a bounded polyhedron,  we call this the {\em polyhedral trust region approach}.
While this method is perhaps more intuitive than the first approach,
it is not immediately clear how to construct a well-poised sample set over the polyhedral region.
We present one method with this aim, but we do not show equivalent error bounds as those found for ellipsoidal regions.
To select sample points from this polyhedral region, 
we present \cref{modified_model_improving_algorithm} as a modification of model-improvement algorithm (\cref{model_improving_algorithm}).
For this approach, the search trust region is given by $\searchtrk = \outertrk \cap \feasible$.

In all cases, the trust regions are related by the inclusions
\begin{align*}
\sampletrk \subseteq \searchtrk \subseteq \outertrk \cap \feasible.
\end{align*}
Both methods fall into a general algorithmic framework, which we describe next.


\section{Algorithm Template}\label{sec:template}

All of the methods in this chapter follow
an algorithmic template described in \cite{Conejo:2013:GCT:2620806.2621814}.

% HOW ABOUT JUST MAKE $\eta > 0$?

{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.5in]
\begin{flushleft}

\begin{algorithm}[H]
    \caption{Linear Always-feasible Constrained Derivative-free Algorithm}
    \label{linearly_constrained_dfo_simple}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Choose
            $\tolcrit\ge 0$,
            $\tolrad \ge 0$, 
            $\omegadec \in (0,1)$, 
            $\omegainc \ge 1$,  
            $ \gammabi \in (0,1]$, 
            $\gammasm \in (0,\gammabi)$,
			and $\alpha > 0$. \\
            Initialize
            $k\gets 0$,
            $x^{(0)} \in \feasible$,
            and $0 < \Delta_0 \le \dmax$.
            
        \item[\textbf{Step 1}] \textbf{(Construct the Model)} \\
           Construct the trust region $\sampletrk$. \\
%            $ \sampletrk \gets $ \Call{ConstructTrustRegion}{$\dk, \xk$}.
%            Ensure that the sample points are poised with respect to $ \sampletrk $ for \cref{accuracy} by calling \cref{model_improving_algorithm}.
           Construct $\mfk$ by calling \cref{model_construction_algorithm} on $\sampletrk$.
        
        \item[\textbf{Step 2}] \textbf{(Check Stopping Criteria)} \\
            Compute the criticality measure $\chik$ as in \cref{define_criticality_measure}. \\
            If $ \chik < \tau_{\xi} $ and $\dk <\tau_{\Delta}$,  {\bf stop}: return $\xk$ as the solution.   \\
            Otherwise, if $\dk > \alpha \chik$,   
%             {\em shrink the trust region}:  
            set 
                $\dkpo \gets \omegadec\dk$, 
                $\xkpo \gets \xk$,
                $k \gets k+1$ and {\bf go to Step 1}.
           
        
        \item[\textbf{Step 3}] \textbf{(Solve the Trust Region Subproblem)} \\
            Compute $\sk = \argmin_{s \in \searchtrk - \xk} \mfk\left(\xk + s\right)$. 
            % \item[] This can also be $\sk = \min_{s \in \outertrk \cap \feasible} \mfk(\xk + \sk)$ depending on the choice made in \cref{which_trust_region}.
            
 		\end{itemize}
 		\end{algorithm}
 		
 		\newpage
 		
 		\begin{algorithm}[H]
 		\begin{itemize}
 		
        \item[\textbf{Step 4}] \textbf{(Test for Improvement)} \\
            Evaluate $f(\xk + \sk)$ and $\rk$ as in \cref{define_rhok}. \\
			If $\rk < \gammasm$, then $\xkpo \gets \xk$, otherwise $\xkpo \gets \xk + \sk$. \\
            If $\rk < \gammabi$, then $\dkpo \gets \min\left\{\dmax, \omegadec\dk\right\}$. \\
            If $\rk \ge \gammabi$, and $\|\sk\|_{\infty} = \dk$, then $\dkpo \gets \omegainc\dk$. \\
            If $\rk \ge \gammabi$, and $\|\sk\|_{\infty} < \dk$, then $\dkpo \gets \dk$. \\
            Set $k \gets k+1$ and go to Step 1.
    \end{itemize}
\end{algorithm}

\end{flushleft}
\end{fullwidth}
}


In Step 1, this algorithm relies on constructing and choosing sample points from $\sampletrk$.
Different variations of the algorithm implement this step differently with their \emph{ConstructTrustRegion} subroutine.
We show convergence for the ellipsoidal approach, in which sample points are chosen using \cref{model_improving_algorithm}
and the choice of $\sampletrk$ satisfies some additional restrictions.
We discuss those restrictions here.

To simplify notation, define $\lctra = \begin{pmatrix} \lca \\ I \\ -I \end{pmatrix}$ and 
$\lctrb = \begin{pmatrix} \lcb \\ \xki+\dk \\ -\xki+\dk \end{pmatrix}$.
We can then define
\begin{align}
\polyk = \feasible \cap \outertrk =  \{x \in \Rn | \; \lca x \le \lcb, \|x - \xk\|_{\infty} \le \dk \} \label{polyhedron_k}  \\
= \{x \in \Rn | \lctra x \le \lctrb \}. \nonumber
\end{align}
Note that we will still have $\|\lctra_i\| = 1$ for each $i \in [m]$.

\begin{definition}
\label[definition]{define_suitable_ellipsoid}
Let $\left\{\qk\right\}$ be a sequence of positive definite symmetric matrices,
$\left\{\ck\right\} \subset \Rn$ be a sequence of points, and $\left\{\sdk\right\}$ be a sequence of positive scalars.
For each $k \in \naturals$, define the ellipsoids
\begin{align*}
\ellipsek &= \left\{x \in \Rn \bigg| \left(x - \ck\right)^T\qk\left(x - \ck\right) \le \frac 1 2 \sdk^2 \right\}, \textrm{and} \\
\scaledellipsek &= \left\{x \in \Rn \bigg | \left(x - \ck\right)^T\qk\left(x - \ck\right) \le  \sdk^2 \right\}.
\end{align*}
The sequence $\left\{\ellipsek\right\}$ is said to be suitable if all of the following are satisfied:
\begin{itemize}
\item[1.] $\ellipsek \subseteq \polyk$, where $\polyk$ is defined by \cref{polyhedron_k},
\item[2.] $\xk \in \scaledellipsek$,
\item[3.] The condition number $\condition \left(\qk\right)$ is bounded independently of $k$.
\end{itemize}
\end{definition}


%As discussed in \cref{ellipsoidal_lambda}, we know that if the condition number of $\qk$ is bounded, 
%we can map a poised set over the unit ball to $\sampletrk$.
%However, we must also ensure that we are always able to find a feasible ellipsoid.
%Although it is not always possible to find a feasible ellipsoid that contains the current iterate,
%we can find a feasible ellipsoid that only needs to be scaled by a constant to do so.
%This ellipsoid must satisfy the following conditions:


\section{Convergence Analysis}
\label{linear_convergence_discussion}
 
Here, we analyze the convergence behavior of \cref{linearly_constrained_dfo_simple}.
% namely the ellipsoidal method with a particular choice of the sample trust region $\sampletrk$  discussed below, and with $\searchtrk = \outertrk \cap \feasible$.
For our analysis, we assume that $\domain$ is some open set containing $\feasible$ and make the following assumptions about the problem and model functions:

\begin{assumption}
\label{for_fully_quadratic}
\label{lipschitz_hessian}
The function $f$ is twice continuously differentiable with Lipschitz continuous Hessian in $\domain$.   That is, there exists constant $\liphess > 0$ such that 
\begin{align}
\left\|\nabla^2 f(x) - \nabla^2 f(y)\right\| \le \liphess \left\|x - y\right\| \quad \forall x, y \in \domain.
\end{align}
\end{assumption}

% \begin{boxedcomment}
% Do we need $f$ to be bounded above (since my models are interpolating $f$)?
% \end{boxedcomment}



\begin{assumption}
\label{lower_bound}
The function $f$ is bounded below over $\domain$.
That is,
\begin{align}
f(x) \ge \fmin \quad \forall x \in \domain.
\end{align}
\end{assumption}

\begin{assumption}
\label{interior_point}
There exists a point $\bar x$ within the interior of the feasible region.
Namely, using $\lca$ and $\lcb$ from \cref{eq:DFO-linear}:
\begin{align}
\lca \bar x < \lcb.
\end{align}
\end{assumption}


\begin{assumption}
\label{uniformly_bounded_hessians_of_f}
The Hessians of $f$ are uniformly bounded at each iterate. That is, there exists a constant $\beta \ge 1$ such that
\begin{align*}
\left\|\nabla^2 f\left(\xk\right)\right\| \le \beta - 1\quad \forall k \in \naturals.
\end{align*}
\end{assumption}


%
%With this modest assumption, we can make the assumptions more straightforward by replacing \cref{uniformly_bounded_hessians_of_mf} with \cref{uniformly_bounded_hessians_of_f}:



% \begin{assumption}
% \label{accuracy_assumption}
% There exists a constant $\delta_g$ such that 
% \begin{align}
% \|\nabla m_k\left(\xk\right) - \nabla f\left(\xk\right)\| \le \delta_g \dk \;\forall k \ge 0.
% \end{align}
% \end{assumption}


Our analysis closely follows that of \cite{Conejo:2013:GCT:2620806.2621814},
which presents a class of trust region algorithms for derivative-free optimization with convex constraints.
In fact, if the tolerances $\tau_{\chi}$ and $\tau_{\Delta}$ are set to zero,  
then \cref{linearly_constrained_dfo_simple} is a particular implementation of the algorithm studied within this reference.
The only modification is in the trust region subproblem, in which we allow for more trial points with a $L_{\infty}$ ball instead of an $L_2$ ball.
It is therefore sufficient to show that the model functions generated by our method satisfy the hypotheses required for their analysis.

We have included a modification that $\dk \le \dmax$; however, this does not alter any of the convergence results.
In fact, the authors allow $\omegainc = 1$, so that the trust region radius can never be increased.

The authors assume that the model of the objective is quadratic and satisfies an efficiency condition.
Namely, there exists a constant $\kappa_f$ such that for all $k \in \naturals$,
\begin{align}
\label{efficiency}
\mfk\left(\xk\right) - \mfk\left(\xk + \sk\right) \ge \kappa_f \chik \min\left\{ \frac{\chik}{1+\left\|\nabla^2 \mfk(\xk)\right\|}, \dk, 1 \right\},
\end{align}
where $\chik$ is defined by \cref{define_criticality_measure}.
The Generalized Cauchy Point is shown to satisfy \cref{efficiency} within \cite{Conn:2000:TM:357813}.
This is a reasonable choice for $\sk$, but the exact solution as chosen within \cref{linearly_constrained_dfo_simple} 
necessarily also satisfies \cref{efficiency} as it can only improve upon the Generalized Cauchy Point.
Also, note that although \cite{Conejo:2013:GCT:2620806.2621814} presents a criticality measure based on the true projection onto the constraints,
for linear constraints, this precisely coincides with the models used in \cref{define_criticality_measure}.

The authors of \cite{Conejo:2013:GCT:2620806.2621814} also make four explicit assumptions.
Their first assumption $H_1$ requires the function $f$ to be differentiable and its gradient $\nabla f$ to be Lipschitz continuous with constant $L > 0$ in $\domain$.
We have assumed \cref{lipschitz_hessian} which is a strictly stronger assumption.
As their second assumption $H_2$, they assume our \cref{lower_bound}.
Their $H_3$ requires the Hessians of $\mfk$ to be uniformly bounded.
That is, there exists a constant $\beta \ge 1$ such that
\begin{align}
\label{uniformly_bounded_hessians_of_mf}
\left\|\nabla^2 \mfk\left(\xk\right)\right\| \le \beta - 1\quad \forall k \ge 0.
\end{align}
Showing that our construction of $m_f$ satisfies \cref{uniformly_bounded_hessians_of_mf} is the topic of \cref{simpler_h3}.
Their last assumption $H_4$ is an accuracy condition.
Namely, they assume there exists a constant $\delta_g>0$ such that for all $k \in \naturals$
\begin{align}
\label{accuracy}
\left\|\nabla m_k\left(\xk\right) - \nabla f\left(\xk\right)\right\| \le \delta_g \dk.
\end{align}
Showing that our construction of $m_f$ satisfies \cref{accuracy} is the topic of \cref{satisfying_accuracy}.

% The following lemma shows that $H_3$ is satisfied under our assumptions:

%
%Here, we let $\domain$ be some open set containing the feasible region: $\feasible \subset \domain$.  \sbnote{Do we really need $\domain$?}

%
% \subsection{Satisfying the assumptions}
% 
% \begin{comment}
% The following appears to be unused, we we can delete it.
% \end{comment}
% 
% \begin{lemma}
% \label{lipschitz_gradient}
% The function $f$ is differentiable and its gradient $\nabla f$ is Lipschitz continuous with constant $\lipgrad > 0$ in $\domain$.
% That is,
% \begin{align}
% \|\nabla f(x) - \nabla f(y)\| \le \lipgrad \|x - y\| \quad \forall x, y \in \domain.
% \end{align}
% \end{lemma}
% \begin{proof}
% This is a direct consequence of \cref{lipschitz_hessian}
% \end{proof}

\subsection{Bounded Hessians}
\label{simpler_h3}

First, we show that \cref{uniformly_bounded_hessians_of_f} can be used instead of \cref{uniformly_bounded_hessians_of_mf}.
% Namely, for this to be true, we also first assume:
% %
% %
% %
% %This is the result of the following lemma:
% 
% 
% \begin{assumption}
% \label{delta_max}
% There exists a $\dmax > 0$ such that $\dk \le \dmax$ for all $k \ge 0$.
% \end{assumption}

% This last assumption could also be satisfied simply by introducing a constraint $\dmax > 0$ and replacing the trust region update in Step 4 
% of \cref{linearly_constrained_dfo_simple} with
% \begin{align*}
% \dkpo \gets \min\left\{\omegainc\dk, \dmax \right\}
% \end{align*}


% \sbnote{The following lemma makes the assumption that the quadratic model function satisfies an error bound on the Hessian. 
% But this is only true if the model function defined by \cref{} is built with a $\Lambda$-poised sample set.  
% So this needs to be stated explicitly in the lemma.} 

% \begin{comment}
% Change this definition of conditioned to match the one for the linear case (Do not say the sequence is conditioned, say for an iterate is conditioned indep of k)
% \end{comment}

\begin{lemma}
\label[lemma]{replacing_h3}

Suppose that \cref{lipschitz_hessian} and \cref{uniformly_bounded_hessians_of_f} hold.
Let $\mfk$ be a quadratic model interpolating $f$ on a $\Lambda$-poised sample set
$Y$ over $B_{2}\left(\xk, \dk\right)$ for each $k \in \naturals$.
Then \cref{uniformly_bounded_hessians_of_mf} is also satisfied.
\end{lemma}

\begin{proof}

By \cref{uniformly_bounded_hessians_of_f}, we can choose $\beta_1 \ge 1$ to be such that for all $k \in\naturals$:
\begin{align*}
\left\|\nabla^2 f\left(\xk\right) \right\| \le \beta_1 - 1.
\end{align*}
% \cref{model_improving_algorithm},
Because $Y$ is $\Lambda$-poised, we can use \cref{scale_the_radius} to bound $\left\|\hat M\left(\bar \Phi, Y\right)^{-1}\right\|$, and apply \cref{3_16_replacement}.
Thus, we see that \cref{error_in_hessian} is satisfied.
Combining this with $\dk \le \dmax$, we see that
\begin{align*}
\left\|\nabla^2 f\left(\xk\right) - \nabla^2 m_f\left(\xk\right) \right\| \le \kappa_{h} \dk \le \kappa_{h} \Delta_{\text{max}}
\end{align*}
Defining $\beta_2 = \kappa_{h} \Delta_{\text{max}} + \beta_1 \ge 1$, we see that
\begin{align*}
\left\|\nabla^2 m_{f}\left(\xk\right)\right\| \le \left\|\nabla^2 m_{f}\left(\xk\right) - \nabla^2 f\left(\xk\right)  \right\| + \left\|\nabla^2 f\left(\xk\right) \right\|
\le \beta_2 - 1 .
\end{align*}
\end{proof}

% For any $x \in \feasible$, we have that the set of gradients of active constraints is linearly independent. That is, the vectors $\{\nabla c_i(x) |  \forall i \in \activei(x)\}$ is linearly independent.


\subsection{Satisfying the accuracy assumption}
\label{satisfying_accuracy}
% To show that the accuracy condition \cref{accuracy} is satisfied, we need to impose some conditions on the ellipsoidal sample regions $\sampletrk$.
% In particular, we require the ellipsoid to satisfy the following {\em suitability} condition:

After an ellipsoidal $\sampletrk$ is constructed,  sample points are then selected by applying  \cref{model_improving_algorithm} 
to a transformed problem in which the ellipsoid $\ellipsek$ is mapped onto a unit ball.
This process is summarized here.

Given some symmetric matrix $\qk \succ 0$, we can give $\qk$ an eigen-decomposition $\qk = V D^2 V^T$,
where $V^TV = I$ and $D$ is a diagonal matrix with positive entries.
% In fact, because we require $\qk$ to be positive definite, the diagonal entries of $D$ are strictly positive.
For any
% $\delta = \max_{x\in \ellipsek}\left\|x-\ck\right\|$
$\delta > 0$ define $T:\Rn \times \Rn_+ \rightarrow \Rn$ by $T(x; \delta) = \frac{\delta}{\sdk} DL^T\left(x - \ck\right)$.
Note that $T$ is invertible and can map $\sampletrk$ onto the $\delta$-ball
$B_2(0;\delta) = \left\{u \in \Rn \; | \; \|u\| \le \delta\right\}$:
\begin{align*}
\delta^2 \ge \|T\left(x; \sqrt{2}\delta\right)\|^2 = \left\|\frac {\sqrt{2}\delta} {\sdk} DV^T(x - \ck)\right \|^2
= \frac {2\delta^2} {\sdk^2} \left(x - \ck\right)^TQ\left(x - \ck\right) \\
\Longleftrightarrow \left(x - \ck\right)^TQ\left(x - \ck\right) \le \frac 1 2 \sdk^2.
\end{align*}
Likewise, with $\scaledellipsek$ defined in \cref{define_suitable_ellipsoid}, we have that
$T\left(\scaledellipsek; \delta\right) = B_2(0; \delta)$.

{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.5in]
\begin{flushleft}

\begin{algorithm}[H]
    \caption{Model Construction Algorithm}
    \label{model_construction_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
			Given a function $f : \Rn \to \reals$;
			ellipsoid parameters $\qk \succ 0$, $\ck$, and $\sdk$;
        	and sample set $Y$.
%         	with $\xk \in Y$;
%         	Iterate $\xk = y^{(0)} \in Y$
        \item[\textbf{Step 1}] \textbf{(Construct the Transformation}) \\
        	Give $\qk$ its eigen-decomposition $\qk = VD^2V^T$, and define
			$T(x; \sqrt{2}) = \frac{\sqrt{2}}{\sdk} D V^T\left(x - \ck\right)$.
%         	Compute $\delta = \max_{x \in \sampletrk} \|x - \ck\| = \frac {1} {\sqrt{2}\min_{i} D_{i, i}}$ as in \cref{define_the_sample_region}\\
% 			Construct the transformation
% 			which maps
% 				$T\left(\scaledellipsek; \sqrt{2}\right) = B_2(0; \sqrt{2})$, and
% 				$T\left(\sampletrk; \sqrt{2}\right) = B_2(0; 1)$.
        \item[\textbf{Step 1}] \textbf{(Construct the Sample Set)} \\
        Construct the transformed sample set $\hat Y$ by computing $T\left(y^{(i)}; \sqrt{2}\right)$ for each $y^{(i)} \in Y$. \\
        Call \cref{model_improving_algorithm} with $\Delta = 2$ on this sample to produce an improved sample set $\hat Y '$.
        Construct the unshifted sample set $Y'$ by computing $T^{-1}\left(\hat y^{(i)}; \sqrt{2}\right)$ for each $\hat y^{(i)} \in \hat Y'$.
        \item[\textbf{Step 2}] \textbf{(Construct Model Functions)} \\
        Evaluate $f$ at each $y^{(i)} \in Y'$, and construct $m_f$ with \cref{reg}
    \end{itemize}
\end{algorithm}


\end{flushleft}
\end{fullwidth}
}

This section analyzes the accuracy of the model functions constructed from the output of \cref{model_construction_algorithm}.
We first show the intermediate result
% s \cref{change_radius} and
\cref{shifted_ellipsoid}
before satisfying \cref{accuracy}.
In particular, \cref{linear_accuracy_is_satisfied} establishes error bounds based on the condition number of $\qk$.
In subsequent sections, we will describe several methods for choosing $\qk$ and $\ck$.

% We construct our sample set by calling \cref{model_improving_algorithm} after first transforming an ellipsoidal sample region 
% to the a ball centered around the origin.

% \sbnote{Steve wanted to double check the exponents in the following lemma.}

\begin{comment}
\color{red}
\begin{lemma}

\label[lemma]{change_radius}
% Suppose that \cref{bounded_hessians_assumption}, \cref{lipschitz_gradients_assumption}, and \cref{lipschitz_hessians_assumption} hold.

Assume that a function $f$ is twice continuously differentiable in an open domain $\domain$ containing $B(y^{(0)}; \Delta)$ and $\nabla^2 f$
is bounded by $\maxhessian$ and Lipschitz continuous in $\domain$ with constant $\liphess > 0$.

% Let $f$ be a function with bounded, Lipschitz continuous hessian.

% Assume that $f$ is twice continuously differentiable with bounded and Lipschitz continuous Hessian in $\domain$ with bound $M$ and Lipschitz constant $\liphess$.
% Let $Y$ be a poised set of $p + 1$ points, and let $R = \max_{i}\|y^i - y^{(0)}\|$.
% Let $m_f(x)$ denote the quadratic model of $f$ using \cref{reg}.

Suppose further, that there exists a quadratic model $m_f$ and constants $\Lambda_1, \Lambda_2, \Lambda_3$ 
such that for all $x \in B\left(y^{(0)}, \Delta\right)$,
\begin{align*}
\left|f(x) - m_f(x)\right| \le \Lambda_1 \\ % \Delta^3
\left\|\gradf(x) - \nabla m_f(x)\right\| \le \Lambda_2 \\ % \Delta^2
\left\|\nabla^2 f(x) - \nabla^2 m_f(x)\right\| \le \Lambda_3. % \Delta
\end{align*}
Then let $r > 1$ be arbitrary.
There exist constants $\Lambda_1', \Lambda_2', \Lambda_3'$ such that for all $x \in B\left(y^{(0)}, r\Delta\right)$,
\begin{align*}
\left|f(x) - m_f(x)\right| \le \Lambda_1' r^2, \\ % \Delta^3
\left\|\gradf(x) - \nabla m_f(x)\right\| \le \Lambda_2' r, \\ % \Delta^2
\left\|\nabla^2 f(x) - \nabla^2 m_f(x)\right\| \le \Lambda_3' r .% \Delta
\end{align*}
\end{lemma}

\begin{proof}

Let $x \in B\left(y^{(0)}, r\Delta\right)$, and define
\begin{align*}
\Lambda_3' = \Lambda_3 + \liphess \Delta, \\
\Lambda_2' = 2 \Delta M + \Lambda_2 +  \Delta \Lambda_3',\\
\Lambda_1' = \Lambda_1 + \Lambda_2' \Delta.
\end{align*}

By assumption, $\left\|\nabla^2 f(x) - \nabla^2 f(y)\right\| \le \liphess\left\|x-y\right\| \forall x,y \in \domain$.
Because of this, and because $m_f$ is a quadratic model, we have
\begin{align*}
\left\| \nabla^2 f\left(x\right) - \nabla^2 m_f\left(x\right)\right\|
= \left\| \nabla^2 f\left(x\right) - \nabla^2 m_f\left(y^{(0)}\right)\right\| \\
\le \left\| \nabla^2 f\left(x\right) - \nabla^2 f\left(y^{(0)}\right)\right\| + \left\| \nabla^2 f\left(y^{(0)}\right) - \nabla^2 m_f\left(y^{(0)}\right)\right\|
\le \liphess \|x - y\| + \Lambda_3 \le  \Lambda_3' r .
\end{align*}

By the mean value theorem and by assumption $\left\|\nabla^2 f\right\| \le \maxhessian$, 
there exist $\xi^{(1)} \in [y^{(0)}, x]$ and $\xi^{(2)} \in [y^{(0)}, x]$ with
\begin{align*}
\left\|\nabla f\left(x\right) - \nabla f\left(y^{(0)}\right) \right\|
\le \left\|x - y^{(0)}\right\| \left\| \nabla^2 f\left(\xi^{(1)}\right) \right\|
\le r \Delta \maxhessian, \\
\left\|\nabla m_f\left(x\right) - \nabla m_f\left(y^{(0)}\right) \right\|
\le \left\|x - y^{(0)}\right\| \left\| \nabla^2 m_f\left(\xi^{(2)}\right) \right\|
\le r \Delta \left(\maxhessian + \Lambda_3'\right).
\end{align*}
Thus, 
\begin{align*}
\left\|\nabla f\left(x\right) - \nabla m_f\left(x\right)\right\| \le 
\left\| \nabla f\left(x\right) - \nabla f\left(y^{(0)}\right) \right\| +
\left\|\nabla f\left(y^{(0)}\right) - \nabla m_f\left(y^{(0)}\right)\right\| + \\ \left\|\nabla m_f\left(y^{(0)}\right) - \nabla m_f\left(x\right)\right\|
\le r \Delta \maxhessian + \Lambda_2 + r \Delta \left(\maxhessian + \Lambda_3'\right) \\
\le r \left(2 \Delta \maxhessian + \Lambda_2 +  \Delta \Lambda_3'\right)
\le r \Lambda_2'.
\end{align*}

Finally, by the mean value theorem, there is a $\xi^{(3)} \in [y^{(0)}, x]$ with
\begin{align*}
\left|f(x) - m_f(x)\right|
\le \left| f\left(y^{(0)}\right) - m_f\left(y^{(0)}\right) \right| + \left\| \nabla f\left(\xi^{(3)}\right) - \nabla m_f\left(\xi^{(3)}\right) \right\| \left\|x - y^{(0)}\right\| \\
\le \Lambda_1 + \Lambda_2' \Delta r^2
\le \Lambda_1' r^2.
\end{align*}

\end{proof}
\color{black}
\end{comment}
% 
% 
% 
% \begin{align*}
% \left| f(x) -  f\left(y^{(0)}\right) \right|
% \le \left\|x - y^{(0)}\right\| \left\| \nabla f\left(\xi\right) \right\|
% \le r \Delta \liphess \\
% \left\|\nabla m_f(x) - \nabla m_f\left(y^{(0)}\right) \right\|
% \le \left\|x - y^{(0)}\right\| \left\| \nabla^2 m_f\left(y^{(0)}\right) \right\|
% \le r \Delta \left(\liphess + \Lambda_3'\right)
% \end{align*}
% Thus,
% \begin{align*}
% \left\|\nabla f(x) - \nabla m_f(x)\right\| \le 
% \left\| \nabla f(x) - \nabla f(y^{(0)}) \right\| + \left\|\nabla f(y^{(0)}) - \nabla m_f(y^{(0)})\right\| + \left\|\nabla m_f(y^{(0)}) - \nabla m_f(x)\right\| \\
% \le r \Delta \liphess + \Lambda_2 + r \Delta \left(\liphess + \Lambda_3'\right)
% \le r \left(2 \Delta \liphess + \Lambda_2 +  \Delta \Lambda_3'\right)
% \le r \Lambda_2'.
% \end{align*} 
% 
% 
% Define $z = y^{(0)} + \Delta\frac{x - y^{(0)}}{\left\|x - y^{(0)}\right\|}$, and notice $z \in B_{\infty}\left(y^{(0)}, \Delta\right)$.
% 
% 
% 
% Subtracting this from
% \begin{align*}
% m_f(x) = m_f\left(y^{(0)}\right) + \nabla m_f\left(y^{(0)}\right)^T\left(x - y^{(0)}\right) + (x - y^{(0)})^T\nabla^2 m_f(y^{(0)}) (x - y^{(0)}),
% \end{align*}
% 
% 
% 
% and define $z = y^{(0)} + \Delta\frac{x - y^{(0)}}{\left\|x - y^{(0)}\right\|}$.
% Because $z \in B\left(y^{(0)}, \Delta\right)$, we know that
% 
% \begin{align*}
% \left|f(z) - m_f(z)\right| \le \Lambda_1 \\ % \Delta^3
% \left\|\gradf(z) - \nabla m(z)\right\| \le \Lambda_2 \\ % \Delta^2
% \left\|\nabla^2 f(z) - \nabla^2 m(z)\right\| \le \Lambda_3 % \Delta
% \end{align*}
% and that there exists 
% % $\alpha \in [0, 1]$, 
% $\chi_1 \in [y^{(0)}, x]$ and
% $\chi_2 \in [z, x]$
% such that such that
% \begin{align*}
% f(x) &= f(y^{(0)}) + \nabla f\left(y^{(0)}\right)^T(x - y^{(0)}) + \left(x - y^{(0)}\right)^T\nabla^2 f (\chi_1)\left(x - y^{(0)}\right) \\
% f(x) &= f(z) + \nabla f\left(z\right)^T(x - z) + \left(x - z\right)^T \nabla^2 f (\chi_2)\left(x - z\right) \\
% m_f(x) &= m_f\left(y^{(0)}\right) + \nabla m_f\left(y^{(0)}\right)^T\left(x - y^{(0)}\right) + \left(x - y^{(0)}\right)^T\nabla^2 m_f\left(y^{(0)}\right)\left(x - y^{(0)}\right)
% \end{align*}
% we have
% \begin{align*}
% f(x) - m_f(x) = f\left(y^{(0)}\right) - m_f\left(y^{(0)}\right) 
% + \left[\nabla f\left(y^{(0)}\right) - \nabla m_f\left(y^{(0)}\right)\right]^T\left(x - y^{(0)}\right) \\
% + \left(z - y^{(0)}\right)^T\left[\nabla^2 f(\chi_1) - \nabla^2 m_f(y^{(0)})\right]\left(z - y^{(0)}\right) \\
% \left|f(x) - m_f(x)\right| 
% \le \left|f\left(y^{(0)}\right) - m_f\left(y^{(0)}\right)\right|
% + \left\|\nabla f\left(y^{(0)}\right) - \nabla m_f\left(y^{(0)}\right)\right\| \|
% \end{align*}
% 
% 
% 
% \begin{align*}
% \left\| \nabla^2 f\left(x\right) - \nabla^2 m_f\left(x\right) \right\| \\
% = \left\| \nabla^2 f\left(x\right) - \nabla^2 f\left(y\right) \right\| 
% + \left\| \nabla^2 f\left(y\right) - \nabla^2 m_f\left(y\right) \right\|
% + \left\| \nabla^2 m_f\left(y\right) - \nabla^2 m_f\left(x\right) \right\| \\
% \le \liphess \left\|x - y \right\| + \Lambda_2 + 
% \end{align*}
% 
% 
% 
% \begin{align*}
% \nabla^2 f\left(x\right) \le \nabla^2 f\left(y^{(0)}\right) + \liphess \|x - y\| \\
% \left\| \nabla^2 f\left(x\right) - \nabla^2 f\left(y^{(0)}\right)\right\| \le \liphess \|x - y\| \\
% \left\| \nabla^2 f\left(x\right) - \nabla^2 m_f\left(y^{(0)}\right)\right\| + \left\| \nabla^2 m_f\left(y^{(0)}\right) - \nabla^2 f\left(y^{(0)}\right)\right\| \le \liphess \|x - y\| \\
% \left\| \nabla^2 f\left(x\right) - \nabla^2 m_f\left(y^{(0)}\right)\right\| \le \liphess r + \Lambda_3 \le \left(\liphess + \Lambda_3\right) r \\
% \end{align*}
% 
% 
% 
% 
% \begin{align*}
% \phi_i\left(x\right) = \phi_i\left(y\right) + 
% \end{align*}
% 
% 
% 

The following theorem allows us to translate error bounds derived for the ball $B_2(0;\delta)$ to the ellipsoid $\ellipsek$.


% \begin{boxedcomment}
% Change this to $V$.
% \end{boxedcomment}


%
%
% \begin{align*}
% T(x; \delta) = \frac{\delta}{\delta_k} D V^T\left(x - \ck\right) \\
% \hat f (u) = f\left(T^{-1}(u; \delta)\right) \\
% \hat m_f(u) \approx \hat f(u) \\
% m_f(x) = \hat m_f\left(T(x; \delta)\right)
% \end{align*}


%Conversely, $ T^{-1}(u) = \frac 1 {\delta} LD^{-1}u + c$ maps the $\delta$-ball to the ellipsoidal region $ \ellipsek $.
% \cref{fully_quadratic}
\begin{lemma}

\label[lemma]{shifted_ellipsoid}
Let $\sdk>0$, $\ck \in \Rn$ and a symmetric matrix $\qk \succ 0$ be given.
Let the eigen decomposition of $\qk$ be $\qk = VD^2V^T$, $V^TV = I$, where $D$ is diagonal with positive entries.
Let $\scaledellipsek$ be defined as in \cref{define_suitable_ellipsoid}:
\begin{align*}
\scaledellipsek = \left\{x \in \Rn \bigg | \left(x - \ck\right)^T \qk\left(x - \ck\right) \le \sdk^2 \right\}
% \subseteq B_{\infty}\left(\xk, \dk\right).
\end{align*}

For $\delta > 0$, define the transformation $T(x; \delta) = \frac{\delta}{\sdk} D V^T\left(x - \ck\right)$,
and let $\delta_r = \max_{x \in \scaledellipsek}\|x - \ck\|$.
Let $\hat m_f(u)$ be a model of the shifted objective $\hat f(u) = f(T^{-1}(u; \delta_r))$ such that,
for constants $\kappa_{ef}, \kappa_{eg}, \kappa_{eh} > 0$, the following error bounds hold for all $u \in B_2(0;\delta_r)$:

\begin{align}
|\hat m_f(u) - \hat f(u)| \le \kappa_{ef} \delta_r^3, \label{shifted_ellipsoid_bounds}\\
\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \le \kappa_{eg}\delta_r^2, \label{shifted_ellipsoid_bounds2} \\
\|\nabla^2 \hat m_f(u) - \nabla^2 \hat f(u)\| \le \kappa_{eh}\delta_r.  \label{shifted_ellipsoid_bounds3}
\end{align}

Then, with
\begin{align*}
\kappa_{ef}' = \kappa_{ef}, \\
\kappa_{eg}' = \kappa_{eg}\sqrt{\kappa(\qk)}, \\
\kappa_{eh}' = \kappa_{eh}\condition(\qk),
\end{align*}
the model function $m_f(x) = \hat m_f(T(x; \delta_r))$ satisfies the following error bounds for all
$x \in T^{-1}\left(B_2(0; \delta_r)\right) = \scaledellipsek$:
\begin{align}
| m(x) - f(x)| \le \kappa_{ef}'\delta_r^3, \label{transformed_error_bounds} \\
\|\nabla  m(x) - \nabla  f(x)\| \le \kappa_{eg}'\delta_r^2, \label{transformed_error_bounds2} \\
\|\nabla^2 m(x) - \nabla^2 f(x)\| \le \kappa_{eh}'\delta_r \label{transformed_error_bounds3}.
\end{align}
\end{lemma}

\begin{proof}


% Notice  that for all $x\in \ellipsek$ we have 
% \begin{align*}
% \|x-c\| \le \delta \\
% \|T(x-c)\| \le \delta \\
% \end{align*}
% so that $\frac{\|T(x-c)\|}{\|x-c\|} \le 
% 
% Observe that for any $T(x) \in B_2(0; \delta)$,
% 
% % \frac{\left(\xk - \ck\right)^T}{\left\|x - \ck\right\|} \frac{2}{\sdk^2}Q\frac{\left(\xk - \ck\right)}{\left\|x - \ck\right\|} 

% \begin{align*}
% \frac{2\delta^2}{\sdk^2} \min_{i \in [n]} D_{i,i}
% = \frac{2\delta^2}{\sdk^2}\sqrt{\lambda_{\text{min}}\left(\qk\right)}
% \le \min_{\left\|x - \ck\right\| = 1}\left(x - \ck\right)^T \frac{2\delta^2}{\sdk^2}Q\left(x - \ck\right)^T
% = \min_{\left\|x - \ck\right\|}\left\| T(x)\right\|^2
% \end{align*}
% 
% \begin{align*}
% 1 \ge \frac{\|T(x)\|^2}{\delta^2}
% \ge \left(x - \ck\right)^T \frac{2}{\sdk^2}Q\left(x - \ck\right)^T \\
% \ge \left\|x - \ck\right\|^2\frac{2}{\sdk^2}\sqrt{\lambda_{\text{min}}\left(\qk\right)}
% = \left\|x - \ck\right\|^2\frac{2}{\sdk^2} \min_{i \in [n]} D_{i,i} 
% \end{align*}
% 
% \begin{align*}
% \left(\xk - \ck\right)^T \frac{2}{\sdk^2}Q\left(\xk - \ck\right)^T \\
% \le \left\|x - \ck\right\|^2\frac{2}{\sdk^2}\sqrt{\lambda_{\text{max}}\left(\qk\right)}
% = \left\|x - \ck \right\|^2\frac{2}{\sdk^2} \max_{i \in [n]} D_{i,i} 
% \le \delta^2
% \end{align*}
% 
% 
% \begin{align*}
% \left\|x - \xk\right\|^2\frac{2}{\sdk^2} \min_{i \in [n]} D_{i,i} 
% = \left\|x - \xk\right\|^2\frac{2}{\sdk^2}\sqrt{\lambda_{\text{min}}\left(\qk\right)} \\
% \le \left(\xk - \ck\right)^T \frac{2}{\sdk^2}Q\left(\xk - \ck\right)^T
% \le 1
% \end{align*}

% If $T(x) \in B_2(0; \delta)$, then
% \begin{align*}
% \delta^2 \ge \|T(x)\|^2 = \frac 2 {\sdk^2}\left\|\left(x - \ck\right)^TLD^2L\left(x - \ck\right)\right\| \ge
% \min_{i \in [n]} D_{i, i}^2 \left\|x - \ck\right\|^2
% \end{align*}
% With $r = \max_{x \in \scaledellipsek}\|x - \ck\|$, notice that
% $\scaledellipsek \subseteq B_{\infty}\left(\xk, \dk\right)$ implies $\dk \ge r$.
Noting that $D_{i, i} > 0$, observe that
\begin{align*}
\delta_r^2 = \frac {\sdk^2} {\lambda_{\text{min}}\left(\qk\right)} = \frac {\sdk^2} {\min_{i \in [n]} D^2_{i, i}},
\end{align*}
so $\min_{i} \Delta_{i, i} = \frac{\sdk^2}{\delta_r^2}$.
%\delta = \max_{v \in E} \|T(v; \delta)\|
%= \max_{v \in E} \|\frac {\delta}{\sdk} DL^T\left(v - \ck\right)\|
%\ge \frac {\delta\min_{i \in[n]} D_{i,i}}{\sdk}\max_{v \in E}\|\left(v - \ck\right)\|
%= \frac {\delta\min_{i \in[n]} D_{i,i}}{\sdk}r
% \|v - \ck\| = \sdk \Longrightarrow 
%And for any $x = T(v; \delta)$:
%\begin{align*}
%\frac{1}{\sdk} 
%= \frac {1} {\sqrt{\lambda_{\text{min}}\left(\qk\right)}} 
%= \frac 1 {\min_{i \in [n]} D_{i, i}} 
%\end{align*}
% = \max_{x \in T^{-1}\left(B_2\left(0, \delta\right)\right)}\left\|x - \ck\right\|^2
Thus,
\begin{align*}
\condition\left(\qk\right) 
= \kappa\left(D^2\right) 
= \frac{\max_{i}D_{i,i}^2}{\min_{i}D_{i,i}^2} 
= \frac{\delta_r^2}{\sdk^2} \max_{i}D_{i,i}^2 = \frac{\delta_r^2}{\sdk^2}\|D\|^2 \\
\Longrightarrow \frac{\delta_r} {\sdk} \|D\| = \sqrt{\condition\left(\qk\right)}.
\end{align*}
%  \le \frac{\kappa_{\lambda}}{\delta}.
Let $x \in \ellipsek$ be arbitrary and let $u = T(x) \in B_2(0;\delta_r)$.
Then
\begin{align*}
 | m_f(x) - f(x)| = |\hat m(u) - \hat f(u)| \le \kappa_{ef}'\delta_r^3.
\end{align*}
Similarly, for the gradient we find:
\begin{align*}
\| \nabla m_f(x) - \nabla f(x)\| &= \left\|\frac{\delta_r} {\sdk}DL^T\left(\nabla\hat m_f(u) - \nabla \hat f(u)\right)\right\| \\
& \le \frac{\delta_r} {\sdk} \|DL^T\|\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \\
& \le \sqrt{\condition(\qk)}\kappa_{eg} \delta_r^2 = \kappa_{eg}' \delta_r^2.
\end{align*}
Finally,  for the Hessian, we have
\begin{align*}
\| \nabla^2 m_f(x) - \nabla^2 f(x)\| & = \left\|\frac{\delta_r^2} {\sdk^2}DL^T\left(\nabla\hat m_f(u) - \nabla \hat f(u)\right)LD^T\right\| \\
& \le \frac{\delta_r^2} {\sdk^2} \|D\|^2\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \\
& \le \condition(\qk)\kappa_{eh} \delta_r = \kappa_{eh}' \delta_r.
\end{align*}

\end{proof}

\cref{shifted_ellipsoid} shows that a uniform bound on the condition number of $\qk$ will produce accurate model functions.
Indeed, recall from \cref{set_is_poised} that \cref{model_improving_algorithm} produces a $\Lambda$-poised sample set, for $B_2(0;\delta)$.
Then \cref{scale_the_radius} and \cref{4_1_14} ensure $m_f$ will satisfy the provided error bounds over the ellipsoidal region as well.
We can now satisfy the accuracy condition \cref{accuracy}.


% It follows that  $m_f$ is $\kappa$ fully quadratic, with constants $\kappa_{ef}', \kappa_{eg}', \kappa_{eh}'$.  

% Within our analaysis, we use this
% \begin{align*}
% \label{accuracy}
% \end{align*}



% \sbnote{Move the following to later}
% For the purposes of a convergence proof, we need only satisfy the weaker accuracy condition \cref{accuracy}.
% Notice that, in practice, the model functions do not need to be mapped to the $\delta$ ball, because $\Lambda$-poisedness is scale invariant \cite{introduction_book}.
% The implications of this theorem are discussed further in the convergence discussion \cref{linear_convergence_discussion}.


%Because the ellipsoid we construct must be feasible with respect to both the trust region and the constraints,
%we simplify notation by creating a matrix $\lctra$ and vector $\lctrb$ from $\lca$ and $\lcb$ defined in \cref{eq:DFO-linear} as follows:
%\begin{align}
%\polyk = \{x \in \Rn | \; \lca x \le \lcb, \|x - \xk\|_{\infty} \le \dk \} \label{polyhedron_k} 
%= \{x \in \Rn | \lctra x \le \lctrb, \|{\lctra}_i\| = 1 \}.
%\end{align}
%This is the normalized polyhedron formed by adding the trust region constraints for iteration $k$ to the problem constraints.
%


% The following is an immediate consequence of \cite[Lemma 3.8]{introduction_book}.
% \begin{lemma}
% \label{scale_the_set}
% Let $\Delta, \Delta' > 0$.
% If a set $\hat Y$ is $\Lambda$-poised over a ball $B(0; \Delta)$,
% then the set $Y = \frac{\Delta'}{\Delta} \hat Y$ is $\Lambda$-poised over $B_2(0; \Delta')$.
% \end{lemma}

\begin{theorem}
\label{linear_accuracy_is_satisfied}

Suppose that \cref{lipschitz_hessian}, \cref{uniformly_bounded_hessians_of_f}, and \cref{interior_point} hold.
Suppose further that for each iterate $k$, the ellipsoids $\ellipsek$ and $\scaledellipsek$ provided by the \emph{ConstructTrustRegion} subroutine 
are suitable according to \cref{define_suitable_ellipsoid},
and the sample set is constructed by calling \cref{model_construction_algorithm}.


% \item[1.] The ellipsoid $\ellipsek = \left\{x \in \Rn \bigg| \left(x - \ck\right)^T\qk\left(x - \ck\right) \le \frac 1 2 \sdk^2 \right\}$ 
% satisfies $\ellipsek \subseteq \polyk$ as defined in \cref{polyhedron_k}
% \item[2.] The ellipsoid $\scaledellipsek = \left\{x \in \Rn \bigg | \left(x - \ck\right)^T\qk\left(x - \ck\right) \le  \sdk^2 \right\}$ satisfies $\xk \in \scaledellipsek$.
% \item[3.] $\condition \left(\qk\right)$ is bounded independently of $k$.

Then, $m_f\left(\xk\right) = f\left(\xk\right)$, and
the accuracy condition \cref{accuracy} is satisfied for each iterate $k$.
Namely, there exists $\kappa_{g} > 0$ such that 
\begin{align*}
\left\|\nabla m_f\left(\xk\right) - \nabla f\left(\xk\right)\right\| \le \kappa_g \dk \quad \forall k \in \naturals.
\end{align*}
\end{theorem}

\begin{proof}

Fix an iterate $k$.
The assumptions provide two ellipsoids:
\begin{itemize}
\item $\ellipsek = \left\{x \in \Rn \bigg | \left(x - c^{(k)} \right)^T \qk \left(x - c^{(k)}\right) \le \frac 1 2 {\delta_k}^2 \right\}$ with $\ellipsek \subset \polyk$.
\item $\scaledellipsek = \left\{x \in \Rn \bigg | \left(x - c^{(k)}\right)^T \qk \left(x - c^{(k)}\right) \le {\delta_k}^2 \right\}$ with $\xk \in \scaledellipsek$.
\end{itemize}
As in \cref{shifted_ellipsoid}, we can give $Q^{(k)} = LD^2L^T$ its eigen-decomposition, 
and for any $\delta > 0$ define the transformation $T(x; \delta) = \frac{\delta}{\sdk^2} D L^T\left(x - \ck\right)$.
Notice that with $\delta = \delta_2 = \sqrt{2}$,
the transformation $T\left(x; \delta_2\right)$ maps $\sampletrk = \ellipsek$ to the unit ball.
After using \cref{model_improving_algorithm} to choose sample points, we know by \cref{set_is_poised}
that there is a bound $\Lambda>0$ with $\left\| M\left(\bar \Phi, \hat Y\right)^{-1}\right\| \le \Lambda$ depending only on $p$ and $\ximin$.
Next, we consider the shifted sample set $\bar Y = \sqrt{2}\frac{\delta_r}{\delta_2} \hat Y$, where $\delta_r = \max_{x \in \scaledellipsek}\|x - \ck\|$.
Notice that the scaled matrix in $\cref{nce_scale}$ is $M\left(\bar\Phi, \hat Y\right) = \hat M\left(\bar \Phi, \bar Y\right)$, so we can use \cref{3_16_replacement} to introduce constants $\kappa_f, \kappa_g, \kappa_h > 0$ such that
\begin{align*}
\left| \hat {f}\left(u\right) - \hat{m}_f\left(u\right) \right|\le \kappa_f\Lambda \delta_r^3, \\
\left\|\nabla \hat {f}\left(u\right) - \nabla \hat{m}_f\left(u\right) \right\|\le \kappa_g\Lambda \delta_r^2, \\
\left\|\nabla^2 \hat {f}\left(u\right) - \nabla^2 \hat{m}_f\left(u\right) \right\|\le \kappa_h\Lambda \delta_r.
\end{align*}
for all $u \in B_2\left(0, \delta_r\right)$.
This means that the shifted functions
$\hat {m}_f(u) = m_f(T^{-1}(u); \delta)$ and
$\hat f (u) = f(T^{-1}(u; \delta))$
as described in \cref{shifted_ellipsoid},
satisfy \cref{shifted_ellipsoid_bounds}---\cref{shifted_ellipsoid_bounds3},
and therefore \cref{transformed_error_bounds}---\cref{transformed_error_bounds3}.



% and scaled sample set $\hat Y$ is lambda poised over $B_2(0; \delta_2)$.
% that there exist constants $\kappa_f, \kappa_g, \kappa_h$ such that for all $u \in B(0, \delta_2)$:
% \begin{align*}
% \left\| \hat {f}\left(u\right) -  \hat{m}_f\left(u\right) \right\|\le \kappa_f \delta_2^3, \\
% \left\|\nabla \hat {f}\left(u\right) - \nabla \hat{m}_f\left(u\right) \right\|\le \kappa_g \delta_2^2, \\
% \left\|\nabla^2 \hat {f}\left(u\right) - \nabla^2 \hat{m}_f\left(u\right) \right\|\le \kappa_h \delta_2.
% \end{align*}
% With , by \cref{scale_the_set},
% we can scale these same points by $\frac{\delta_r}{\delta_2}$ to obtain a $\Lambda$ poised set over $B_2(0; \delta_r)$.
% Thus, by \cref{quadratic_errors}, there exist constants $\kappa_f, \kappa_g, \kappa_h$ such that for all $u \in B_2(0; \delta_r)$:



% This, along with \cref{lipschitz_hessian} and \cref{uniformly_bounded_hessians_of_f} satisfy the assumptions for \cref{change_radius}.
% We can conclude that there is another constant $\Lambda_2$ such that for all $u \in B(0, 2\delta)$:
% \begin{align*}
% \left\|\nabla \hat {f}\left(u\right) - \nabla \hat{m}_f\left(u\right) \right\|\le 4 \Lambda_2 \left(2\delta\right)^2 L \sqrt{p+1} = {\kappa'}_g\delta^2
% \end{align*}
% where $\kappa_{g}' = 16 \Lambda_2 L \sqrt{p+1}$.

% After using  \cref{alphas_are_bounded} to construct an $\epsilon_{\alpha} > 0$ 
Because $\condition \left(\qk\right)$ is bounded by some $\epsilon_{\alpha} > 0$ independently of $k$,
and defining $\kappa'_{g} =  \kappa_g\sqrt{\epsilon_{\alpha}}\Lambda\dmax$, we see that
we can use  \cref{shifted_ellipsoid} to conclude that for all $x_0 \in \scaledellipsek$:
\begin{align*}
\left\|\nabla f\left(x_0 \right) - \nabla m_f\left(x_0\right)\right\| \le 
\kappa_g  \Lambda\dk^2 \sqrt{\condition \left(\frac 2 {\delta_k} Q^{(k)}\right)}
=  \kappa_g \sqrt{\epsilon_{\alpha}}\Lambda\dmax\dk 
= \kappa'_g\dk.
\end{align*}
In particular, $\xk \in \scaledellipsek$.
\end{proof}

% Note that while applying \cref{quadratic_errors},
% we assumed there is a point on the boundary of the sphere after running
% \cref{model_improving_algorithm}.
% In practice, this is not always ensured, but it is likely to be the case when a point of $Y$ is replaced.


% Notice that although \cref{linear_accuracy_is_satisfied} requires $\delta \le 1$, the authors of  show that $\dk \to 0$ within Lemma 3.1 and Lemma 3.2.
% Within Lemma 3.1, $\dk \le 1 $ explicitly. 


\section{Ellipsoidal Trust Region Approach}\label{sec:ellipsoidal}

The main idea of the ellipsoidal method is to define the sample trust region to be a feasible ellipsoid as in \cref{define_the_sample_region}:
\begin{align*}
\sampletrk = \ellipsek = \left\{x \in \Rn \bigg | (x - \ck)^T \qk (x - \ck) \le \frac 1 2 \sdk^2 \right\}
\end{align*}
where $\qk$ is a positive definite matrix, $\ck$ is the center of the ellipsoid, and $\sdk$ is a constant determining the ellipsoid's radius.   
$\qk$ and $\ck$ are chosen so that the ellipsoid conforms roughly to the shape of the feasible region near the current iterate, 
while ensuring that it lies entirely within the intersection of the feasible region and the outer trust region.

% \cref{linear_convergence_discussion} analyzes the convergence of one version of the algorithm.


\subsection{A safe ellipsoid}

\subsubsection{Construction}
\label{the_safe_ellipsoid}

This section shows how to construct one possible ellipsoid that satisfies \cref{define_suitable_ellipsoid}.
We define the active constraints at a point $x \in \feasible$ by
\begin{align}
\activei(x) = \left\{i \in [m] | {\lca}_ix = {\lcb}_i \right\}. \label{define_activei}
\end{align}
Recall that $\lca$ and $\lcb$ are defined by \cref{eq:DFO-linear}.

For any iterate $k$, if there are no active constraints, $\activei\left(\xk\right) = \emptyset$, then we are free to choose
\begin{align}
\label{define_linear_trivial_ellipse}
\qk = I, \quad \ck = \xk, \quad \textrm{and} \quad \sdk = \min\left\{\dk, \min_{i \in [m]}{b_i - A_i x}\right\}.
\end{align}
We show within \cref{trivial_ellipsoid_exists} that this is a suitable ellipsoid.
Otherwise, we begin by constructing a direction $\uk$ that is maximally feasible with respect to the active constraints.
To make this precise, let $\mathcal S \subseteq \{1, \ldots, m\}$ be arbitrary.
We define the set of ``most'' feasible direction from $x$, and quantify how feasible they are with the definitions:
\begin{align}
\alphaone (\mathcal S) = \begin{cases}
\argmax_{\|u\| = 1} \min_{i \in \mathcal S} -u^T{\lca}_i & \text{if} \; \mathcal S \ne \emptyset \\
\emptyset & \text{if} \; \mathcal S = \emptyset
\end{cases} \label{define_alpha_one} \\
\alphatwo(\mathcal S) = \begin{cases}
\max_{\|u\| = 1} \min_{i \in \mathcal S} -u^T{\lca}_i & \text{if} \; \mathcal S \ne \emptyset \\
1 & \text{if} \; \mathcal S = \emptyset
\end{cases} \label{define_alpha_two} \\
\alphathree(x) = \alphatwo\left(\activei(x)\right). \label{define_alpha_three}
\end{align}
Here, $\alphaone$ is a set of directions that head away from each of the active constraints at a point.
For each iterate, this produces the quantities
\begin{align}
\alphak =  \alphathree\left(\xk\right) \label{define_alpha_k}, \\
\uk \in  \alphaone\left(\activei\left(\xk\right)\right). \label{define_u_k}
\end{align}
We then compute
\begin{align}
\alphakp=\left(1+\frac{1}{\sqrt{2}}\right)\sqrt{1+\left(\alphak\right)^2}, \label{define_alphakp} \\
\deltaf = \frac 1 {\alphakp} \min\left\{\dk, \min_{i \in [m] \setminus \activei\left(\xk\right)} \left[{\lcb}_i - \left({\lca}_i\right)^T\xk\right]\right\}. \label{define_deltaf}
\end{align}
Notice that the minimization in the above expression computes the minimum distance to a non-active constraint.
It will be convenient to define the rotation matrix and affine mapping
\begin{align}
\rotk = 2\frac{(e_1 + \uk)(e_1 +\uk)^T}{(e_1 +\uk)^T(e_1 +\uk)} - \boldsymbol I, \label{define_r} \\
T_k(x) = \rotk\left(x - \xk\right). \label{define_affine_mapping}
\end{align}
Recall that $e_1 = (1, 0, \ldots, 0)^T$, and observe that $\rotk e_1 = \uk$, $\rotk \uk = e_1$, $\det(\rotk) = 1$, and 
$\rotk \rotk ^T = \rotk ^T\rotk = I$.

We can then define the ellipsoid as
\begin{align}
\label{define_linear_nontrival_ellipsoid}
\qk = \rotk^T \begin{pmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \left({\alphak}\right)^{-2} \boldsymbol I \\
\end{pmatrix} \rotk,
\quad
\ck = \xk+\deltaf \uk,
\quad
\textrm{and}
\quad
\sdk=\deltaf
\end{align}
whenever $\activei\left(\xk\right) \ne \emptyset$.



% Now, fix some iterate $k$.
% If there are no active constraints, $\activei = \emptyset$, then we are free to choose
% \begin{align}
% \label{define_linear_trivial_ellipse}
% \qk = I, \quad \ck = \xk, \quad \textrm{and} \quad \sdk = \dk.
% \end{align}
% We show within \cref{trivial_ellipsoid_exists} that this is a suitable ellipsoid.

% Otherwise, we can use \cref{alphas_are_bounded} to satisify the conditions of \cref{nontrivial_ellipsoid_exists}.

\subsubsection{Suitability}

We show that this construction provides a suitable ellipsoid according to \cref{define_suitable_ellipsoid}.

% \begin{comment}
% Somehow it doesn't make sense to say that for an iterate, this construction satisfies a bound on the condition number.
% \end{comment}

\begin{lemma}
\label[lemma]{trivial_ellipsoid_exists}

Let $\activei$ be defined by \cref{define_activei}.

If $\activei\left(\xk\right) = \emptyset$ during iteration $k$, then \cref{define_linear_trivial_ellipse} defines a suitable ellipsoid for iteration $k$ according to \cref{define_suitable_ellipsoid}.
\end{lemma}
% $\epsilon > 0$, $c \in \Rn$  and a positive definite, symmetric matrix $Q$, 
\begin{proof}

If $\activei\left(\xk\right) = \emptyset$, then we are free to use \cref{define_linear_trivial_ellipse}.
This simplifies $\scaledellipsek$ to
\begin{align*}
\left(x - \ck\right)^2 \qk \left(x - \ck\right)^2 \le \sdk^2 \Longrightarrow \left\|x - \xk\right\|^2 \le \dk^2.
\end{align*}
Because $\ellipsek$ is then a sphere within the outer trust region with radius less than the distance to the nearest constraint, $\ellipsek \subseteq \polyk$.
Because the sphere $\scaledellipsek$ is centered at $\xk$, $\xk \in \scaledellipsek$.
Also, $\condition\left(\qk\right) = 1$.

% \color{red}
% \begin{align*}
% \min_{i \in [m] \setminus \activei\left(\xk\right)}{b_i - A_i x}
% \end{align*}
% \color{black}
\end{proof}


\begin{lemma}
\label[lemma]{alphas_are_positive}

Let $\alphathree$ be defined by \cref{define_alpha_three}.

Suppose that \cref{interior_point} holds.

Then, $1 \ge \alphathree(y) > 0$ for any $y \in \feasible$.
\end{lemma}

\begin{proof}

Let $y \in \feasible$, and let $\activei(x)$ be defined by \cref{define_activei}.
If $\activei(y) = \emptyset$, then $\alphathree(y) = 1 > 0$.
Otherwise, let $i \in \activei(y)$, so that by \cref{eq:DFO-linear}, $c_i(y) (Ay - b)_i= 0$.
% We know that for each $i \in \activei(x_0)$ both $c_i(x_0) = 0$ and $c_i(\bar x) < 0$.
% subtract the equations: $G_i^T \bar x < g_i$ and $G_i^T  x_0 = g_i$ to find
We know that if $\bar x$ is defined as in \cref{interior_point}, then
\begin{align*}
c_i(\bar x) = c_i(y) + {\lca}_i(\bar x - y)
\Longrightarrow {\lca}_i(\bar x - y) \le c_i(\bar x) - c_i(y) = c_i(\bar x) < 0.
\end{align*}
Using \cref{polyhedron_k}, we can write this as
\begin{align*}
-{\lca}_i\frac {\bar x - y}{\|\bar x - y\|} > 0  \Longrightarrow \min_{i \in \activei(y)} -{\lca}_i\frac {\bar x - y}{\|\bar x - y\|} > 0.
\end{align*}
Using this along with the definitions of $\alphaone$, $\alphatwo$, and $\alphathree$ in \cref{define_alpha_one}, \cref{define_alpha_two}, and \cref{define_alpha_three}; we see
\begin{align*}
\alphathree(y) = \alphatwo\left(\activei(y)\right) = \max_{\|u\| = 1} \min_{i \in \activei(y)} -{\lca}_i^Tu
\ge \min_{i \in \activei(y)} - {\lca}_i^T\frac {\bar x - y}{\|\bar x - y\|} > 0.
\end{align*}

We know that $\alphathree(y) \le 1$ because it is the dot product of two vectors of length one:
if $\|u\| = 1$, then $\left|u^T {\lca}_i\right|^2 \le \|u\|\|{\lca}_i\| = 1$ by CauchySchwartz.

\end{proof}

\begin{lemma}
\label[lemma]{alphas_are_bounded}

Let ${\alphak}$ be defined by \cref{define_alpha_k}.

Suppose that \cref{interior_point} holds.

There exists an $\epsilon_{\alpha} > 0$ such that $\alphak \ge \epsilon_{\alpha} \; \forall \; k \in \naturals$.
\end{lemma}
\begin{proof}

Let $\activei$ be defined by \cref{define_activei}.
Because there are $m$ constraints, each $\activei(x)$ is one of the $2^m$ subsets of  $\{1, 2, 3, \ldots, m\}$.
This means that $\alphaone$, $\alphatwo$, and $\alphak$ as defined by \cref{define_alpha_one}, \cref{define_alpha_two}, and \cref{define_alpha_k} can only take on at most $1 + 2^m$ values.
By \cref{alphas_are_positive}, we know that each of these values must be positive.
Thus, we are free to choose $\epsilon_{\alpha}$ to be the smallest of these values.
\end{proof}

% 
% \begin{align*}
% \|s\| \le \pi t \\
% u ^T(tu + s) \ge y \|tu + s\| \\
% t \ge y (t + \|s\|) \\
% \end{align*}

It will be useful to define some intermediate cones.
Namely, for any scalar $\pi$, direction $u$, and point $c$, we define the cone
\begin{align}
\mathcal C\left(\pi, u, c\right) = \left\{c + t u + s \in \Rn | \; s^Tu= 0, t \ge 0, \|s\| \le \pi t\right\}.
\end{align}
We can use this to define shifted and unshifted cones about the point $\xk$ along a direction $\uk$:
\begin{align}
\shiftedcone = \mathcal C\left(\alphak, e_1, 0\right), \label{defineshiftedcone} \\
\unshiftedcone = \mathcal C\left(\alphak, \uk, \xk\right). \label{defineunshiftedcone}
\end{align}


\begin{figure}[ht]
    \centering
    \includegraphics[width=200px]{images/unshifted_cone.png}
    \includegraphics[width=200px]{images/shifted_cone.png}
    \caption[An example of the shifted and unshifted cones]
	{
		On the left is an unshifted cone $\unshiftedcone$.
		The zeros of the polyhedron constraint functions are in blue, and the current iterate is in green.
		A feasible direction $u$ from the current iterate is calculated, and the width of the cone is determined to lie within the active constraints of the polyhedra.
		On the right is a shifted cone $\unshiftedcone$.
		It is centered at the origin, and points along $e_1$, opening at a rate of $\alphak$.
    }
    \label{linear_cones_images}
\end{figure}

% \begin{boxedcomment}
% Illustrate the open rate...
% \end{boxedcomment}

Observe that, by construction, $\unshiftedcone$ is feasible with respect to the active constraints.
That is, $\lca_i x \le \lcb_i$ for all $x \in \unshiftedcone$ and $i \in \activei\left(\xk\right)$.
\cref{linear_cones_images} contains a depiction of these cones.


% = \left\{x \in \Rn \bigg | \quad x = \xk + t \uk+ s, s^Tu^{\star} = 0, t \ge 0, \|s\| \le {\alphak} t\right\}  \\
% \left\{x = (t, s)^T \in \Rn, t \in \mathbb R_{\ge 0}, s \in \mathbb R^{n-1} \bigg |\quad \|s\| \le {\alphak} t \right\} 

\begin{lemma}
\label[lemma]{unshiftedconeisfeasible}

Let $\unshiftedcone$ and $\polyk$ be defined by \cref{defineunshiftedcone} and \cref{polyhedron_k}.

The set $\unshiftedcone$ is feasible with respect to the active constraints of $\polyk$ at $\xk$.
\end{lemma}

\begin{proof}

Note that the trust region boundary cannot be active at $\xk$ as $\dk > 0$.
Let $\activei$, $\alphak$, and $\uk$ be defined by \cref{define_activei}, \cref{define_alpha_k}, \cref{define_u_k} and
$\lca$ and $\lcb$ be defined by \cref{eq:DFO-linear}.
Let $y = \xk + t\uk + s \in \unshiftedcone$ and $i \in \activei\left(\xk\right)$ be arbitrary.
Then,
\begin{align*}
{\lca}_{i}^Ty - {\lcb}_{i} = {\lca}_{i}^T(t\uk + s) = {\lca}_{i}^Ts + t {\lca}_{i}^T\uk \le \|s\| - \alphak t \le 0.
\end{align*}
\end{proof}

The following function is useful for showing results about our ellipsoids:
\begin{align}
f_{e}(\pi, \delta, r; x) = (x - \delta e_1)^T
\begin{pmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \pi^{-2} \boldsymbol I \\
\end{pmatrix}
(x - \delta e_1) - r. \label{define_ellipsoid_function}
\end{align}

\begin{lemma}

\label[lemma]{shifted_ellipsoid_in_cone}
Let $\shiftedcone, f_e, \alphak$ be defined as in \cref{defineshiftedcone}, \cref{define_ellipsoid_function}, \cref{define_alpha_k}.
Then, for all $\delta > 0$, the ellipsoid
\begin{align}
\left\{x \in \Rn \bigg | f_e\left(\alphak, \delta, \frac 1 2 \delta^2; x\right) \le 0 \right\} \subseteq \shiftedcone.
\end{align}
\end{lemma}

\begin{proof}

Suppose that $x \in \left\{x \in \Rn \bigg| f_e\left(\alphak, \delta, \frac 1 2 \delta^2; x\right) \le 0 \right\}$, 
and let $t = x^Te_1$, $s=x - t e_1$. 
Then
\begin{align*}
f_e(x) \le 0 &\Longrightarrow
(x - \delta e_1)^T\begin{pmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \left(\alphak\right)^{-2} \boldsymbol I \\
\end{pmatrix}(x - \delta e_1) \le \frac 1 2 \delta^2  \\
&\Longrightarrow (t - \delta)^2 + \frac {1} {\left(\alphak\right)^2} \|s\|^2 \le \frac 1 2 \delta^2 \\
&\Longrightarrow \|s\|^2 \le \left(\alphak\right)^2 \left[\frac 1 2 \delta^2 - (t - \delta)^2\right] \\
&= \left(\alphak\right)^2 \left[t^2 - 2(t - \frac 1 2 \delta)^2 \right] \le \left(\alphak\right)^2t^2 \\
&\Longrightarrow \|s\| \le \alphak t.
\end{align*}
Thus, $x \in\shiftedcone$.
\end{proof}


\begin{lemma}
\label[lemma]{linear_mapping_works}

Let $\rotk$, $T_k$, $\unshiftedcone$, $\shiftedcone$ be defined as in
\cref{define_r}, \cref{define_affine_mapping}, \cref{defineunshiftedcone}, \cref{defineshiftedcone}.
Then $T_k(\unshiftedcone) = \shiftedcone$.
% and $T_k^{-1}(\shiftedcone) = \unshiftedcone$
\end{lemma}

\begin{proof}

Observe that $\rotk e_1 = \uk$, $\rotk \uk = e_1$, $\det(\rotk) = 1$, and 
$\rotk \rotk ^T = \rotk ^T\rotk = I$.

Suppose that $x \in \unshiftedcone$.
Then there exists $t \ge 0$ and $s \in \Rn$ such that $x = \xk + t \uk+ s$ where $s^T \uk = 0$ and $\|s\| \le {\alphak} t$.
Then $T_k(x) = t\rotk\uk + \rotk s = te_1 + \rotk s$.
Observe that $(Rs)_1 = (\rotk s)^Te_1 = s^T\rotk^T(\rotk \uk) = s^T \uk = 0$.
Hence,
$T_k(x) = \begin{pmatrix}
t \\
\sigma
\end{pmatrix}$ where $\sigma \in \mathbb R ^ {n-1}$ satisfies $\|\sigma\| = \|s\| \le \alphak t$.
Thus, $T_k(x) \in \shiftedcone$.
Conversely, if $\begin{pmatrix}
t \\
\sigma
\end{pmatrix} \in \shiftedcone$, then let
$s = \rotk^T\begin{pmatrix}
0 \\
\sigma
\end{pmatrix}$
to see that
$x = T_k^{-1}\left(\begin{pmatrix}
t \\
\sigma
\end{pmatrix} \right)= \rotk^T\left(t e_1 + \begin{pmatrix}
0 \\
\sigma
\end{pmatrix}\right) = t \uk + s$, where
$\|s\| = \|\sigma\| \le \alphak t$.
Hence $T_k^{-1}\left(\begin{pmatrix}
t \\
\sigma
\end{pmatrix}\right) \in \unshiftedcone$.
\end{proof}


\begin{lemma}
\label[lemma]{ellipsoid_fits}

Let $\activei$, $f_e$, $\deltaf$ $\alphak$, $\rotk$, $T_k$, and $\polyk$ be defined by
\cref{define_activei}, \cref{define_ellipsoid_function}, \cref{define_deltaf}, \cref{define_alpha_k}, \cref{define_r}, \cref{defineshiftedcone}, and \cref{polyhedron_k},
respectively.

For each iteration $k$, if $\activei\left(\xk\right) \ne \emptyset$, the ellipsoid
\begin{align}
\ellipsek = \left\{x \in \Rn \bigg | f_e\left(\alphak, \deltaf, \frac 1 2 \deltaf^2; T_k(x)\right) \le 0\right\} \label{definefeasibleellipsoid}
\end{align}
satisfies $\ellipsek \subseteq \polyk$.
\end{lemma}

\begin{proof}


% Let $L$ be the shortest distance from $\xk$ to any point on a non-active constraint.
% Define $\alphakp = \sqrt{\left(1 + \left(\alphak\right)^2 \right) \left(1 + \frac 1 {\sqrt{2}}\right)}$, and let $\deltaf = \frac 1 {\alpha'} L$.

Let $\alphakp$, $\rotk$, $\unshiftedcone$, and $\shiftedcone$ be defined by
\cref{define_alphakp}, \cref{define_r}, \cref{defineunshiftedcone}, and \cref{defineshiftedcone},
respectively.
We see that if $x \in \ellipsek$,
then by \cref{shifted_ellipsoid_in_cone} we have that $T_k(x) = \begin{pmatrix}t\\ \sigma\end{pmatrix} \in \shiftedcone$ for some $\sigma \in \mathbb R^{n-1}$
with $\left\|\sigma\right\| \le \alphak$, and
\begin{align*}
(x - \deltaf e_1)^T\begin{pmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \left(\alphak\right)^{-2} \boldsymbol I \\
\end{pmatrix}(x - \deltaf e_1) \le \frac 1 2 \deltaf^2 \\
\Longrightarrow (t - \deltaf)^2 \le (t - \deltaf)^2 + \frac {1} {\left(\alphak\right)^2} \|\sigma\|^2 \le \frac 1 2 \deltaf^2 \\
\Longrightarrow t \le \left(1 + \frac 1 {\sqrt{2}}\right) \deltaf
\end{align*}
so that 
\begin{align*}
\|x\|^2 = t^2 + \|\sigma\|^2 \le \left(1 + \left(\alphak\right)^2 \right) t^2 
\le \left(1 + \left(\alphak\right)^2 \right) \left(1 + \frac 1 {\sqrt{2}}\right)^2 \deltaf^2 
= \left(\alphakp\right)^2 \deltaf^2 \\
\Longrightarrow \|x\| \le \alphakp \deltaf \le \min_{i \in [m] \setminus \activei\left(\xk\right)} \left[{\lcb}_i - \left({\lca}_i\right)^T\xk\right].
\end{align*}
Thus, all points within $\ellipsek$ are closer than the nearest point of a non-active constraint.
Combine this with \cref{unshiftedconeisfeasible} to see that $\ellipsek \subseteq \polyk$.
\end{proof}



\begin{lemma}
\label[lemma]{ellipsoid_includes_origin}

Let $\deltaf$, $\rotk$, $T_k$, $\unshiftedcone$, $\shiftedcone$, $\polyk$ be defined as in
\cref{define_deltaf}, \cref{define_r}, \cref{define_affine_mapping}, \cref{defineunshiftedcone}, \cref{defineshiftedcone}, \cref{polyhedron_k}.

For any iteration $k$,
the ellipsoid
\begin{align}
\scaledellipsek  = \left\{x \in \Rn | f_e\left({\alphak}, \sdk, \sdk^2; T_k(x)\right) \le 0\right\} \label{definescaledfeasibleellipsoid}
\end{align}
satisfies $\xk \in \scaledellipsek$.
\end{lemma}

\begin{proof}

We have that
\begin{align*}
f_e\left(\alphak, \deltaf, \deltaf^2; T_k\left(\xk\right) \right) =  
f_e\left({\alphak}, \deltaf, \deltaf^2; 0\right) = \\
(0 - \deltaf e_1)^T\begin{pmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \left(\alphak\right)^{-2} \boldsymbol I \\
\end{pmatrix}(0 - \deltaf e_1) = \deltaf^2 \le \deltaf^2.
\end{align*}
\end{proof}








% 
% 
% 
% 
% We will first define the ellipsoid and show some of its properties within the transformed space $C_2$ before mapping it to $C_1$.
% To this end, fix an arbitrary $\delta > 0$ and let 
% $f_{e}(x): \Rn \to \reals $ be defined by 
% \begin{align}
% f_{e}(x) = (x - \delta e_1)^T\begin{pmatrix}
% 1 & \boldsymbol0^T \\
% \boldsymbol 0 & \alpha^{-2} \boldsymbol I \\
% \end{pmatrix}(x - \delta e_1) - \frac 1 2 \delta^2
% \label{define_ellipsoid_function}
% \end{align} 
% and consider the ellipsoid $E_1 = \{x | f_{e}(x) \le 0\}$.
% We will show that $E_1 \subseteq C_2$.
% To this end, suppose $x = (t, s) \in E_1$.
% Firstly, note that
% \begin{align*}
% 2\big(t - \frac {\delta} 2\big)^2 \ge 0
% \Longrightarrow 2t\delta - \frac 1 2 \delta^2 \le 2t^2 
% \Longrightarrow \frac 1 2 \delta^2 - (t - \delta)^2 \le t^2. 
% \end{align*}
% \Longrightarrow \frac 1 2 \delta^2 -t^2  + 2t\delta - \delta^2 \le t^2 \\
% \Longrightarrow 0 \le t^2 - t\delta + \frac 1 4 \delta^2
%  \Longrightarrow 0 \le 2t^2 - 2t\delta + \frac 1 2 \delta^2\\

% We choose this mapping because if $x = x_0 + t u^{\star} + s \in C_1$,
% then $\|s\|\le \alpha t \Leftrightarrow \|Rs\| \le \alpha t$ and $0 = s^Tu^{\star} = s^T R^T R u^{\star} = (Rs)^T e_1$ imply that 
% $R(x - x_0 - \delta u^{\star}) = t Ru^{\star} + Rs = t e_1 + Rs \in C_2$.
% Thus, the affine mapping $T : \Rn \to \Rn$ defined by $T(x) = R(x - x_0 - \delta u^{\star})$ maps $C_1$ to $C_2$.
% Conversely, the same arguments show that $T^{-1}(x) = R^Tx + x_0 + \delta u^{\star}$ maps $C_2$ to $C_1$.

%  \in SO(n)
% u = [3957; 6294.9]
% u = u / norm(u)
% e = [1; 0.0]
% a = e + u
% r = 2 * a * a' / (a' * a) - eye(2)
% r * e
% r * u


% 
% Having proven that $E_1 \subseteq C_2$, it follows that $T^{-1}(E_1) \subseteq C_2$.
% However, $T^{-1}(E_1) = \{ x \in \Rn | (x - \delta u^{\star})^TQ(x-\delta u^{\star} \le \frac 1 2 \epsilon\}$ where

% 
% \begin{align*}
% E_2 = \bigg \{x \bigg | (x - x_0 - \delta u^{\star})^T\bigg(R^T\begin{pmatrix}
% 1 & \boldsymbol0^T \\
% \boldsymbol 0 & \alpha^{-2} \boldsymbol I \\
% \end{pmatrix}R\bigg)(x - x_0 - \delta u^{\star}) \le \frac 1 2 \delta^2 \bigg\}.
% \end{align*}
% We know that $x \in E_1 \Leftrightarrow T(x) = R(x - x_0 - \delta u^{\star}) \in E_2 \Longrightarrow T(x) \in C_2 \Longrightarrow x = T^{-1}\left(T(x)\right) \in C_1$.
% Thus, we know that the ellipsoid $E_2$ is contained within the active constraints, and can be scaled by $2$ to include $x_0$.

\begin{lemma}
\label[lemma]{nontrivial_ellipsoid_exists}

Let $\activei$ and ${\alphak}$ be defined by \cref{define_activei} and \cref{define_alpha_k}, respectively.

Suppose that \cref{interior_point} holds.

For some iteration $k$, if $\activei \ne \emptyset$, then the ellipsoid defined by \cref{define_linear_nontrival_ellipsoid}
is suitable according to \cref{define_suitable_ellipsoid}.

% For iteration $k$, if ${\alphak} > 0$, then there exists a suitable ellipsoid for iteration $k$ according to .
\end{lemma}

\begin{proof}

Let 
$f_e$,
$T_k$,
$\rotk$, $\deltaf$, and $\scaledunshiftedellipsoid$
be defined as in
\cref{define_ellipsoid_function},
\cref{define_affine_mapping},
\cref{define_r},
\cref{definefeasibleellipsoid}, and
\cref{definescaledfeasibleellipsoid},
respectively. 
Observe that \cref{define_suitable_ellipsoid} with \cref{define_linear_nontrival_ellipsoid} defines  $\ellipsek$ and $\scaledellipsek$ to be
\begin{align*}
\begin{array}{cccc}
\ellipsek &=& \left\{x \in \Rn \bigg | f_e\left(\alphak, \sdk, \frac 1 2 \sdk^2; T_k(x)\right) \le 0\right\}, &\quad \textrm{and}  \\
\scaledellipsek &=& \left\{x \in \Rn \bigg | f_e\left({\alphak}, \sdk, \sdk^2; T_k(x)\right) \le 0\right\}.&
\end{array}
\end{align*}

By \cref{ellipsoid_fits}, we know that $\ellipsek \subseteq \polyk$.
By \cref{ellipsoid_includes_origin}, we know that $\xk \in \scaledellipsek$ .
By \cref{alphas_are_bounded}, there exists $\epsilon_{\alpha} > 0$, such that the condition number 
$\condition\left(\qk\right) = \frac{\max\{1, {\alphak}^{-2}\}}{\min\{1, {\alphak}^{-2}\}} = {\alphak}^{-2} > 0$.
This is because $\det\left(\rotk\right) = 1$ means the condition number of $\qk$ is not affected $\rotk$.
\end{proof}


% Let
% \begin{align*}
% \qk = \rotk^T\begin{pmatrix}
% 1 & \boldsymbol0^T \\
% \boldsymbol 0 & {\alphak}^{-2} \boldsymbol I \\
% \end{pmatrix}\rotk \\
% c_k = \xk - \deltaf \uk \\
% \epsilon = \delta^2 
% \end{align*}


%
%\begin{comment}
%I think we no longer use this result...
%\end{comment}
%
%\color{red}
%We use the following result shown \cite{BillupsLarson2013}, Corollary 4.7.
%We restate the theorem here, with the simplification that $f$ is deterministic function:
%
%\begin{assumption}
%\label{fully_quadratic_assumption}
%Suppose that a set $S$ and a radius $\dmax$ are given.
%Assume that $f$ is twice continuously differentiable with Lipshcitz continuous Hessian in an open domain containing the $\dmax$ neighborhood
%$\cup_{x \in S} B(x; \dmax)$ of the set $S$.
%\end{assumption}
%
%\begin{lemma}
%\label[lemma]{larson_change_radius} 
%Let $Y$ be a poised set of $p$ points, and let $R = \max_{i}\|y^i - y^{(0)}\|$.
%Let $f$ satisfy \cref{fully_quadratic_assumption} over some convex set $\Omega$, and let $m(x)$ denote the quadratic model of $f$ using \cref{reg}.
%If $f$ is a Lipschitz continuous function with Lipschitz constant $L_g$, and $m_f(x)$ is a quadratic model of $f$.
%Then, there exist constrants $\Lambda_1, \Lambda_2, \Lambda_3$ independent of $R$ such that for all $x \in B(y^{(0)}, R)$,
%\begin{align*}
%\|f(x) - m_f(x)\| \le 4\Lambda_1 R^3L \sqrt{p+1} \\
%\|\nabla f(x) - \nabla m(x)\| \le 4\Lambda_2R^2  L \sqrt{p+1} \\
%\|\nabla^2 f(x) - \nabla^2 m(x)\| \le 4\Lambda_3  RL \sqrt{p+1}
%\end{align*}
%\end{lemma}
%
%\color{black}

% 
% \sbnote{There needs to be some discussion about how the method defined above to construct the suitable ellipsoid relates to the other methods 
% you described}.

\subsection{Ellipsoid searches}

Within \cref{the_safe_ellipsoid}, we showed how to construct one possible ellipsoid that satisfies \cref{define_suitable_ellipsoid}.
In practice, this ellipsoid could be less than desirable.
Within this section, we discuss the requirements of other variants of the \emph{ConstructTrustRegion} subroutine that we explored for practicality.
The key requirement is these ellipsoids must still satisfy \cref{define_suitable_ellipsoid} to share the same convergence results.

\subsubsection{Ensuring suitability}

To retain the convergence results, these algorithms maintain $\ellipsek \subseteq \polyk$,
$\xk \in \scaledellipsek $, and a bound on $\condition\left(\qk\right)$.

To ensure the condition number is bounded, the algorithm can compute the condition number of the safe ellipsoid, and only consider ellipsoids better conditioned.
Alternatively, it could introduce its own bound.
We found it simplest to parameterize ellipsoids by their Cholesky factorization $\qk = LL^T$.
Namely, we parameterized the search space in terms of a lower triangular matrix $L$, and required the diagonal entries to be positive.
To ensure a bounded condition number, we chose a $\epsilon_{\alpha} > 0$, and constrain  $\max_{i\in[n]} \le \epsilon_{\alpha} \min_{i \in [n]}$.
% Then requiring a 

One potential difficulty created by moving the ellipsoid center $\ck$ is that the current iterate $\xk$ may not lie within near the resulting ellipsoid.   
The pitfall is that the model function may lose accuracy near the current iterate.
Thus, we have implemented a few ways of ensuring the current iterate is within the search trust region.
This can be done by either of the following two options:
\begin{itemize}
\item Adding a constraint to the ellipsoid problem to include the original point.
\item Expanding the size of the ellipsoid.
\end{itemize}

\paragraph*{Adding a constraint.}
In order to include the original point as a constraint, we add a constraint of the following form to the definition of the ellipsoid.
\begin{align*}
\frac 1 2 \left(\xk - \ck\right)^T\qk\left(\xk - \ck\right) \le \frac 1 2 \sdk^2.
\end{align*}
Constraints of this nature make finding the ellipsoid much more expensive:
the optimization problem we construct uses ${\qk}^{-1}$ as decision variables, so that constraints in terms of $\qk$ must model matrix inversion.

\paragraph*{Increasing the radius.}
An alternative is to scale $\qk$ by a constant.
We use a scaling factor $\sdk > 0$ defined by
\begin{align*}
\sdk = \max \left\{1, \sqrt{\left(\xk - \ck \right)^T \qk \left(\xk - \ck \right)} \right\}
\end{align*}
and let the ellipsoid be:
\begin{align*}
\ellipsek = \left\{x \in \Rn \bigg| \frac 1 2 \left(x - \ck\right)^T \qk \left(x - \ck\right) \le \frac 1 2 \sdk^2\right\}.
\end{align*}
However, this means that in general $\ellipsek \not \subset \feasible$.
so that the sample points must be contained to also lie within the feasible region: $\ellipsek \cap \feasiblek$.
For details on how to choose sample points with additional constraints, see \cref{model_improving_algorithm}.


%  \sbnote{This raises a number of questions.
%  First is whether the current iterate will be a sample point.
%  If it isn't, then the model function may disagree with the true function at the current iterate, 
%  so descent of the model function may not correspond to descent of the true function, even for very small steps.
%  Also, if the search region is chosen to be equal to the ellipsoidal region, then we may not be able to get descent at all.
%  At the end of the day,  we don't necessarily need the current iterate to be in the ellipsoid as long as
%  1) it is within the search trust region, and 2) the model function is sufficiently accurate over the search trust region.
%  Actually, we don't even need 2), do we?  We just need the accuracy condition to be satisfied at the current iterate, right?}


\subsubsection{Maximal volume ellipsoids}
\label{ellipse_optimization}

The error bounds given in \cref{shifted_ellipsoid} suggest that we can obtain more accurate model functions by 
minimizing the condition number of the matrix $\qk$.
However, we also desire a large ellipsoid so that our model will satisfy the error bounds over more of $\searchtrk$.
Thus, one choice for $\sampletrk$ is to choose the maximum volume ellipsoid that is both feasible and lies within the outer trust region.
We can accomplish this for various ellipsoid centers, by finding the maximal volume ellipsoid that is constrained to lie within the polytope
\begin{align*}
\polyk := \left\{x \in \Rn | \lca x\le \lcb,   \xki - \dk \le x_i \le \xki + \dk\right\}.
\end{align*}
% Note that we have replaced the usual trust region $B_2\left(\xk, \dk\right)$ with an $L_{\infty}$ ball, called the {\em outer trust region},
% defined in \cref{define_outer_trust_region}.

This is not the only reasonable approach: maximizing ensures a larger region for which the models will be accurate, 
but we are most interested in descent directions.
Namely, we may wish to use previously evaluated points to provide a hint of where the next ellipsoid should be.
Another consideration is where points have been evaluated: it may be more economical to choose a smaller ellipsoid that can reuse existing points.
However, in this section,  we consider the problem of choosing $\qk$ and $\sdk$ to maximize the volume of $\ellipsek \subseteq \polyk$ given a fixed center $\ck$.
Later, in \cref{center_searches}, we will explore strategies for moving the center of the ellipsoid to improve the performance of our trust region algorithm.

We adopt a method similar to that described in \cite{Khachiyan1993},
which presents an algorithm for finding the maximum volume ellipsoid inscribed in a given polytope.
% For the remainder of this section, we drop the superscript $(k)$ and write
% \begin{align*}
% P = \polyk =  \{ x \in \Rn\; | \;  Ax \le b \}.
% \end{align*}
% We wish to find the maximum-volume ellipsoid $E \subseteq P$ centered at a point $c \in P$.

% \bar{\lctrb}
Let $\bar g = \lctrb - \lctra \ck$ and $d = x - \ck$ so that the polytope becomes
\begin{align*}
\polyk = \left\{ \ck + d \in \Rn \; | \;  \lctra d \le \bar{g} \right\}.
\end{align*}
Using this transformation, the ellipsoid can then be centered at zero, and defined by a symmetric positive definite matrix $Q \succ 0$:
\begin{align*}
E = \left\{ d \in \Rn \; \bigg | \; \frac 1 2 d^T Q d \le 1 \right\}.
\end{align*}
Our goal is to determine the matrix $Q$ that maximizes the volume of $E$ such that $\mu + E \subset \mathcal{P}$.
This is accomplished by defining $\bar b = b - Ac$ and solving the following problem for $Q$ for a given center:
 \begin{align}
\begin{array}{cc}
 \sup_{Q \succeq 0} & \det(Q^{-1})  \\
 \textrm{s.t.} & A_i^T Q^{-1} A_i \le \frac 1 2 \bar{b_i}^2.
\end{array}
 \label{ellipse_1}
\end{align}


\begin{theorem} 

Let $\mathcal{P} = \{x \in \Rn | Ax \le b\}$, 
where $A$ is an $m \times n$ matrix, 
and $b \in \Rm$.  Let $c \in \intr{\mathcal{P}}$.

Suppose that some positive definite, symmetric matrix $Q$ solves \cref{ellipse_1}, where $\bar{b} = b - Ac$.
Then the ellipsoid $E = \{ x \in \reals^n | (x-c)^T Q(x-c) \le 1\}$ has the maximum volume over all ellipsoids centered at $c$ and contained in $\mathcal{P}$.
\end{theorem}


\pagebreak
\begin{proof}

Define the auxiliary function $f(d) = \frac 1 2 d^T Q d$ so that $E = \{ d \in \Rn\; | \; f(d) \le 1 \}$.
Because $Q$ is positive definite, $f$ has a unique minimum on each hyperplane $\left\{d \in \Rn | \; A_i d = b_i\right\}$.
Let this minimum be $d^{(i)} = \argmin_{A_id =\bar{b}_i} f(d)$ for $i\in[m]$.
By the first-order optimality conditions, there exists a $\lambda \in \Rm$ such that for each $i\in[m]$,
\begin{align*}
\nabla f(d^{(i)}) = Q d^{(i)} = \lambda_i A_i.
\end{align*}
Since $Q$ is invertible, we have $d^{(i)} = \lambda_i Q^{-1}A_i$. 
We also know that $A_i^T d^{(i)} = \bar{b_i}$, so 
\begin{align*}
A_i^T \lambda_i Q^{-1}A_i = \bar{b_i} \Longrightarrow
\lambda_i = \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i},
\end{align*}
so that
\begin{align*}
d^{(i)} = \lambda_i Q^{-1}A_i = \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \quad \forall 1\le i\le m.
\end{align*}
Because $E \subset \mathcal{P}$, we also know that $f(d^{(i)}) \ge 1$ for each $i$. Thus,
\begin{align*}
\frac 1 2 (d^{(i)})^{T} Q d^{(i)} \ge 1 \\
\Longrightarrow & \frac 1 2 \bigg(\frac {\bar{b}_i}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i\bigg)^{T} Q \frac {\bar{b}_i}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \ge 1 \\
\Longrightarrow & \frac 1 2 \frac {1}{A_i^T  Q^{-1}A_i}  \bar{b_i} A_i^T Q^{-1} Q \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \ge 1 \\
\Longrightarrow & \frac 1 2 \frac {1}{A_i^T  Q^{-1}A_i}  \frac {\bar{b_i}^2}{A_i^T  Q^{-1}A_i}  A_i^T Q^{-1}A_i \ge 1 \\
\Longrightarrow & \frac 1 2  \frac {\bar{b_i}^2}{A_i^T  Q^{-1}A_i} \ge 1 \\
\Longrightarrow & \frac 1 2 \bar{b_i}^2\ge A_i^T  Q^{-1}A_i \\
\Longrightarrow & A_i^T  Q^{-1}A_i \le \frac 1 2 \bar{b_i}^2.
\end{align*}

Because the volume of the ellipsoid is proportional to the determinant of $Q^{-1}$, the maximal ellipsoid is defined by \cref{ellipse_1}.
\end{proof}


Notice that the constraints for \cref{ellipse_1} can be simplified for the outer trust region's constraints.
These take the form:
\begin{align*}
e_i^T\left(\frac{\qk}{\frac 1 2 \sdk^2}\right)^{-1} e_i \le \left[e_i^T\left(\xk - \ck\right) \pm \dk \right]^2 \quad \forall i \in [n]
\end{align*}
or
\begin{align}
\label{ellipsoids_trust_region_constraints}
\left(\frac{\qk}{\frac 1 2 \sdk^2}\right)_{i,i}^{-1} \le \left[\xki - \ck_i \pm \dk \right]^2 \quad \forall i \in [n].
\end{align}


\section{Polyhedral Trust Region Approach}
\label{sec:polyhedral}

One simple approach to ensuring that all sample points are feasible is to restrict them to lie within the intersection of the feasible region and the outer trust region.
In particular,  we define the sample and search trust regions by
\[ \sampletrk = \searchtrk = \feasible \cap \outertrk.\]
Note that by using an $L_{\infty}$-ball for the outer trust region, both $\sampletrk$ and $\searchtrk$ are polytopes.
 
The main challenge in implementing this approach is ensuring that the sample points chosen from within $\sampletrk$ are well-poised.
To accomplish this, we modify the model improvement algorithm given by \cref{model_improving_algorithm}.   
Recall that \cref{model_improving_algorithm} works on a shifted and scaled problem in which sample points are selected to lie within a unit ball.
Thus,  in Step 2 of that algorithm,  each new sample point $\hat{y}$  is selected by  
$\hat{y} \in \argmax_{t:\norm{t} \le 1} \left|u_i(t)\right|$, where the pivot polynomials $u_i$ are constructed during the algorithm.  
We modify this step by choosing $\hat{y} \in \argmax_{t\in \sampletrk} \left|u_i(t)\right|$.  



%That is, we add the constraints $\mcik(x) \le 0 \forall i \in \mathcal{I}$ and $\mcik(x) = 0 \forall i \in \mathcal{E}$ to the model improvement algorithm while selecting new points.
%This constrains the new points to also lie within the current model of the trust region in \cref{model_improving_algorithm}, Step 2.
%The search space for this optimization problem will be the feasible region intersect the trust region: $\feasible \cap \outertrk $.

The challenge lies in finding sufficiently poised sample points.
Note that \cref{model_improving_algorithm} uses a parameter $  \ximin $ as a lower bound of the pivot values of the Vandermonde matrix.
For unconstrained problems, this approach could always find a pivot value for any $ \ximin \in (0,1)$ because it optimizes over a sphere.
However, when requiring points to live within $ \feasible \cap \outertrk $, it can happen that even after replacing a point, we still have not satisfied this bound.
In \cref{lspc}, for some values of $  \ximin $, there is no point in $ \feasible \cap \outertrk $ that will leave a sufficiently large pivot.

\begin{figure}[ht]
    \centering
    \includegraphics[width=200px]{images/small_sample_region.png}
    \caption[An example of constraints limiting sample point choices.]
    	{An example of constraints limiting sample point choices.
    	If the constraints remove a large region of the trust region,
    	there may be no feasible $\Lambda$-poised set for a given $\Lambda>0$.
    }
    \label{lspc}
\end{figure}

%As the number of dimensions grows the ratio of volume of the trust region intersect the feasible region to the feasible region can become smaller.

One way to handle this is to introduce a $\xi_{\text{cur}}$ which is allowed to decrease.
(Possibly, until a threshold is reached for maintaining a fixed $\Lambda$.)
If the new point does not improve the geometry of the set significantly, then there is no other point that would do better.
To test this, we introduce a constant $\delta_{\text{improv}}>0$ and require a new point to increase the current pivot by a factor greater than $\delta_{\text{improv}}$.
If the new point does not satisfy this test, we proceed with our current point and possibly decrease $\xi_{\text{cur}}$.
Conceptually, 
\begin{itemize}
\item $\ximin$ is a tolerance that ensures Step 3 does not perform division by zero,
\item $\xi_{\text{cur}}$ measures the most poised set possible within $\sampletrk$,
\item and replacement points are ignored if they do not improve the poisedness by more than $\delta_{\text{improv}}$.
\end{itemize}
The new modified improvement algorithm is described in \cref{modified_model_improving_algorithm}.
The \emph{ConstructTrustRegion} subroutine for this approach follows the prototype with $\sampletrk = \searchtrk = \feasible \cap \outertrk $.
As usual, we may also wish to remove points larger than a certain radius from the current model center.

\pagebreak
{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.5in]
\begin{flushleft}

\begin{algorithm}[H]
    \caption{Modified Model Improvement Algorithm}
    \label{modified_model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Given an interpolation set $\sampletrk$, and set $Y$ of $p+1$ points,
            initialize $i=1$, $0 < \ximin < \xi_{\text{desired}}$, $0 <\delta_{\text{improv}} < 1$,
            $  \xi_{\text{cur}} = \xi_{\text{desired}}$.

            
		\item[\textbf{Step 1}] \textbf{(Pivot)} \\
			Compute the next pivot index $j^{\textrm{max}}_i \in \argmax_{i \le j \le |Y|-1} \left|u_i\left(y^j\right)\right|$,
			and swap points $i$ and $j^{\textrm{max}}_i$ within $Y$.
			
        \item[\textbf{Step 2}] \textbf{(Check threshold)}
                If $\left|u_i\left(y^i\right)\right| \ge \xi_{\text{cur}}$ then go to Step 3. \\
                Compute $ \hat y = \arg\max_{t \in \sampletrk \cap \feasible}\left|u_i(x)\right|$ \\
                If $ |u_i(\hat y)| < \ximin$ then \textbf{Stop}: the algorithm failed \\
                If $|u_i(\hat y)| - \xi_{\text{cur}} \ge \delta_{\text{improv}} \xi_{\text{cur}}$ then
                replace point $y^i$ with $\hat y$ and set $\xi_{\text{cur}} \gets |\phi_i(\hat y)|$
                
        \item[\textbf{Step 3}] \textbf{(Gaussian elimination)} \\
        	For $j = i+1, \ldots, p$: \\
        	Set $u_j(x) \gets u_j(x) - \frac{u_j\left(y^i\right)}{u_i\left(y^i\right)} u_i(x)$ \\
            If $i = p$ then \textbf{Stop}, otherwise Set $i \gets i+1$ and go to Step 1
    \end{itemize}
\end{algorithm}

\end{flushleft}
\end{fullwidth}
}

% \paragraph*{Algorithm Conjecture}

When the algorithm fails, it is likely because $\sampletrk$ is nearly contained in a subspace 
for which some basis function can be written as a linear combination of other basis functions.
Because our feasible region contains an interior point, we would expect that sufficiently small values of $\ximin>0$ allow the algorithm to run to completion.
However, for non-linear constraints, or even equality-based constraints, there may not be such an $\ximin$.

Intuitively, higher order monomials would not improve the accuracy of the model over $\sampletrk$ 
if their function values do not significantly differ from that of a linear combination of lower order monomials.
This insight inspires a model improving algorithm that uses Gaussian elimination with {\em full pivoting}
to select only those monomials {\em useful} for approximating functions over $\sampletrk$.
When there is no replacement point or corresponding monomial in the basis that can be added to the existing set of Lagrange polynomials with a pivot larger than $\ximin$,
the algorithm would simply stop the Gaussian elimination.
Note that the maximization over $\sampletrk$ to find a replacement point would need to maximize $|u_j|$ for several $i \le j \le p$ rather than simply $i$.

% If a lower bound $\kappa_{\phi}$ on the maximum value of each polynomial is known ahead of time, then the check on \cref{impossibly_poised} is not needed.
% That is, for a given set of linear constraints and largest trust region radius, it may be possible to calculate $\xi_{\text{min}} \le \kappa_{\phi} \le \max_{V}\max_{j}\max_{i}\|\phi_i(y^j)\|$.
%Another interesting approach we have not investigated is to decrease the size of the sample set when a new point cannot be computed.
%The analysis for this approach may be more difficult.

\section{Results}

\subsection{Algorithm variants}

Here, we present numerical results for our implementations of \cref{linearly_constrained_dfo_simple}.
We begin by describing the different ways we implemented \emph{ConstructTrustRegion}.

\subsubsection{Circular trust region}

The simplest approach to maintaining a feasible trust region is to set the inner trust region radius sufficiently small.
Within the \emph{ConstructTrustRegion} subroutine, this method sets the trust region radius to the distance to the closest constraint:
$\outertrk = B_2\left(\xk, \min\left\{\dk, \min_{i}\frac{\left|A_i\xk - b_i\right|}{\left\|A_i\right\|} \right\}\right)$.
In practice, this does not work well as the radius can become too small to allow adequate progress.

Two general strategies were considered for addressing this issue as illustrated in \cref{options_basis}.
One option is to shift the center of the inner trust region as long as it remains within the outer trust region.
The second option is to elongate the trust region along the nearest constraint as discussed in the next section.
Of course, both of these can be done at the same time.


\begin{figure}[ht]
    \centering
    \includegraphics[width=200px]{images/small_circle.png}
    \includegraphics[width=200px]{images/shifted_center.png}
    \caption[The advantage of not requiring the sample region center to be the trust region center.]{
    	When the current iterate is too close to a constraint, the circular trust region becomes too small.
    	Shifting the trust region center can help remedy this.
    	The star is the current iterate, the outer trust region is in green, and the inner trust region is in blue.
    }
    \label{options_basis}
\end{figure}


In order to address this issue, we considered using ellipsoidal trust regions.
Whereas the circle does not allow improvement when the current iterate lies along a constraint, an ellipsoid elongates along this constraint.
In figure \cref{ellipse_adv}, we have this type of iterate, but by using an ellipsoid we are still able to search towards the vertex of the feasible region.
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.4]{images/long_ellipsoid.png}
    \caption[An ellipsoidal trust region allows for more progress than a circular trust region.] {
    	Although the center of the ellipsoid in green is close to the boundary of the blue constraints, it can elongate to allow progress.
    }
    \label{ellipse_adv}
\end{figure}

% \begin{boxedcomment}
% Update this image...
% \end{boxedcomment}


More specifically, at iteration $k$, we choose a scaling factor $\sdk$ and solve for an ellipsoid center $\ck \in \Rn$ and positive definite matrix $\qk$ to define an ellipsoid
\begin{align*}
\ellipsek = \left\{x \in \Rn \bigg| \; \frac 1 2 \left(x - \ck\right)^T\qk\left(x - \ck\right) \le \frac 1 2 \sdk^2 \right\}.
\end{align*}
The simplest approach is to simply let the center of the ellipsoid be the current iterate: $\ck = \xk$.





% \item How do we choose $\ellipsek$ to make the  ellipsoid as large as possible while ensuring that $ \ellipsek \subset \outertrk \cap \feasible $?




% ====================
% \sbnote{Move the following to somewhere else.}
% The advantage of the ellipsoidal trust region approach \cref{bluepill} is that we can reuse classical methods for ensuring good geometry.
% We can construct $\sampletrk$ to be ellipsoidal and use efficient algorithms within \cite{introduction_book} to satisfy \cref{accuracy}.
% However, we must be careful while choosing $ \searchtrk$ to allow sufficient reduction when we solve the trust region subproblem using the inner trust region.
% The search trust region is used while selecting the next iterate:
% \begin{align*}
% \sk = \argmin_{s \in \searchtrk} \mfk(\xk + s).
% \end{align*}
% =====================






\subsubsection{Choosing the ellipsoid center}
\label{center_searches}

The most obvious choice for the center of the ellipsoid is to choose $\ck = \xk$ (i.e., the current iterate).  
However, if $\xk$ is too close to a boundary of the feasible region, this can result in a badly shaped or very small ellipsoid.
We, therefore, explore strategies where the \emph{ConstructTrustRegion} subroutine moves the center of the ellipsoid away from the boundary. 
This is depicted in \cref{ellipse_adv}.


% We let the volume of the ellipsoid $E$ at center $c$ be given by $V(c) = \det(Q^{-1}) $.

\paragraph{Outer trust region search.}

One approach is to search all possible centers within $\feasible \cap \outertrk $.  
% That is, we solve:  \sbnote{Why do you use $\sdk$ in the following?}
% \begin{align*}
% \ck = \sup_{c \in \feasible \cap \outertrk} V(c)
% \end{align*}
% where $V(c)$ is the volume of the ellipsoid defined in \cref{ellipse_1}.

This has the advantage that it allows for the largest volume.
However, one problem with this search is that it can force the trust region away from the descent direction.
Notice that in \cref{ellipse_runs_away}, although the ellipsoid found has larger volume than before being shifted, 
this ellipsoid contains points farther from the corner that happens to contain the trust region's minimizer.
Within the numerical results, these algorithms are described as ``ellipse everywhere''.

The following section addresses this problem by proposing a path search method for choosing the ellipsoid center.

\begin{figure}[ht]
    \centering
    \includegraphics[width=200px]{images/worse_larger_ellipsoid_1.png}
    \includegraphics[width=200px]{images/worse_larger_ellipsoid_2.png}
    \caption[An example of how the search for the sample region center can go wrong.]{
    	An example of how the search for the feasible region center can go wrong.  
     	On the left, a very small sample region is selected; however its proximity to the minimizer makes the model more accurate at the minimizer.
    	On the right, a sample region with larger volume is chosen, but it is further from the trust region minimizer.
	}
    \label{ellipse_runs_away}
\end{figure}


\paragraph{Path searches.}

% \sbnote{This discussion is quite vague, and in my opinion, off target.  
% You don't necessarily want to be moving toward a vertex.   
% You just don't want your ellipsoid to move in the opposite direction as  the descent direction.}
% 
% 
% 
% Although $\mfk$'s minimizer over $\outertrk$  can appear anywhere, there are some reasons for expecting it to be at a ``vertex."
% If it lies in the interior, there is little need for using constrained approaches once near the solution.
% 
% 
% %The ellipsoid with maximum volume, however, tends to lead $ \sampletrk $ away from vertices.
% One way of trying to ensure a feasible direction towards a vertex, while still allowing a larger volume ellipsoid, 
% is by limiting the search for the new center to lie on a piecewise linear path starting at the current iterate $\xk$.

Rather than searching over all possible centers, it may be more efficient to only move away from the boundary.
This can be done using one-dimensional search along an appropriate direction.
For example, our first attempt was to simply search a line directed orthogonally away from the closest constraint.
This has obvious problems as shown in \cref{first_line_search}: we should avoid letting the new center get closer to another constraint.    

% \sbnote{This could be clearer.
% A key point is that with this method, you can determine the ellipsoid center simply by moving along this line until you are equidistant from the 2 closest constraints.
% Thus,  there is little gain if the current iterate is close to two or more constraints.}

\begin{figure}[ht]
    \centering
    \includegraphics[width=200px]{images/narrow_ellipsoid_1.png}
    \includegraphics[width=200px]{images/narrow_ellipsoid_2.png}
    \caption[Why only considering the nearest constraint is not sufficient. ]
        {Why only considering the nearest constraint is not sufficient.   On the left is the starting ellipsoid.
    	By choosing centers further away from only the nearest constraint, the ellipsoid becomes narrow as another constraint is limiting the length of the second axis.
	}
    \label{first_line_search}
\end{figure}

To fix this, we search along a piecewise linear path leading away from the closest constraints.   
The algorithm works by choosing a set of breakpoints $s_0, s_1, s_2, \ldots, s_{n_{\text{points}}}$
that are each equidistant to a subset of the constraint's faces.
Intuitively, the search moves away from the nearest constraint until it reaches a point equidistant to the second nearest constraint, and so on.
The center search then considers points along the line segments between these points.
% Namely, it starts at the current iterate and travels along a ray away from all the closest constraints until it reaches a point equidistant to yet another constraint.

More precisely, the first point is chosen to be the current iterate: $s_0 = \xk$.
The algorithm then repeats the following process for $i$ from $0$ to $n_{\text{points}}-1$.
First, compute the set of nearest constraints, where the distance from the current point $s_i$ to each constraint $A_j$ for $j \in [m]$: 
is given by $d_j = b - A_j x$.
Recall that the rows of $A$ are normalized: $\left\|A_j\right\| = 1 \quad \forall j \in [m]$.
While finding the next point $s_{i+1}$, let  $E$ be the indices of $A$ whose constraints are equidistant and nearest to $s_i$:
$\{j \in [m] | d_j = \min_{l \in [m]} d_l\}$.
Let the remaining indices be $R = [m] \setminus E$.
The algorithm chooses a search direction $p = {A_E}^Tr$ as a linear combination of the normal vectors of the nearest constraints.
%When the constraint violation of $s_i$ is non-zero, this search ray can be found by finding the point that doubles the current slack ${A_E}s_i-{b_E}$.
%This is given by $r{A_E}^T$ where $r$ solves the linear system ${A_E}(s_i + r{A_E}^T) - b_E = 2 ({A_E}n_i - b_E)$.
%If the current violation is zero, then the right hand side can be set to a vector of all ones to ensure that all slacks violations are the same: $A_E(s_i + r{A_E}^T) - b_E = 1$.
This search ray $r$ can be found by computing a point $s_i$ whose distance to each equidistant constraint is twice its current value:
\begin{align*}
b_E - A_E(s_i + {A_E}^Tr) = 2 \left[b_E - A_Es_i\right] \Longrightarrow r = \left[A_E{A_E}^T\right]^{-1}\left(b_E + A_E s_i\right).
\end{align*}
% $A_E(s_i + r{A_E}^T) - b_E = 1$.
We can travel along this ray until we reach a point that is the same distance to a remaining constraint.
By travelling a distance $t$, we see that the $j$-th constraint becomes active when
$A_j (s_i + t p) = b_j \Longrightarrow t = \frac{b_j - A_j s_i}{A_jp}$
so that we can travel by 
$t = \min_{j \in R} \left\{\frac{b_j - A_j s_i}{A_jp}  \right\}. $
We set $s_{i+1} = s_{i} + t p$.
This process is described in \cref{segment_construction}.
Of course, $n_{\text{points}}$ must be less than or equal to $n + 1$ in order for this to be defined.

% \begin{comment}
% Also, the algorithm must stop early if $A_E$ contains $n$ parallel normal vectors: 
% as there will no longer be a direction that leads away from all constraints.
% \end{comment}

{
\begin{fullwidth}[leftmargin=0in, rightmargin=0in, width=\linewidth-0.5in]
\begin{flushleft}


\begin{algorithm}[H]
    \caption{Path segment construction}
    \label{segment_construction}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Choose a number of segments $n_{\text{points}} \le n$, and set $s_0 = \xk$, $i=1$.
            
        \item[\textbf{Step 1}] \textbf{(Compute nearest constraints)} \\
			Compute $d_j = b - A_j s_{i-1}$ for each $j \in [m]$, and partition 
			\begin{align*}
			E = \left\{j \in [m] \bigg| d_j = \min_{l \in [m]} d_l\right\}, \; \textrm{and} \; R = [m] \setminus E.
			\end{align*}
			If $|E| \ge n$, then \textbf{Stop}.
			
            
        \item[\textbf{Step 2}] \textbf{(Compute search segment)} \\
        	Compute the search direction $p = {A_E}^T\left[A_E{A_E}^T\right]^{-1}\left(b_E + A_E s_{i-1}\right)$
        	and distance $t = \min_{j \in R} \left\{\frac{b_j - A_j s_{i-1}}{A_jp}  \right\}$. \\
        	Set $s_i \gets s_{i-1} + tp$.
        	
        \item[\textbf{Step 4}] \textbf{(Repeat)} \\
        if $i = n_{\text{points}}$ \textbf{stop}, otherwise set $i \gets i+1$ and go to Step 1.
    \end{itemize}
\end{algorithm}

\end{flushleft}
\end{fullwidth}
}


% if we let $\nabla \modelconstrainti\left(\xk\right) = A_i$ be the $i$th row of $A$, then we define the distance from a search point $s$ so the $i$th constraint to be

Once each end point $s_i$ is computed, the algorithm searches along each line segment $[s_{i-1}, s_i]$ for $i \in [n_{\text{points}}]$.
This means that we can define a class of searches that each limit the number of line segments to search $n_{\text{points}}$.
Within the results, these algorithms are described as ``ellipse segment $n_{\text{points}}$''.

% In \cref{line_can_run}, the red line shows the line segments equidistant from their closest constraints.
% Notice that with two line segments, the algorithm can already choose new centers further from the vertex.
%
% % TODO: REPLACE PICTURES
% \begin{figure}[ht]
%     \centering
%     \includegraphics[scale=0.4]{images/run_away_1.png}
%     \includegraphics[scale=0.4]{images/run_away_2.png}
%     \caption{
% %     	\emph{Short:} Why only considering the nearest constraint is not sufficient.
% %     	\emph{Long:} On the left is the starting ellipsoid.
% %     	By choosing centers further away from only the nearest constraint, the ellipsoid becomes narrow as another constraint is limiting the length of the second axis.
%     Ellipse runs away from the trust region minimizer}
%     \label{line_can_run}
% \end{figure}

% \begin{boxedcomment}
% Update this image...
% \end{boxedcomment}

\pagebreak

\subsection{Buffered segments}

Even with these modifications, the iterates may approach the boundary of the feasible region.
Another way of dealing with this is to shift the constraints closer to the current iterate.
Namely, we introduce a parameter $\upsilon$ to determine how far to scale the constraints.
Then, within the trust region subproblem, we add constraints of $Ax \le b\upsilon + (1-\upsilon) A \xk $.
This produces the buffered segment searches within the results.

\paragraph*{Circumscribed ellipse.}

We also implemented a variant of the algorithm in which the sample region is a smallest volume ellipsoid to contain the feasible region.
Notice the ellipsoid necessarily includes points that are outside the current trust region and may include infeasible points.
Thus, both the trust region and linear constraints have to be added to the optimization problem defining the replacement point while computing the Lagrange polynomials.
For more details about this modified model improvement algorithm, see \cref{sec:polyhedral}.

\subsection{Sample problem}

The first test was on a problem with simple constraints and a pathological objective.
We let $f(x) = \epsilon x + (1-\epsilon)(y - \alpha x \sin(\gamma x))^2$ for a fixed constant $\epsilon$, and set the constraints to be
$x_2 \le ax_1$, $x_2 \ge -ax_1$ for a fixed constant $a$.
We summarize the number of function evaluations and iterations taken within \cref{linear_pathological_results}.

In general, we notice the linear models use fewer evaluations than quadratic models.
We see that the method with the fewest iterations and function evaluations is the linear polyhedral shape.
This is likely because the polyhedral shape is allowed to search the entire outer trust region.
This also explains why the circumscribed ellipse and maximum volume simplex also perform well.
%We also notices that with a simple heuristic we were able to improve the ellipse slightly from 170 to 157.
Also, the scaled ellipsoid performs comparably to the unscaled version.

\pagebreak

\subsection{Hock-Schittkowksi test problems}


We tested these algorithms on several problems from the Hock-Schittkowski problem set \cite{Schittkowski1981MoreTE} and \cite{Hock1980}.
We selected the problems that have linear constraints: 21, 24, 25, 35, 36, 44, 45, 76, 224, 231, 232, 250, 251.
We summarize the results within \cref{linear_schittowski_results}.

% 37 was left out because it proved to be difficult.

\paragraph*{Performance profile.}
\label{performance_profile}
In order to better evaluate the algorithms on the problems across in this test set, we use a performance profile developed in \cite{More:2009:BDO:1654367.1654371}.
Given a set of Solvers $\mathcal S$ that solved a set of problems $\mathcal P$ with the number of evaluations of solver $s$ on problem $p$ being $N(s, p)$, the performance ratio is defined to be $r(s, p) = \frac{N(s, p)}{\min_{s \in \mathcal S} N(s, p)}$.
If the algorithm does not complete, then the number of evaluations is set to $\infty$.
The performance profile of a solver $s$ and parameter $\alpha \in [0, \infty)$ is then the number of problems for which the performance ratio is less than or equal to $\alpha$: 

\begin{align}
\rho(s, \alpha) = \frac 1 {\left\|\mathcal P \right\|} \left\|p \in \mathcal P | r(s, p) \le \alpha\right\|.
\end{align}

The $y$ axis of a performance plot is the performance profile, and the $x$ axis is the parameter $\alpha$.
Note that algorithms with high performance profiles for small values of $\alpha$ solved a large number of problems the most with the fewest evaluations, while algorithms that eventually reach high performance profiles with larger values of $\alpha$ solve a large set of problems.
The performance profile for the Hock-Schittkowski problem set is given in figure \cref{performance_profile_image}.

	
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.4]{images/performance_profile_plot.png}
    \caption[A performance profile comparing variants of the algorithm for linear constraints.]{
    	A performance profile comparing different variants of the algorithm for linear constraints.
    	We see that the polyhedral algorithm is both efficient and robust.
    }
    \label{performance_profile_image}
\end{figure}



The line segment search with 5 segments does not solve many problems, this is because several of the problems have dimension less than $5$, so that it was not even run on these.
Notice that the polyhedral search does very well.
We conjecture that this may not hold with modeled, nonlinear constraints.



% \color{red}
% 
% \section{Figure out where goes}
% 
% From here on, we will assume that the iterates $\xk$ are chosen according to \cref{linearly_constrained_dfo}.
% This implies that each of the sample points used to construct $\mfk$ are output of \cref{model_improving_algorithm}.
% 
% Because \cref{lipschitz_gradient} and \cref{lipschitz_hessian} are satisfied, $f$ also satisfies \cref{introduction_3_1} and hence the assumptions for \cref{quadratic_errors}.
% Notice that because $\kappa_f$, $\kappa_g$, $\kappa_h$ only depend on $p$, $L_h$, and $\Lambda$, these values do not depend on the iteration $k$:
% using the same tolerance $\xi_{\text{min}}$ within \cref{model_improving_algorithm} implies a bound on $\Lambda$.
% , and therefore $\mfk$ satisfies the requirements for \cref{quadratic_errors}.
% is a fully quadratic model over $B_{\infty}(\xk, \dk)$.
% \color{black}


\bibliography{thesis}
\bibliographystyle{ieeetr}
\end{document}



%==================================
%  parts of old paper follow:

\section{Parts from old paper}



\subsection{Background}\label{background}

\ifnum\INCLUDEOMITTED=1

\paragraph{Constrained derivative free algorithms}
To address the rise in these applications, new algorithms are being developed such as \cite{doi:10.1080/10556788.2015.1026968} which is an algorithm similar to the one presented here, but the sample points are not always feasible.
\cite{Troltzsch2016} presents another similar algorithm for equality based constraints.
\cite{infeasiblestarting} presents an algorithm which accepts an infeasible starting point.
\cite{Gao2018} also presents an algorithm for linearly constrained derivative free optimization that uses a backtracking technique to minimize the number of evaluations required.

\paragraph{Reviews}
Within \cite{DUMMY:intro_book} derivative-free methods are developed in detail.
This is the first text book devoted to derivative free optimization.
It contains a good explanation of ensuring geometry of the current set with poisedness for unconstrained problems and also covers other derivative-free methods including direct-search and line search.

A good review of derivative free algorithms and software libraries can be found in \cite{DUMMY:review}.
This compares several software libraries, and reviews the development of derivative free optimization since it started.
Another recent review can be found in \cite{DUMMY:review2} and \cite{larson_menickelly_wild_2019}.
\fi

\ifnum\INCLUDEOMITTED=1

%
% REMOVE THIS SECTION ??  down to *** 1 ***
\subsection{Model-based Trust Region Methods}

We will modify the following derivative free trust region algorithm.
%A set of poised points are chosen for some radius $\Delta_k>0$ about the current iterate.
The objective value and derivatives are approximated in a trust region around the current iterate to construct their model functions.
Next, this model function is minimized over the trust region and the minimum argument becomes the trial point.
The objective is evaluated at the trial point and a measure of reduction $\rho$ is computed.
If $\rho$ implies that sufficient reduction has been made and that the model approximates the function well, the trial point is accepted as the new iterate.
Otherwise, the trust region is reduced to increase model accuracy.
The algorithm terminates when both and a criticality measure $\chik$ and the trust region radius $\Delta_k$ reach sufficiently small thresholds of $\tau_{\chi}$ and $\tau_{\Delta}$.


For unconstrained optimization, the algorithmic framework is described in \cref{unconstrained_dfo}.

\begin{algorithm}[H]
    \caption{Unconstrained Derivative Free Algorithm}
    \label{unconstrained_dfo}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Initialize tolerance constants $\tau_{\chi} \ge 0$, $\tau_{\Delta} \ge 0$, starting point $x^{(0)}$, initial radius $\Delta_0 > 0$, iteration counter $k=0$, and constants $\omegadec \in (0, 1)$, $ \gammasm \in (0, 1)$, $\gammabi \in (\gammasm, 1)$.
            
        \item[\textbf{Step 1}] \textbf{(Construct the model function)} \\
            Call the model improvement ``\cref{model_improving_algorithm}" to provide a set of sample points $Y^{(k)}$.
            Evaluate the objective on these points and use interpolation \cref{interpolation_formula} to construct the model function $\mfk(x)$.
        
        \item[\textbf{Step 2}] \textbf{(Check stopping criteria)} \\
            Compute the criticality measure $\chik$ such as $\chik = \|\nabla\mfk(\xk)\|$. \begin{itemize}
                \item[] If $ \chik < \tau_{\chi} $ and $\Delta_k<\tau_{\Delta}$ then return solution $\xk$.
                \item[] If $ \chik < \tau_{\chi} $ but $\Delta_k\ge\tau_{\Delta}$ then  
                set $\Delta_{k+1} \gets \omegadec\Delta_{k}$, 
                $x^{(k+1)} \gets \xk$,
                $k \gets k+1$ and go to Step 1.
            \end{itemize}
        
        \item[\textbf{Step 3}] \textbf{(Solve the trust region subproblem)} \\
            Compute $\trialk = \argmin_{s\in B_2(0; \Delta_k)} \mfk (\xk + s)$ where $B_2(0; \Delta_k)$ is the ball of radius $\Delta_k$ defined in \cref{tab:TableOfNotation}.
            
        \item[\textbf{Step 4}] \textbf{(Test for improvement)} \\
            Compute $\rho$ with \cref{rho} \begin{itemize}
                \item[] If $\rho < \gammasm$ then $\xkpo \gets \xk$ (reject) and $\Delta_{k+1} \gets \omegadec\Delta_{k}$
                \item[] If $\rho \ge \gammasm$ and $\rho < \gammabi$ then $\xkpo\gets\xk+\trialk$ (accept) $\Delta_{k+1} \gets \omegadec\Delta_{k}$
                \item[] If $\rho \ge \gammabi$ and $\|\trialk\| = \Delta_{k}$ then $\xkpo=\xk+\trialk$ (accept) $\Delta_{k+1} \gets \omegainc\Delta_{k}$
                % and either increase the radius or decrease if $\nabla \mfk(\xk)$ is small
            \end{itemize}
            $k \gets k+1$ and go to Step 1.
    \end{itemize}
\end{algorithm}

This derivative-free optimization algorithm differs from the classical trust region algorithm in two important respects:
\begin{enumerate}
    \item Models are constructed without derivative information.
    \item The trust region radius $\Delta_k$ must go to zero as $k\to\infty$.
\end{enumerate}

This is required to ensure that the gradient of the model function is equal to the gradient of $f$ in the limit.
Our goal is to generalize this framework to handle constraints, where we must ensure no constraint violation occurs while also ensuring the accuracy of the models of the constraints.
\fi   % END OF REMOVED SECTION. *** 1 ***


An excellent introduction to model-based trust region methods for derivative-free optimization is provided in \cite{DUMMY:intro_book}.  At the heart of these methods is the idea of constructing model functions that approximate the objective function $f(x)$ over a trust-region.   


\subsection{Interpolation}
\label{interpolation}

Derivative free trust region methods construct models of the objective function $f(x)$ from a family of functions spanned by a set of $p + 1 \in \naturals$ basis functions  $\Phi = \{\phi_0, \phi_1, \ldots, \phi_p\}$. Each member of this family has the form $\mf(x) = \sum_{i=0}^p\alpha_i\phi_i(x)$ for some scalar coefficients $\alpha_i, i \in \{0, \ldots, p\}$.

We use interpolation to choose the coefficients $\alpha = [\alpha_0, \ldots, \alpha_p]^T$ so that $\mf$ agrees with $f$ on a set of $p+1$ sample points $Y = \{y^0, y^1, \ldots, y^p\}$ at which the function $f$ has been evaluated.
Thus, the coefficients $\alpha$ must satisfy the \emph{interpolation condition}
\begin{align}
\label{interpolation_condition}
    \mf(y^i) = \sum^p_{j=0}\alpha_j\phi_j(y^i) = f(y^i) \quad \forall \quad 0 \le i \le p.
\end{align}

% We can also write this equation in matrix form.
This equation can be written more compactly in the form
\begin{equation}\label{matrix_form}
V \alpha = \bar{f},
\end{equation}
where $\bar{f} = [f(y^0), f(y^1), \ldots, f(y^p)]^T$ and the Vandermonde matrix $V$ is defined by 

\begin{align}
\label{vandermonde}
V=M(\Phi,Y) :=
\begin{bmatrix}
    \phi_0(y^0)      & \phi_1(y^0)       & \ldots & \phi_{p}(y^0)      \\
    \phi_0(y^1)      & \phi_1(y^1)       & \dots  & \phi_{p}(y^1)      \\
                     &                   & \vdots &                    \\
    \phi_0(y^{p})    & \phi_1(y^{p})     & \ldots & \phi_{p}(y^{p})
\end{bmatrix},
\end{align}


\ifnum\INCLUDEOMITTED=1

% REMOVE to *** 2 ****
The interpolation
the interpolation condition becomes:
\begin{align}
\label{matrix_form}
V
\begin{bmatrix}
    \alpha_0     \\
    \alpha_1     \\
    \vdots       \\
    \alpha_p
\end{bmatrix}
=
\begin{bmatrix}
    f(y^0)     \\
    f(y^1)     \\
    \vdots     \\
    f(y^p)
\end{bmatrix}
\end{align}
\fi
% END REMOVE *** 2 ***

The interpolation equation \cref{matrix_form} has a unique solution if and only if $V$ is nonsingular.  In this case, we say that the sample set $Y$ is \emph{poised} for interpolation with respect to the basis functions $\phi_i$. 
However, even when $V$ is nonsingular but ``close" to singular, as measured by its condition number, the model's approximation may become inaccurate.

% Suppose that we use $p+1$ sample points $Y = \{y^0, y^1, \ldots, y^p\}$ to construct the approximation of $f$.

% MOVE THE FOLLOWING, OR DELETE
%
% We desire a method for choosing these sample points that provides error bounds on % not only the function values, but also on orders of derivatives in some region 
% around the current iterate.



% The model is constructed to agree with the original functions on at least the sample points: we evaluate the objective here, so that we know the true function values at these points.
% For the objective, this becomes

%It is convenient to write the model as a linear combination of basis polynomials $\{\phi_0, \phi_2, \ldots, \phi_p\}$.
<
\subsection{Sample set geometry}
\label{geometry}
The term \emph{geometry} describes how the distribution of points in the sample set $Y$ affects the model's accuracy.
% The condition number of $V$ measures how far the current Vandermode matrix is from being illpoised.
% REMOVED:
%Algorithms must be careful to avoid choices of sample points $Y$ that cause the %condition number of this matrix to be too large
In the case of polynomial model functions, a careful analysis of model accuracy can be performed using \emph{Lagrange polynomials}.
Let the space of polynomials with degree less than or equal to $d$ be denoted $\polydn$ and have dimension $p+1$.
The Lagrange polynomials $l_0, l_1, \ldots, l_p$ for the sample set $Y$ are a basis of $\polydn$ such that
\begin{align}
l_i(y^j) = \delta_{i,j}
\end{align}
where $\delta_{i,j} = \{0 \;\text{if}\; i\ne j,\; 1 \;\text{if} \; i = j \}$ is the Kronecker-delta function.
%For example, after this change of basis, note that the Vandermonde matrix becomes the identity matrix.
Thus, as shown in \cite{DUMMY:intro_book}, we can conveniently write
\begin{align}
\label{reg}
\mf(x) = \sum^p_{j=0}f(y^i)l_i(x).
\end{align}
%This implies computing the change of basis to the Lagrange polynomials amounts to inverting this Vandermonde matrix.
%This relationship allows us to use properties of the Vandermonde matrix and these Lagrange polynomials to find conditions on our sample points that ensure nice geometry.

We say that a set $Y$ is \emph{$\Lambda$-poised} for a fixed constant $\Lambda$ with respect to a basis $\Phi$ on the set 
$B \subset\Rn$ if and only if the Lagrange polynomials $l_i$ associated with $Y$ satisfy
\begin{align}
\Lambda \ge \max_{0\le i\le p}\max_{x\in B}|l_i(x)|.
\end{align}
In the case of interpolation over the quadratic polynomials, 
$ \mathcal{P}^2_n$, we say that $Y$ is \emph{$\Lambda$-poised for quadratic interpolation}.
The concept of $\Lambda$-poisedness allows us to establish the following error bounds, as shown in \cite[Theorem ]{DUMMY:intro_book}:

\begin{theorem}
\label{quadratic_errors}
Let $Y = \{y^0, y^1, \ldots, y^p\} \subset \Rn$ be a set of $p+1=\frac{(n+1)(n+2)}{2}$ sample points and $\Delta = \max_{1 \le j \le p} \|y^j-y^0\|$.  Suppose that $Y$ is $\Lambda$-poised for quadratic interpolation on $B(y^0; \Delta)$.    Then, for any constant $L > 0$, there exist constants $\kappa_{h}, \kappa_{g}$, and $\kappa_{f}$ such that the following error bounds hold for any function $f:\Rn \rightarrow \reals$ that is $LC^2$ with Lipschitz constant $L$ on an open set containing $B(y^0;\Delta)$:

\begin{align}
\|\nabla^2 f(y) - \nabla^2 m_f(y)\| \le \kappa_{h} \Delta \quad \forall y \in B_2(y^0; \Delta) \label{error_in_hessian}\\
\|\nabla f(y) - \nabla m_f(y)\| \le \kappa_{g} \Delta^2 \quad \forall y \in B_2(y^0; \Delta) \label{error_in_gradient} \\
|f(y) - m_f(y) | \le \kappa_{f} \Delta^3 \quad \forall y \in B_2(y^0; \Delta). \label{error_in_function} 
\end{align}
where $m_f$ is the quadratic model function interpolating $f$ on $Y$.
\end{theorem}

There is a close connection between the $\Lambda$-poisedness of $Y$ and the condition number of the Vandermonde matrix associated with the monomial basis $\bar{\Phi}$ $= \{ \bar{\phi}_0, \ldots, \bar{\phi}_p\}$ $=\{1, x_1, \ldots, x_n, x_1^2/2, \ldots x_n^2/2,x_1 x_2, \ldots, x_{n-1}x_{n}\}$.  In particular, let $\hat{Y}$ be the shifted and scaled sample set $\left\{\frac{(y^i-y^0)}{\Delta}|y^i \in Y\right\}$.    Then we have the following result

\begin{theorem}(\cite[Theorem 3.14]{DUMMY:intro_book}) Let $\hat{M} = M(\bar{\Phi},\hat{Y})$.  If $\hat{M}$ is  nonsingular and $\norm{\hat{M}}^{-1} \le \Lambda$, then the set $\hat{Y}$ is $\Lambda\sqrt{p+1}$-poised in the unit ball $B(0;1)$.  Conversely, if the set $\hat{Y}$ is $\Lambda$-poised for quadratic interpolation on the unit ball, then $\norm{\hat{M}^{-1}} \le \theta \Lambda \sqrt{p+1}$, where $\theta > 0$ is a constant dependent on $n$ but independent of $\hat{Y}$ and $\Lambda$.
\end{theorem}

%
% 
%
\fbox{ TO DO --- Move the following to later in the paper ---}

In particular, these bounds ensure that the following accuracy condition %is satisfied, which is used by \cite{conejo.karas.ea:global} to %prove convergence to a first order critical point: 
\begin{equation}
\label{accuracy}
\|\nabla \mfk(\xk) - \nabla f(\xk) \| \le \kappa_g \Delta_k
\end{equation}
 for some fixed constant $\kappa_g$ independent of $k$.
We will extend these results for ellipsoidal trust regions in %\cref{ellipsoidal_lambda}.
 
A more detailed discussion can be found in \cite{doi:10.1080/10556780802409296}, but a step to ensure good geometry is required for convergence analysis although it may come at the expense of adding more function evaluations.












\subsection{Geometry Improvement Algorithms}

Efficient implementations of model-based methods re-use sample points from previous iterations that fall within (or at least near) the current trust region.  New points are then added to the sample set using a model improvement algorithm as described in [11] and stated here in \cref{model_improving_algorithm}.

The model improvement algorithm starts with a set of $p+1$ sample points and then uses LU factorization with partial pivoting of the associated Vandermonde matrix to construct a set of pivot polynomials $\{u_0, \ldots, u_p\}$ that are closely related to the Lagrange polynomials.  

Each iteration of the algorithm identifies a point in the sample set to include in the final sample set.   In particular, on the $i$th iteration, the points $y^0, \ldots, y^{i-1}$ have already been included.   If a point $y^j$, $j \ge i$ can be found such that $u_i(y^j)$ has sufficiently large magnitude, then that point is added to the final sample set (by swapping it with $y^{i}$).     However, if no such point can be found, it indicates that including any of the remaining points in the final sample set would result in a poorly poised set.  Therefore, the point $y^i$ is replaced by a new point which is obtained by maximizing $|u_i(x)|$ over the trust region.

\paragraph{Note:}  Typically, we have fewer than $p+1$ previously evaluated sample points within the trust region at the beginning of each iteration.  Since the Model Improvement Algorithm requires a starting set of $p+1$ points, we add copies of $y^0$ to create a set with $p+1$ points.

%
% The following text was replaced
%
%Sample points are chosen by a geometry ensuring algorithm from %\cite{DUMMY:intro_book}.
%At any given time, the algorithm has evaluated 1 or more sample points.
%Initially, only the starting point $x_0$ is evaluated, so that points %must be added to the sample set.
%Evaluated points within the trust region should be reused when possible, %but the algorithm may have to replace some points to ensure a well poised %set on the new trust region.
%We call the algorithm that adds points, replacing where necessary, the %\emph{model improvement algorithm}.
%One classic such algorithm is presented in \cite{DUMMY:intro_book}.
%
%The idea behind this algorithm is to perform an LU factorization with %partial pivoting on the Vandermonde matrix.
%As we have seen, this computes the basis for the Lagrange polynomials %corresponding to $Y$.
%However, when this LU factorization encounters a small pivot, the point %corresponding to that row is replaced, improving the condition number of %the Vandermonde matrix.

%In practice, we first shift the sample set $Y$ by subtracting the current %iterate and dividing by the trust region radius:
%\begin{align}
%\bar{Y} = [0, \frac{y^1 - y^0}{\Delta}, \ldots, \frac{y^p - y^0}{\Delta}]
%\end{align}

%At times, the algorithm will not have all $p+1$ points.
%This can be because it is only given one point during initialization, or %because points not within the trust region are removed.
%Because the model improvement algorithm requires all $p+1$ points, we %initialize $y^i = y^0$ for any $0 < i \le p$ corresponding to a missing %point.
%We choose a threshold $0 < \ximin < 1$, and follow \cref{model_improving_algorithm}:


\begin{algorithm}[H]
    \caption{Model Improvement Algorithm--REPLACE THIS}
    \label{model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Initialize $i=1$.
            Given a non-empty set $Y$ of $p+1$ points. 
            Construct the Vandermonde matrix $V_{i,j} = \bar{\phi}_j(\frac 1 {\Delta}(y^i - y^0))$.
			Initialize constant $\ximin > 0$.
        \item[\textbf{Step 1}] \textbf{(Pivot)} \\
            Swap row $i$ with row $i_{\max} = \arg \max_{j|j\ge i} V_{j,i} $        
        \item[\textbf{Step 2}] \textbf{(Check threshold)} \begin{itemize}
                \item[] If $|V_{i,i}| < \ximin$ then select \label{next_point} $\hat y \in \argmax_{t | \|t\|\le 1} |\phi_i(t)|$
                \item[] Replace row $i$ with $V_{i, j} \gets \phi_j(\hat y)$.
                    \item[] $Y \gets Y \cup \{\hat y \} - \{y^i\}$
            \end{itemize}        
        \item[\textbf{Step 3}] \textbf{(LU)} \begin{itemize}
%                 \item[] Set $V_i \gets \frac{1}{V_{i,i}} V_i$
                \item[] Set $V_{\bullet j} \gets V_{\bullet j} - \frac{V_{i,j}}{V_{i, i}} V_{\bullet j} \forall j=i \ldots p$
            \end{itemize}
            If $i = p$ then \textbf{Stop}, otherwise Set $i \gets i+1$ and go to Step 1
    \end{itemize}
\end{algorithm}


At the completion of the algorithm, we obtain a $\Lambda$-poised  sample set $Y=\{y^0, \ldots, y^p\}$ that is $\Lambda$-poised, where $\Lambda$ is inversely proportional to $\xi_{\min}$ as given by the following result, which is shown in \cite{DUMMY:intro_book} through Theorems 6.5 and 3.14, and Section 6.7, Exercise 3: 
\begin{theorem}
\label{set_is_poised}
The sample set $Y$ obtained from \cref{model_improving_algorithm} is $\Lambda$-poised for quadratic interpolation, where $\Lambda > 0$ is a constant that depends only on $\xi_{\text{min}}$ and $n$ and is inversely proportional the $\xi_{\text{min}}$.
\end{theorem}

We will show in \cref{ellipsoidal_lambda} that this algorithm can 
 be used to create a poised set over an ellipsoidal region.


\subsection{Constructing feasible well-poised sample sets}

The central idea behind our method is to choose sample points at the $k$th iteration from within a feasible ellipsoid defined by
\[\ellipsek = \{x \in \Rn | (x - \mu^{k})^T \qk (x - \mu^{k}) \le 1\} \]
where $Q^{(k)}$ is a positive definite matrix and $\mu^{k}$ is the center of the ellipsoid.   
$Q^{(k)}$ and $\mu^k$ are chosen so that the ellipsoid conforms roughly to the shape of the feasible region near the current iterate.   Sample points are then selected by applying the model improvement algorithm to a transformed problem in which $\ellipsek$ is mapped onto a ball.

In addition to requiring the ellipsoid to be feasible, we also require that it lie within the current trust region.   To achieve this, we constrain the ellipsoid to lie within the  polytope
$\displaystyle P^k := \{x | Gx\le b,   \xki -\Delta_k \le x_i \le \xki + \Delta_k\}.$
In essence,  we have replaced the usual trust region $B_2(x^{(k)}, \Delta_k)$ with an $L_1$ ball, called the {\em outer trust region}, which is defined by
\begin{equation}
\label{trust_region}
\outertrk = B_{\infty}(\xk,\dk) = \{x\in \Rn | \; {\xk}_i - \dk \le x_i \le {\xk}_i + \dk \quad \forall 1\le i \le n\}.
\end{equation}
Defining $\displaystyle A = \left[\begin{array}{c} G \\ I \\ -I \end{array}\right]$ and $\displaystyle b = \left[\begin{array}{c} g \\ {\xk}_i+\Delta_k \\ -{\xk}_i+\Delta_k \end{array} \right]$, we can then write
\[P^{k} = \left\{ x | Ax \le b \right\}.\]

The following section analyzes the accuracy of the resulting model.  We will then describe methods for choosing $Q^{(k)}$ and $\mu^k$ 


\subsection{Poisedness over Ellipsoidal Trust Regions}
\label{ellipsoidal_lambda}

% TODO: Find a better reference
It is possible to show $\Lambda$-poisedness for an ellipsoidal region with a change of variables to the ball centered around the origin.
We wish to construct a model for $f(x)$ in the ellipsoidal region
$\ellipsek = \{x \in \Rn | (x - c)^T\qk(x - c) \le 1\}$ for some symmetric, positive definite
$\qk \in \mathbb R^{n\times n}$ and some center $c \in \Rn$.
We can give $\qk$ its eigen-decomposition $\qk = L D^2 L^T$, where $L^TL = I$ and $D$ is a diagonal matrix with nonnegative entries.
Let $\delta = \max_{x\in \ellipsek}\|x-c\|$.  Then, the transformation $T(x) = \delta DL^T(x - c)$ maps $ \ellipsek $ to the $\delta$ ball $\{u = T(x) \in \Rn \; | \; \|u\| \le \delta\}$.
Conversely, $ T^{-1}(u) = \frac 1 {\delta} LD^{-1}u + c$ maps the $\delta$ ball to the ellipsoidal region $ \ellipsek $.

% \cref{fully_quadratic}

\begin{theorem}
\label{shifted_ellipsoid}
Let $T$ and $\delta$ be as defined above, and let $\hat m_f(u)$ be a model of the shifted objective $\hat f(u) = f(T^{-1}(u))$ in the $\delta$ ball such that
there exist constants $\kappa_{ef}, \kappa_{eg}, \kappa_{eh} > 0$ such that for all $\{u \in R^n | \;\|u\| \le \delta \}$, we have
% for all $u \in B(0 ; \delta)$ we have the following error bounds:
\begin{align*}
|\hat m_f(u) - \hat f(u)| \le \kappa_{ef} \delta^3\\
\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \le \kappa_{eg}\delta^2\\
\|\nabla^2 \hat m_f(u) - \nabla^2 \hat f(u)\| \le \kappa_{eh}\delta.
\end{align*}

Then, with
\begin{align*}
\kappa_{ef}' = \kappa_{ef} \\
\kappa_{eg}' = \kappa_{eg}\sqrt{\kappa(\qk)} \\
\kappa_{eh}' = \kappa_{eh}\kappa(\qk),
\end{align*}
we have that for all $x \in \ellipsek$,
the model function $m_f(x) = \hat m_f(T(x))$ will satisfy
\begin{align*}
| m(x) - f(x)| \le \kappa_{ef}'\delta^3 \\
\|\nabla  m(x) - \nabla  f(x)\| \le \kappa_{eg}'\delta^2 \\
\|\nabla^2 m(x) - \nabla^2 f(x)\| \le \kappa_{eh}'\delta.
\end{align*}
\end{theorem}

\begin{proof}

% Notice  that for all $x\in \ellipsek$ we have 
% \begin{align*}
% \|x-c\| \le \delta \\
% \|T(x-c)\| \le \delta \\
% \end{align*}
% so that $\frac{\|T(x-c)\|}{\|x-c\|} \le 

We know that $\delta = \frac 1 {\sqrt{\lambda_{\text{min}}(\qk)}} = \frac 1 {\min_{i} D_{i, i}}$.
This means,
\begin{align*}
\kappa(\qk) = \kappa(D^2) = \frac{\max_{i}D_{i,i}^2}{\min_{i}D_{i,i}^2} = \delta^2 \max_{i}D_{i,i}^2 = \delta^2 \|D\|^2 \\
\|D\| = \frac 1 {\delta} \sqrt{\kappa(\qk)} \le \frac{\kappa_{\lambda}}{\delta}.
\end{align*}

Also, $\delta \le \dk$ as the ellipse is constructed within the outer trust region.

Then, we have for all $\{u = T(x) \; | \; \|u\| \le \delta \} \Leftrightarrow x \in \ellipsek$

\begin{align*}
 | m_f(x) - f(x)| = |\hat m(u) - \hat f(u)| \le \kappa_{ef}'\dk^3.
\end{align*}

Similarily, for the gradient we find:

\begin{align*}
\| \nabla m_f(x) - \nabla f(x)\| = \delta\left\|DL^T\left(\nabla\hat m_f(u) - \nabla \hat f(u)\right)\right\| \le \delta \|DL^T\|\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \le \sqrt{\kappa(\qk)}\kappa_{eg} \delta^2 \\
\end{align*}

Finally, we show that for the Hessian:

\begin{align*}
\| \nabla^2 m_f(x) - \nabla^2 f(x)\| = \delta^2\left\|DL^T\left(\nabla\hat m_f(u) - \nabla \hat f(u)\right)LD^T\right\| \le \delta^2 \|D\|^2\|\nabla \hat m_f(u) - \nabla \hat f(u)\| \le \kappa(\qk)\kappa_{eh} \delta \\
\end{align*}

\end{proof}

This shows that in order to have strongly quadratic model functions, we need only bound the condition number of $\qk$.

% Notice that in practice the model functions do not need to be mapped to the $\delta$ ball, because $\Lambda$-poisedness is scale invariant \cite{DUMMY:intro_book}.
%The implications of this proof are discussed further in the convergence discussion \cref{convergence_discussion}.





\subsection{Finding the maximum volume feasible ellipsoid for a fixed center}

\label{ellipse_optimization}
The error bounds given in \cref{shifted_ellipsoid} suggest that we can obtain more accurate model functions by minimizing the condition number of the matrix $Q^{(k)}$. 
Here, we first solve the problem of finding the maximum-volume feasible ellipsoid given a fixed center. Later we will explore strategies for moving the center of the ellipsoid in order to improve performance. 

We require the ellipsoid to be both feasible and also lie within the current trust region.  To simplify the problem formulation, we use an $L_1$ ball rather than an $L_2$ ball for our trust region.  In particular, define







%Because of this, we will first show how to find an ellipsoid with maximum volume given a fixed center.
We adopt a method similar to that described in \cite{Khachiyan1993}, which presents an algorithm for finding the maximum volume inscribed ellipsoid for a polytope.  
Let $P$ be a polytope defined by an $m \times n$ matrix $A$, $P = \{ x \in \Rn\; | \;  Ax \le b \}$.  In our algorithm $P$ is defined as the intersection of the feasible region with an $L_1$ ball.  We wish to find the maximum-volume ellipsoid $E \subset P$ centered at a point $\mu \in P$.

Let $\bar{b} = b - A\mu$ and $d = x - \mu$ so that the polytope becomes
\begin{align*}
P = \{ \mu + d \in \Rn \; | \;  Ad \le \bar{b} \}
\end{align*}
Using this transformation, the ellipsoid can then be centered at zero, and defined by a symmetric positive definite matrix $Q \succ 0$:
\begin{align*}
E = \{ d \in \Rn \; | \; \frac 1 2 d^T Q d \le 1 \}.
\end{align*}
Our goal is to determine the matrix $Q$ that maximizes the volume of $E$ such that $\mu + E \subset P$.   This is accomplished by solving the following problem for $Q$:
 
 
\begin{align}
 Q = V(\mu) = \sup_{Q \succeq 0} \det(Q^{-1})  \label{ellipse_1} \\
s.t. \quad A_i^T Q^{-1} A_i \le \frac 1 2 \bar{b_i}^2. \nonumber
\end{align}


\begin{theorem} 
Let $P = \{x \in \Rn | Ax \le b\}$, 
where $A$ is an $m \times n$ matrix, 
and $b \in \Rm$.  Let $\mu \in \intr{P}$. Suppose that $Q$ solves \cref{ellipse_1}, where $\bar{b} = b - A\mu$.  Then the ellipsoid $E = \{ x \in \Rn | (x-\mu)^T Q(x-\mu) \le 1\}$ has the maximum volume over all ellipsoids centered at $\mu$ and contained in $P$.
\end{theorem}

\begin{proof}
  


Define the auxiliary function $f(d) = \frac 1 2 d^T Q d$ so that $E = \{ d \in \Rn\; | \; f(d) \le 1 \}$.



Because $Q$ is positive definite, $f$ has a unique minimum on each hyperplane $A_i d = b_i$.
Let this minimum be $d^{(i)} = \argmin_{A_id =\bar{b}_i} f(d)$ for $i=1,\ldots,m$.
By the first order optimality conditions, there exists a $\lambda \in \Rm$ such that
\begin{align*}
\nabla f(d^{(i)}) = Q d^{(i)} = \lambda_i A_i 
\Longrightarrow d^{(i)} = \lambda_i Q^{-1}A_i \quad \forall 1\le i\le m
\end{align*}
We also know that
\begin{align*}
A_i^T d^{(i)} = \bar{b_i} \Longrightarrow
A_i^T \lambda_i Q^{-1}A_i = \bar{b_i} \Longrightarrow
\lambda_i = \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i}
\end{align*}
so that
\begin{align*}
d^{(i)} = \lambda_i Q^{-1}A_i = \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \quad \forall 1\le i\le m.
\end{align*}

Because $E \subset P$, we also know that $f(d^{(i)}) \ge 1$ for each $i$. Thus,
\begin{align*}
\frac 1 2 (d^{(i)})^{T} Q d^{(i)} \ge 1 \\
\Longrightarrow \frac 1 2 \bigg(\frac {\bar{b}_i}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i\bigg)^{T} Q \frac {\bar{b}_i}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \ge 1 \\
\Longrightarrow \frac 1 2 \frac {1}{A_i^T  Q^{-1}A_i}  \bar{b_i} A_i^T Q^{-1} Q \frac {\bar{b_i}}{A_i^T  Q^{-1}A_i}  Q^{-1}A_i \ge 1 \\
\Longrightarrow \frac 1 2 \frac {1}{A_i^T  Q^{-1}A_i}  \frac {\bar{b_i}^2}{A_i^T  Q^{-1}A_i}  A_i^T Q^{-1}A_i \ge 1 \\
\Longrightarrow \frac 1 2  \frac {\bar{b_i}^2}{A_i^T  Q^{-1}A_i} \ge 1 \\
\Longrightarrow \frac 1 2 \bar{b_i}^2\ge A_i^T  Q^{-1}A_i \\
\Longrightarrow A_i^T  Q^{-1}A_i \le \frac 1 2 \bar{b_i}^2
\end{align*}

Because the volume of the ellipsoid is proportional to the determinant of $Q^{-1}$, the maximal ellipsoid is defined by \cref{ellipse_1}.
\end{proof}



\subsection{Choosing the ellipsoid center}
The most obvious choice for the center of the ellipsoid is to choose $\mu^k = x^{(k)}$ (i.e., the current iterate).   However, if $\xk$ is too close to a boundary of the feasible region, this can result in a badly shaped ellipsoid.  We therefore, in this section, explore strategies for moving the center of the ellipsoid away from the boundary. 

% We consider several different approaches for determining the trust region center $\mu^k$.
%In this case, our \emph{ConstructTrustRegion} subroutine searches over multiple centers of the ellipsoid, however it may not need to construct the model functions for each until it has found a desirable ellipsoid.









\subsubsection{Circular Trust Region}
The simplest approach to maintaining a feasible trust region is to set the inner trust region radius sufficiently small.
Within the \emph{ConstructTrustRegion} subroutine, this method sets the trust region radius to the distance to the closest constraint:
$\outertrk = B_2(\xk, \min\{\dk, \min_{i}\frac{|A_i\xk - b_i|}{\|A_i\|} \})$.
In practice, this does not work well as the radius can become too small to allow adequate progress.

Two general strategies were considered for addressing this issue as illustrated in \cref{options_basis}.
One option is to shift the center of the inner trust region as long as it remains within the outer trust region.
The second option is to elongate the trust region along the nearest constraint as discussed in the next section.
Of course, both of these can be done at the same time.


\begin{figure}[h]
    \centering
    \includegraphics[width=200px]{images/small_circle.png}
    \includegraphics[width=200px]{images/shifted_center.png}
    \caption{When the current iterate is too close to a constraint, the circular trust region becomes too small. Shifting the trust region center helps remedy this. The star is the current iterate, the green is the outer trust region, and blue the inner.}
    \label{options_basis}
\end{figure}







\subsubsection{Ellipsoids}

In order to address this issue we considered using ellipsoidal trust regions.
Whereas the circle does not allow improvement when the current iterate lies along a constraint, an ellipsoid elongates along this constraint.
In figure \cref{ellipse_adv}, we have this type of iterate, but by using an ellipsoid we are still able to search towards the vertex of the feasible region.
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/advantage_of_ellipse_2.png}
    \caption{A nicer trust region}
    \label{ellipse_adv}
\end{figure}


More specifically, at iteration $k$, we choose a scaling factor $\pi^k$ and solve for an ellipsoid center $\mu^k$ and positive definite matrix $\qk$ to define an ellipsoid
$ \ellipsek = \{x \in \Rn \| \pi^k - \frac 1 2 (x - \mu^{k})^T\qk(x - \mu^{k}) \ge 0 \}$.
Of course, the simplest approach is to not change the center of the ellipsoid, but instead let $\mu^k = x^k$.



\subsubsection{Search Everything}

One approach is to search all possible centers within $ \feasible \cap \outertrk $.
That is, we solve:
$$\mu^k = \sup_{\mu \in \feasible \cap \outertrk} V(\mu)$$
where $V(\mu)$ is the volume of the ellipsoid defined in \cref{ellipse_1}.
%The search within the \emph{ConstructTrustRegion} is allowed to go anywhere within $ \feasible \cap \outertrk$.
This has the advantage that it captures much of the feasible region.
However, one problem with this search is that it can force the trust region away from the desired direction.
Notice that in \cref{ellipse_runs_away}, although the ellipsoid found has larger volume than before being shifted, this ellipsoid contains points farther from the corner containing the minimizer.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/everything_runs_1.png}
    \includegraphics[scale=0.4]{images/everything_runs_2.png}
    \caption{Searching $\feasible$}
    \label{ellipse_runs_away}
\end{figure}


One attempt to fix this problem is by limiting the search direction for the center of the ellipsoid.


\subsubsection{Line Searches}
Although $\mfk$'s minimizer over $\outertrk$  can appear anywhere, there are some reasons for expecting it to be at a ``vertex."
If it lies in the interior, there is little need for using constrained approaches once near the solution.

%The ellipsoid with maximum volume, however, tends to lead $ \sampletrk $ away from vertices.
One way of trying to ensure a feasible direction towards a vertex, while still allowing a larger volume ellipsoid, is by limiting the search for the new center to lie on line segments starting at the current iterate $\xk$.

For example, our first attempt was to simply search a line directed orthogonally away from the closest constraint.
This has obvious problems as shown in \cref{first_line_search}, as we should avoid letting the new center get closer to another constraint:

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/line_1.png}
    \includegraphics[scale=0.4]{images/line_2.png}
    \caption{Line searches}
    \label{first_line_search}
\end{figure}


For a given distance $d$, let the indices $i$ for which $\frac {|A_i x - b|}{\|A_i\|} \le d$


To fix this, we break the search space within the \emph{ConstructrustRegion} subroutine into segments based on the nearest constraints.
The algorithm works by choosing a set of up to $n_{\text{points}}$ points $s_1, s_2, \ldots, s_{n_{\text{points}}}$ that are each equidistant to a subset of the constraint's faces.
The center search then considers points along the line segments between these points.
% Namely, it starts at the current iterate and travels along a ray away from all the closest constraints until it reaches a point equidistant to yet another constraint.

More precisely, the first point is chosen to be the current iterate: $s_1 = \xk$.
The algorithm then repeats the following process for $i$ from $1$ to $n_{\text{points}}$.
First, compute the set of nearest constraints, where the distance from a point $x$ to a constraint $A_i$ is given by $d(A_i, x) = \frac {|A_i x - b|}{\|A_i\|}$.
While finding the next point $s_{i+1}$, let  $A_E$ be a normalized array of the equidistant faces $\{\frac{A_i}{\|A_i\|} | d(A_i, s_i) = \min_j d(A_j, s_i), i = 1, 2, \ldots, m\}$ and $b_E$ be the rows' corresponding values of $b$.
All other faces are called the remaining faces, and construct the matrix $A_R$ and vector $b_R$.
It then finds a search direction $p  = r{A_E}^T$ as a linear combination of the normal vectors to the equidistant faces.
%When the constraint violation of $s_i$ is non-zero, this search ray can be found by finding the point that doubles the current slack ${A_E}s_i-{b_E}$.
%This is given by $r{A_E}^T$ where $r$ solves the linear system ${A_E}(s_i + r{A_E}^T) - b_E = 2 ({A_E}n_i - b_E)$.
%If the current violation is zero, then the right hand side can be set to a vector of all ones to ensure that all slacks violations are the same: $A_E(s_i + r{A_E}^T) - b_E = 1$.
This search ray can be found by setting the slack to each equidistant face to a vector of all ones: $A_E(s_i + r{A_E}^T) - b_E = 1$.
We can travel along this ray until we reach a point that is the same distance to a remaining face.
Specifically, we can travel by 
\begin{align}
t = \argmin_j {\frac{d({A_E}_0, s_i) - d({A_R}_j, s_i)}{ {A_R}_j - d({A_E}_0) p} | ({A_R}_j - d({A_E}_0) p > 0 }. 
\end{align}

We can then set $s_{i+1} = s_{i} + t p$.

Of course, $n_{\text{points}}$ must be less than or equal to $n + 1$ in order for this to be defined.
Also, the algorithm must stop early if $A_E$ contains parallel faces.

% if we let $\nabla \modelconstrainti(\xk) = A_i$ be the $i$th row of $A$, then we define the distance from a search point $s$ so the $i$th constraint to be


This means that we can define a class of searches that each limit the number of line segments to search $n_{\text{points}}$.

In figure \cref{line_can_run}, the red line shows the line segments equidistant their closest constraints.
Notice that with two line segments, the algorithm can already choose new centers further from the vertex.

% TODO: REPLACE PICTURES
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/run_away_1.png}
    \includegraphics[scale=0.4]{images/run_away_2.png}
    \caption{Ellipse runs away from the optimizer}
    \label{line_can_run}
\end{figure}







=========

This section describes strategies for choosing the center $\mu^k$ for the ellipsoid $E^k$.  At issue is the fact that if the center of the ellipsoid is too close to the boundary of the feasible region, then the condition number of $Q^{k}$ may be unacceptably large.  We there   There are several issues at play:
\begin{itemize}
    \item The ellipsoid should include the current iterate (or maybe not).
    \item We want the ellipsoid
\end{itemize}


\subsubsection{Ellipsoid Choices}

There are a number of issues to be solved to define this ellipsoid:
\begin{itemize}
\item How do we ensure that $\xk \in \ellipsek $?
\item How do we choose $\ellipsek$ in such a way that it does not limit travel along a decent direction?
\item How do we choose the center of the ellipsoid $\mu^k$?
\end{itemize}

% \item How do we choose $\ellipsek$ to make the  ellipsoid as large as possible while ensuring that $ \ellipsek \subset \outertrk \cap \feasible $?

If $\xk \not \in \searchtrk $, the ellipse may not even contain a point with any reduction.
Thus, we have implemented a few ways of ensuring the current iterate is within the search trust region.
This can be done by either of the following two options:
\begin{itemize}
\item Adding a constraint to the ellipsoid problem to include the original point.
\item Expand the size of the ellipsoid.
\end{itemize}

%IMAGES GO HERE

\paragraph{Adding a constraint.}
In order to include the original point as a constraint, we add a constraint to the definition of the ellipsoid of the following form:
$$ \pi^k - \frac 1 2 (x^k - \mu^{k})^T\qk(x^k - \mu^{k}) \ge 0. $$
Constraints of this nature make finding the ellipsoid much more expensive.
This is because the optimization problem we construct uses ${\qk}^{-1}$ as decision variables, so that constraints in terms of $\qk$ must model matrix inversion.

\paragraph{Increase the size.}
An alternative is to scale $\qk$ by a constant.
We use the scaling factor $\pi^k$ defined by

$$\pi^{(k)} = \max \{1, \frac 1 {2} (x^{k} - \mu^{k})^T \qk (x^{k} - \mu^{k})^T \}$$

and let the ellipsoid be:
$$\ellipsek = \{x \in \Rn | 1 - \frac 1 {2\pi^k} (x - \mu^{k})^T \qk (x - \mu^{k}) \ge 0\} $$
However, this means that in general $\ellipsek \not \subset \feasible$ so that the trust region subproblem must contain constraints for both the ellipsoid and the feasible region: $\searchtrk = \ellipsek \cap \domain$.

To help mitigate the second issue, we maximize the volume of the ellipsoid.
However, the choice of ellipsoid center can still limit travel along a decent direction.
Choosing the best center is the topic of the next section.\





\subsection{Algorithm Components}

Before describing the algorithm, we discuss several components referenced within an algorithm template.

\subsubsection{Criticality Measure}

In order to define stopping criteria for the algorithm, we introduce a criticality measure $\chi$ which goes to zero as the iterates approach a first order critical point.
When the criticality measure is small, we must also decrease the trust region radius.
Once this has reached a small enough threshold $\tau_{\chi}$ and the trust region is small enough ($\Delta_k < \tau_{\Delta}$), we can terminate the algorithm.
For now, our algorithm is designed to work with convex constraints, so we employ a classic criticality measure discussed in \cite{ConnGoulToin00} of
\begin{align}
\label{critical}
\chik = \|\xk - \text{Proj}_{\feasible}(\xk- \nabla \mfk(\xk))\|
\end{align}
The first order optimality conditions for $x^{\star} \in \Rn$ to by a local optimum of $f$ is that $x^{\star}$ satisfies
\begin{align*}
x^{\star} = \text{Proj}_{\feasible}\left(x^{\star} - \nabla f(x^{\star})\right).
\end{align*}
For linear constraints, this condition is necessary and sufficient.
Thus, our criticality measure measures how far the current iterate is from satisfying the first order optimality conditions for $\xk$ to be a optimum of $\mfk$.
In turn, as $\dk \to 0$, the model $\mfk$ better approximates $f$ and $\xk$ approaches an optimum of $f$.

\subsubsection{Assessing Model Accuracy and Radius Management}

Each iteration that evaluates a trial point must also test the accuracy of the model functions.
To test the accuracy, we calculate a quantity
\begin{equation}
\label{rho}
\rho_k = \frac{f(\xk) - f(\xk+\trialk)}{\mfk(\xk) - \mfk(\xk+\trialk)}
\end{equation}
which measures the actual improvement over the predicted improvement.
A small $\rho_k$ implies the model functions are not sufficiently accurate.
Values of $\rho_k$ close to $1$ imply that the model accurately predicted the new objective value.
A large $\rho_k$ implies progress minimizing the objective although the model was not accurate.
This has been widely used within trust region frameworks such as \cite{Conn:2000:TM:357813} and within a derivative free context \cite{DUMMY:intro_book}.
The user supplies fixed constants $0 < \gammasm \le \gammabi \le 1$ as thresholds on $\rho_k$ and $0 < \omega_{\text{dec}} < 1 \le \omega_{\text{inc}}$ as decrement or increment factors to determine the trust region update policy.


\subsection{Trust Regions}
Our algorithm maintains up to three trust regions.
The outer trust region is an $L_1$ ball of radius $ \dk $ defined by
\begin{equation}
\label{trust_region_outer}
\outertrk = B_{\infty}(\xk,\dk) = \{x\in \Rn | \; \xki - \dk \le x_i \le \xki + \dk \quad \forall 1\le i \le n\}.
\end{equation}

Note that the outer trust region may include infeasible points.
To ensure feasibility of all sample points, we construct an inner trust region for sample points $ \sampletrk $  satisfying 
$\sampletrk \subset \outertrk \cap \feasible$ and $\xk \in \sampletrk $.
However, we do not want to limit the search for a new iterate to the same trust region we use to construct the model.
This means we introduce another trust region $ \searchtrk $ that also satisfies $ \searchtrk \subset \outertrk \cap \feasible$ and $\xk \in \searchtrk $ for the trust region subproblem.

\paragraph{The Sample Region}
\label{sample_region_choices}
We consider general strategies for constructing $ \sampletrk $ and $ \searchtrk $.
\begin{itemize}
\item[1.] Take 
\begin{align}
\label{redpill} \sampletrk = \searchtrk = \outertrk \cap \feasible.
\end{align} This results in a polyhedral trust region, so we refer to this approach as the \emph{Polyhedral Trust Region Approach}.
% \item[2.] Let $\label{hybrid} \sampletrk \subseteq \searchtrk = \outertrk \cap \feasible $ where $\sampletrk$ has an ellipsoidal shape. This is referred to as the \emph{Hyrbid Trust Region Approach}
\item[2.] Force 
\begin{align}\label{bluepill} \sampletrk \subseteq \searchtrk \subseteq \outertrk \cap \feasible
\end{align} where $\sampletrk$ has an ellipsoidal shape. This is referred to as the \emph{Ellipsoidal Trust Region Approach}
\end{itemize}

The advantage of the ellipsoidal trust region approach \cref{bluepill} is that we can reuse classical methods for ensuring good geometry.
We can construct $\sampletrk$ to be ellipsoidal and use efficient algorithms within \cite{DUMMY:intro_book} to satisfy \cref{accuracy}.
However, we must be careful while choosing $ \searchtrk$ to allow sufficient reduction when we solve the trust region subproblem using the inner trust region.
The search trust region is used while selecting the next iterate:
\begin{align*}
\trialk = \argmin_{\trialk \in \searchtrk} \mfk(\xk + \trialk).
\end{align*}

\paragraph{The Search Region}
\label{search_region_choices}
When using the ellipsoidal trust region approach, we have two choices for this trust region.
We can take
\begin{align}
\searchtrk = \sampletrk \label{search_a_little}
\end{align}
or
\begin{align}
\searchtrk = \outertrk \cap \feasible \label{search_a_lot}.
\end{align}
Namely, in \cref{search_a_little} with an ellipsoidal inner trust region, we still have an option to select our trial point from the entire $\trialk \in \outertrk \cap \feasible$.

To complete the polyhedral trust region approach \cref{redpill},
we need some redefinition of poisedness for polyhedral shapes.
However, since the trust region is larger, it is easier to ensure sufficient reduction.
This strategy has the drawback that it will yield sample points close to the boundary of the feasible region.
This may cause more infeasible evaluation attempts when we use models to approximate black-box constraints this may.

The classical methods for ensuring good geometry require an optimization call to the model functions over a sphere.
This is no longer possible in the polyhedral trust region approach.
However, the bounds produced over the entire trust region may also be stronger than required as the models will only be used on the feasible region.
This may mean the geometric requirements can be reduced.

Within our algorithm, if $ \outertrk \subseteq \feasible$ we can set $ \sampletrk $ to be a sphere.
This saves the computation of $ \sampletrk $ when it is not needed, as there are no nearby constraints.









\subsection{Algorithms}

\subsubsection{Sufficient Model Reduction}

To ensure sufficient reduction of the objective's model function during each iteration, we impose the following efficiency condition:
\begin{equation}
\label{efficiency}
\mfk(\xk) - \mfk(\xk + \trialk) \ge \kappa_f \chi_k \min\left\{ \frac{\chi_k}{1+\|\nabla^2 \mfk(\xk)\|}, \dk, 1 \right\}
\end{equation}
where $\kappa_f$ is a constant independent of $k$.
This is widely used within trust region frameworks such as \cite{conejo.karas.ea:global} and \cite{Conn:2000:TM:357813}.
It can be shown that the \emph{generalized Cauchy point} satisfies this condition \cite{Conn:2000:TM:357813}.



\subsection{Algorithm Template}

We follow an algorithm template described in \cite{doi:10.1080/10556788.2015.1026968}, where variations of the algorithm have different choices of $ \sampletrk $ implemented in a \emph{ConstructTrustRegion} subroutine.
The different versions are described in the remainder of this section.

% HOW ABOUT JUST MAKE $\eta > 0$?


\begin{algorithm}[H]
    \caption{Always-feasible Constrained Derivative Free Algorithm}
    \label{constrained_dfo}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Initialize tolerance constants 
            $\tolcrit \ge 0$,
            $\tolrad \ge 0$,
            starting point $x^{(0)} \in \feasible$,
            initial radius $\Delta_0 > 0$,
            iteration counter $k=0$,
            $0 < \omegadec < 1 \le \omegainc$,
            $0 < \gammasm < \gammabi \le 1$,
            $\alpha > 0$,
            $k \gets 1$,
            $0 < \omegadec < 1 \le \omegainc$,
            $0 < \gammasm < \gammabi < 1$.
            
        \item[\textbf{Step 1}] \textbf{(Construct the model)} \\
            $ \sampletrk \gets $ \Call{ConstructTrustRegion}{$\dk, \xk$}.
            Ensure that the sample points are poised with respect to $ \sampletrk $ for \cref{accuracy} by calling \cref{model_improving_algorithm}.
            Construct $\mfk$ as described in \cref{reg} to construct $\mfk(x)$.
        
        \item[\textbf{Step 2}] \textbf{(Check stopping criteria)} \\
            Compute $\chi_k$ as in \cref{critical}. \begin{itemize}
                \item[] If $ \chik < \tau_{\xi} $ and $\dk <\tau_{\Delta}$ then return $\xk$ as the solution.
                \item[] Otherwise, if $\dk > \alpha \chik$ then 
                $\Delta_{k+1} \gets \omegadec\dk$, 
                $x^{(k+1)} \gets \xk$,
                $k \gets k+1$ and go to Step 1.
            \end{itemize}
        
        \item[\textbf{Step 3}] \textbf{(Solve the trust region subproblem)} \\
            Compute $\trialk = \min_{s \in \searchtrk} \mfk(\xk + \trialk)$.
            % \item[] This can also be $\trialk = \min_{s \in \outertrk \cap \feasible} \mfk(\xk + \trialk)$ depending on the choice made in \cref{which_trust_region}.
            
        \item[\textbf{Step 4}] \textbf{(Test for improvement)} \\
            Evaluate $f(\xk + \trialk)$ and evaluate $\rho_k$ as in \cref{rho} \begin{itemize}
                \item[] If $\rho_k < \gammasm$ then $\xkpo=\xk$ (reject) and $\Delta_{k+1} = \omegadec\dk$
                \item[] If $\rho_k \ge \gammasm$ and $\rho < \gammabi$ then $\xkpo=\xk+\trialk$ (accept), $\Delta_{k+1} = \omegadec\dk$
                \item[] If $\rho_k > \gammabi$ then $\xkpo=\xk+\trialk$ (accept), $\Delta_{k+1} = \omegainc\dk$
                % and either increase the radius or decrease if $\nabla \mfk(\xk)$ is small
            \end{itemize}
            $k \gets k+1$ and go to Step 1.
    \end{itemize}
\end{algorithm}
 

Much of the work is deferred to the \emph{ConstructTrustRegion} subroutine.
We will describe several different approaches for this subroutine.

\subsection{Polyhedral Trust Region Approach}
One simple approach to handle partially-quantifiable constraints is to maintain the same trust region as the classical algorithm, but avoid letting points fall outside the feasible region within the model improvement algorithm \cref{model_improving_algorithm}.
That is, we add the constraints $\mcik(x) \le 0 \forall i \in \mathcal{I}$ and $\mcik(x) = 0 \forall i \in \mathcal{E}$ to the model improvement algorithm while selecting new points.
This constrains the new points to also lie within the current model of the trust region in \cref{model_improving_algorithm}, Step 2.
The search space for this optimization problem will be the feasible region intersect the trust region: $\feasible \cap \outertrk $.

The challenge lies in finding sufficiently poised sample points.
Note that \cref{model_improving_algorithm} uses a parameter $  \ximin $ as a lower bound of the pivot values of the Vandermonde matrix.
For unconstrained problems, this approach could always find a pivot value for any $ \ximin \in (0,1)$ because it optimized over a sphere.
However, when requiring points to live within $ \feasible \cap \outertrk $, it can happen that even after replacing a point, we still have not satisfied this bound.
In \cref{lspc}, for some values of $  \ximin $, there is no point in $ \feasible \cap \outertrk $ that will leave a sufficiently large pivot.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/bad_lambda.png}
    \caption{Limited sample point choice}
    \label{lspc}
\end{figure}

%As the number of dimensions grows the ratio of volume of the trust region intersect the feasible region to the feasible region can become smaller.

One way to handle this is to introduce a $\xi_{\text{cur}}$ which is allowed to decrease.
(Possibly, until a threshold is reached for maintaining a fixed $\Lambda$.)
If the new point does not improve the geometry of the set significantly, then there is no other point that would do better.
To test this, we introduce a constant $\delta_{\text{improv}}>0$ and require a new point to increase the current pivot by a factor greater than $\delta_{\text{improv}}$.
If the new point does not satisfy this test, we proceed with our current point and possibly decrease $\xi_{\text{cur}}$.
The new modified improvement algorithm is described in \cref{modified_model_improving_algorithm}:

\begin{algorithm}[H]
    \caption{Modified Model Improvement Algorithm}
    \label{modified_model_improving_algorithm}
    \begin{itemize}
        \item[\textbf{Step 0}] \textbf{(Initialization)} \\
            Initialize $i=1$.
            If the current sample set does not have $p$ points, repeat one of the current points. 
            Construct the Vandermonde matrix $V_{i,j} = \phi_j(\frac 1 {\Delta}(y^i - y^0))$.
            Initialize $0 < \ximin < \xi_{\text{desired}}$, $0 <\delta_{\text{improv}} < 1$,
            $  \xi_{\text{cur}} = \xi_{\text{desired}}$.
            
        \item[\textbf{Step 1}] \textbf{(Pivot)} \\
            Swap row $i$ with row $i_{\max} = \arg \max_{j|j\ge i} V_{j,i} $
        
        \item[\textbf{Step 2}] \textbf{(Check threshold)} \begin{itemize}
                \item[] If $|V_{i,i}| \ge \xi_{\text{cur}} $ then go to Step 3
                \item[] $ \hat y = \arg\max_{t \in \sampletrk \cap X} |\phi_i(t)|$
                \item[] If $\label{impossibly_poised} |\phi_i(\hat y)| < \ximin$ then \textbf{Stop}: the algorithm failed
                \item[] If $\xi_{\text{cur}} - |\phi_i(\hat y)| > \delta_{\text{improv}} \xi_{\text{cur}}$ then replace $V_{i,j}$ with $\phi_j(\hat y)$ and $\xi_{\text{cur}} \gets |\phi_i(\hat y)|$
            \end{itemize}
        
        \item[\textbf{Step 3}] \textbf{(LU)} \begin{itemize}
                \item[] Set $V_i \gets \frac{1}{V_{i,i}} V_i$
                \item[] Set $V_{,j} \gets V_{, j} - V_{i,j} V_{\bullet, i} \forall j=i \ldots p$
            \end{itemize}
            $i \gets i+1$
            Go to step 1 unless $i > p$
    \end{itemize}
\end{algorithm}

The \emph{ConstructTrustRegion} subroutine for this approach follows the prototype with $\sampletrk = \searchtrk = \feasible \cap \outertrk $.
As is usual, we may also wish to remove points larger than a certain radius from the current model center.
% If a lower bound $\kappa_{\phi}$ on the maximum value of each polynomial is known ahead of time, then the check on \cref{impossibly_poised} is not needed.
% That is, for a given set of linear constraints and largest trust region radius, it may be possible to calculate $\xi_{\text{min}} \le \kappa_{\phi} \le \max_{V}\max_{j}\max_{i}\|\phi_i(y^j)\|$.

%Another interesting approach we have not investigated is to decrease the size of the sample set when a new point cannot be computed.

%The analysis for this approach may be more difficult.




\subsection{Ellipsoidal Trust Region Approach}

If we adopt the ellipsoidal trust region approach to maintain a feasible inner trust region with a ``nice" shape we ensure of a stronger version of \cref{accuracy}.
Namely, we know from \cref{ellipsoidal_lambda} that 
\begin{align*}
    \|\mfk(x) - \nabla f(x) \| \le \kappa_g \Delta_{k} \quad \forall x \in \searchtrk.
\end{align*}
If we also choose our trial point with \cref{search_a_little}, we have no guarantee of satisfying the efficiency condition \cref{efficiency} because $\dk$ is the outer trust region radius.
However, the model will likely be more accurate over this region.

%If bounds can be shown relating the model error of the inner trust region to the outer trust region, then we will satisfy \cref{accuracy}.
%In this case, classical methods ensure that $\|\nabla f(x^{(k)}) - \nabla m_f(x^{(k)})\| < \Delta_{inner} \le \dk$.





\subsection{Convergence Discussion}

\subsection{Algorithm Assumptions}

Here, we show convergence for one version of \cref{constrained_dfo}.
Namely, we choose to satisfy \cref{bluepill} and let $\sampletrk$ have an ellipsoidal shape as described in \cref{sample_region_choices}. 
Also, we will select \cref{search_a_lot} as discussed in \cref{search_region_choices}: namely, $\searchtrk = \outertrk \cap \feasible$.
To do this, we require the following assumptions.

Here, we will let $\domain$ be some open set containing the feasible region: $\feasible \subset \domain$.

\begin{assumption}
\label{lipschitz_gradient}
The function $f$ is differentiable and its gradient $\nabla f$ is Lipchitz continuous with constant $L_{g} > 0$ in $\domain$.
That is,
\begin{align}
\|\nabla f(x) - \nabla f(y)\| \le L \|x - y\| \quad \forall x, y \in \domain.
\end{align}
\end{assumption}

\begin{assumption}
\label{for_fully_quadratic}
\label{lipschitz_hessian}
The function $f$ has Lipschitz continuous hessian with constant $L_h > 0$ in $\domain$.
That is,
\begin{align}
\|\nabla^2 f(x) - \nabla^2 f(y)\| \le L_h \|x - y\| \quad \forall x, y \in \domain.
\end{align}
\end{assumption}

\begin{assumption}
\label{lower_bound}
The function $f$ is bounded below over $\domain$.
That is,
\begin{align}
f(x) \ge \fmin \quad \forall x \in \domain.
\end{align}
\end{assumption}


\begin{assumption}
\label{uniformly_bounded_hessians_of_mf}
The Hessian's of $\mfk$ are uniformly bounded at each iterate. That is, there exists a constant $\beta \ge 1$ such that 
\begin{align}
\|\nabla^2 \mfk(\xk)\| \le \beta - 1\quad \forall k \ge 0.
\end{align}
\end{assumption}

% \begin{assumption}
% \label{accuracy_assumption}
% There exists a constant $\delta_g$ such that 
% \begin{align}
% \|\nabla m_k(\xk) - \nabla f(\xk)\| \le \delta_g \dk \;\forall k \ge 0.
% \end{align}
% \end{assumption}

\begin{assumption}
\label{interior_point}
There exists a point $\bar x$ within the interior of the feasible region: 
\begin{align}
G\bar x < g.
\end{align}
\end{assumption}

\label{convergence_discussion}


\subsection{Required Assumptions}

If the tolerances $\tau_{\chi} = 0$ and $\tau_{\Delta} = 0$ are set to zero, \cref{constrained_dfo} is a particular implementation of the algorithm presented in \cite{doi:10.1080/10556788.2015.1026968}.
This means we only need to satisfy the requirements detailed in their convergence analysis.
For your convenience, we duplicate these assumptions.
\begin{itemize}
\item[$H_0$] The efficiency condition \cref{efficiency} is satisfied.
\item[$H_1$] The function $f$ is differentiable and its gradient $\nabla f$ is Lipchitz continuous with constant $L > 0$ in $\domain$.
\item[$H_2$] The function $f$ is bounded below over $\domain$.
\item[$H_3$] The matrices $H_k$ are uniformly bounded. That is, there exists a constant $\beta \ge 1$ such that $\|\nabla^2 \mfk\| \le \beta - 1$ for all $k \ge 0$.
\item[$H_4$] There exists a constant $\delta_g$ such that $\|\nabla m_k(\xk) - \nabla f(\xk)\| \le \delta_g \dk$ for all $k \ge 0$.
\end{itemize}

$H_0$ can be satisfied within our algorithm by selecting the Generalized Cauchy Point \cite{Conn:2000:TM:357813} to solve the trust region subproblem.
Notice that $H_1$, $H_2$, and $H_3$  are kept as hypothesis within our algorithm.
This leaves $H_4$, which is the topic of \cref{satisfying_accuracy}.
However, first we show a way of using a more straightforward version of $H_3$ in \cref{simpler_h3}.

\subsection{Satisfying these assumptions}

\subsubsection{More simple $H_3$}
\label{simpler_h3}
First, we show that \cref{uniformly_bounded_hessians_of_f} can be used instead of \cref{uniformly_bounded_hessians_of_mf} under some restrictions.
Namely, for this to be true, we also first assume:
\begin{assumption}
\label{delta_max}
There exists a $\dmax > 0$ such that $\dk \le \dmax$ for all $k \ge 0$.
\end{assumption}

With this modest assumption, we can make the assumptions more straightforward by replacing \cref{uniformly_bounded_hessians_of_mf} with \cref{uniformly_bounded_hessians_of_f}:

\begin{assumption}
\label{uniformly_bounded_hessians_of_f}
The Hessian's of $f$ are uniformly bounded at each iterate. That is, there exists a constant $\beta \ge 1$ such that $\|\nabla^2 f\| \le \beta - 1$ for all $k \ge 0$
\end{assumption}


This is the result of the following lemma:
\begin{lemma}
\label{replacing_h3}
Assume that 
\cref{uniformly_bounded_hessians_of_f},  
\cref{lipschitz_hessian}, 
\cref{introduction_3_1},
and \cref{delta_max} are satisfied and that each $k \in \naturals$, $\mfk$ is a quadratic model of $f$ over $B_{\infty}(\xk, \dk)$  as in \cref{quadratic_errors}.
Then \cref{uniformly_bounded_hessians_of_mf} is also satisfied.
\end{lemma}

\begin{proof}
Let $\beta_1 \ge 1$ be such that for all $k \ge 0$:
\begin{align*}
\|\nabla^2 f(\xk) \| \le \beta_1 - 1
\end{align*}
% \cref{model_improving_algorithm},
Because $\mfk$ are fully quadratic, we know that \cref{error_in_hessian} is satisfied.
Combining this with \cref{delta_max} we see that
\begin{align*}
\|\nabla^2 f(\xk) - \nabla^2 m_f(\xk) \| \le \kappa_{h} \dk \le \kappa_{h} \Delta_{\text{max}}
\end{align*}
Defining $\beta_2 = \kappa_{h} \Delta_{\text{max}} + \beta_1 \ge 1$, we see that
\begin{align*}
\|\nabla^2 m_{f}(\xk) \| \le \|\nabla^2 m_{f}(\xk) - \nabla^2 f(\xk)  \| + \|\nabla^2 f(\xk) \|  \le \beta_2 - 1 .
\end{align*}
\end{proof}

% For any $x \in \feasible$, we have that the set of gradients of active constraints is linearly independent. That is, the vectors $\{\nabla c_i(x) |  \forall i \in \activei(x)\}$ is linearly independent.


\subsubsection{Satisfying the Accuracy Assumption}
\label{satisfying_accuracy}
The only remaining assumption is the accuracy condition $H_4$.

As discussed in \cref{ellipsoidal_lambda}, we know that if the condition number of $\qk$ is bounded, 
we can map a poised set over the unit ball to $\sampletrk$.
However, we must also ensure that we are always able to find a feasible ellipsoid.
Although it is not always possible to find a feasible ellipsoid that contains the current iterate,
we can find a feasible ellipsoid that only needs to be scaled by a constant to do so.
This ellipsoid must satisfy the following conditions:

\begin{definition}
An ellipsoid $E_k$ determined by a positive definite, symmetric matrix  $\qk$, a center $c^{(k)} \in \Rn$, and a radius $\epsilon_k $
is said to be a \textbf{suitable ellipsoid} for iteration $k$ if all of the following are satisfied:
\begin{itemize}
\item[1.] The ellipsoid $E_k = \{x | (x - c)^TQ(x - c) \le \frac 1 2 \epsilon^2 \}$ satisfies $E_k \subseteq P_k$ as defined in \cref{polyhedron_k}
\item[2.] The ellipsoid $\hat E_k = \{x | (x - c)^TQ(x - c) \le  \epsilon^2 \}$ satisfies $\xk \in \hat E_k$.
\item[3.] $\sigma(\qk)$ is bounded independently of $k$.
\end{itemize}
\end{definition}

Because the ellipsoid we construct must be feasible with respect to both the trust region and the constraints, we simplify notation by naming 
\begin{align}
P_k = \{x \in \Rn | \quad Gx \le g, \|x - \xk\|_{\infty} \le \dk \} = \{x \in \Rn | \ak x \le \bk, \|{\ak}_i\| = 1 \} \label{polyhedron_k}.
\end{align}
This is the normalized polyhedron formed by adding the trust region constraints for iteration $k$ to the problem constraints.
The active constraints at any point will be denoted by
\begin{align}
\activei(x) = \{1 \le i \le m | c_i(x) = 0 \Leftrightarrow G_ix = g_i \} \label{active_indices}
\end{align}

It will be convenient to use a feasible direction with respect to the active constraints at a given point.
To this end, let $\mathcal S \subseteq \{1, \ldots, m\}$ be arbitrary, and define
\begin{align}
\alphaone (\mathcal S) = \begin{cases}
\argmax_{\|u\| = 1} \min_{i \in \mathcal S} -u^TG_i & \text{if} \; \mathcal S \ne \emptyset \\
\emptyset & \text{if} \; \mathcal S = \emptyset
\end{cases} \label{define_alpha_one} \\
\alphatwo(\mathcal S) = \begin{cases}
\max_{\|u\| = 1} \min_{i \in \mathcal S} -u^TG_i & \text{if} \; \mathcal S \ne \emptyset \\
1 & \text{if} \; \mathcal S = \emptyset
\end{cases} \label{define_alpha_two}\\
\alphathree(x) = \alphatwo\left(\activei(x)\right) \label{define_alpha_three} \\
\alpha_k =  \alphathree\left(\xk\right) \label{define_alpha_k} \\
\uk \in  \alphaone\left(\activei(\xk)\right) \label{define_u_k}
\end{align}
Here, $\alphathree$ is a set of directions that hopefully head away from each of the active constraints at a point.

Throughout, we will use a couple different cones, which can be described here
\begin{align}
\mathcal C(\alpha, d, c) = \left\{x \in \Rn | \quad x = c + t d + s, s^Td= 0, t \ge 0, \|s\| \le \alpha t\right\} \\
\unshiftedcone = \mathcal C(\alpha_k, \uk, \xk) = \{x \in \Rn | \quad x = \xk + t \uk+ s, s^Tu^{\star} = 0, t \ge 0, \|s\| \le \alpha_k t\} \label{defineunshiftedcone} \\
\shiftedcone = \mathcal C(\alpha_k, e_1, 0) =  \{x = (t, s)^T \in \Rn, t \in \mathbb R_{\ge 0}, s \in \mathbb R^{n-1} |\quad \|s\| \le \alpha_k t \} \label{defineshiftedcone}
\end{align}

We will use the following mapping to go between these cones:
\begin{align}
\rotk = 2\frac{(e_1 + \uk)(e_1 +\uk)^T}{(e_1 +\uk)^T(e_1 +\uk)} - \boldsymbol I \label{define_r} \\
T_k(x) = \rotk\left(x - \xk\right) \label{define_affine_mapping}
\end{align}

Finally, the following is a useful function for defining ellipsoids:
\begin{align}
f_{e}(\alpha, \delta, r; x) = (x - \delta e_1)^T\begin{bmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \alpha^{-2} \boldsymbol I \\
\end{bmatrix}(x - \delta e_1) - r \label{define_ellipsoid_function}
\end{align}


\begin{lemma}
\label{alphas_are_positive}
Assume that \cref{interior_point} is satisfied and $x_0 \in \feasible$.
Then $1 \ge \alphathree(x_0) > 0$. 
\end{lemma}

\begin{proof}
Let $x_0 \in \feasible$.
If $\activei(x_0) = \emptyset$, then $\alpha_k = 1 > 0$.
Otherwise, let $i \in \activei(x_0)$, so that $c_i(x_0) = 0$.
% We know that for each $i \in \activei(x_0)$ both $c_i(x_0) = 0$ and $c_i(\bar x) < 0$.
% subtract the equations: $G_i^T \bar x < g_i$ and $G_i^T  x_0 = g_i$ to find
Because $c_i$ is convex, we know
\begin{align*}
c_i(\bar x) \ge c_i(x_0) + \nabla c_i(x_0)^T(\bar x - x_0)
\Longrightarrow \nabla c_i(x_0)^T(\bar x - x_0) \le c_i(\bar x) - c_i(x_0) = c_i(\bar x) < 0
\end{align*}
Using \cref{define_g}, we can write this as
% G_i^T \left(\bar x - x_0 \right) < 0 \Longrightarrow -G^T_i\frac {\bar x - x_0}{\|\bar x - x_0\|} > 0 
\begin{align*}
-G^T_i\frac {\bar x - x_0}{\|\bar x - x_0\|} > 0  \Longrightarrow \min_{i \in \activei(x_0)} -G_i^T\frac {\bar x - x_0}{\|\bar x - x_0\|} > 0.
\end{align*}
Using this along with definitions \cref{define_alpha_one}, \cref{define_alpha_two}, and \cref{define_alpha_three} we see
\begin{align*}
\alphathree(x_0) = \alphatwo\left(\activei(x_0)\right) = \max_{\|u\| = 1} \min_{i \in \activei(x_0)} -G_i^Tu
\ge \min_{i \in \activei(x_0)} - G_i^T\frac {\bar x - x_0}{\|\bar x - x_0\|} > 0.
\end{align*}

We know that $\alphathree(x_0) \le 1$ because it is the dot product of two vectors of length one:
if $\|u\| = 1$, then $\left|u^T G_i\right|^2 \le \|u\|\|G_i\| = 1$ by CauchySchwarz.

\end{proof}

\begin{lemma}
\label{alphas_are_bounded}
If \cref{interior_point} is satisfied, then there exists an  $\epsilon_{\alpha} > 0$ such that $\alpha_k \ge \epsilon_{\alpha} \; \forall \; k \in \naturals$.
\end{lemma}
\begin{proof}
Because there are only $m$ constraints, each $\activei(x)$ is one of the only $2^m$ subsets of  $\{1, 2, 3, \ldots, m\}$.
This means that $\alphaone$, $\alphatwo$, and $\alpha_k$ can only take on at most $1 + 2^m$ values.
By \cref{alphas_are_positive}, we know that each of these values must be positive.
Thus, we are free to choose $\epsilon_{\alpha}$ to be the smallest of these values.
\end{proof}

\begin{lemma}
\label{trivial_ellipsoid_exists}
If $\activei = \emptyset$ during iteration $k$, then there exists a suitable ellipsoid for iteration $k$.
\end{lemma}
% $\epsilon > 0$, $c \in \Rn$  and a positive definite, symmetric matrix $Q$, 
\begin{proof}
If $\activei = \emptyset$, then we are free to select $c = x_0, Q = I$, and $ \epsilon$ smaller than the distance to the nearest constraint:
$\epsilon \le  \min_{1 \le i \le m} b^{(k)}_i - \left(\ak_i\right)^Tx_0$.
Because $E_k$ is then a sphere with radius less than the distance to the nearest constraint, $E \subseteq P$.
Because the sphere $\hat E_k$ is centered at $x_0$, $x_0 \in \hat E_k$.
Also, $\sigma(Q) = 1$.
\end{proof}




\begin{lemma}
\label{unshiftedconeisfeasible}
The set $\unshiftedcone$ defined in  \ref{defineunshiftedcone} is feasible with respect to the active constraints of $P_k$ at $\xk$.
\end{lemma}

\begin{proof}
Note that the trust region boundary cannot be active at $\xk$ as $\dk > 0$.
Let $y = \xk + t\uk + s \in \unshiftedcone$ and $i \in \mathcal A(\xk)$ be arbitrary.
Then,
\begin{align*}
A_{i}^Ty - b_{i} = A_{i}^T(t\uk + s) = A_{i}^Ts + t A_{i}^T\uk \le \|s\| - \alpha t \le 0.
\end{align*}
\end{proof}




\begin{lemma}
\label{shifted_ellipsoid_in_cone}
Let $\shiftedcone, f_e, \alpha_k$ be defined as in \cref{defineshiftedcone}, \cref{define_ellipsoid_function}, \cref{define_alpha_k}.
Then the ellipsoid
\begin{align}
\left\{x \in \Rn | f_e(\alpha_k, \delta, \frac 1 2 \delta^2; x) \le 0 \right\} \subseteq \shiftedcone \quad \forall \delta > 0
\end{align}
\end{lemma}

\begin{proof}
Suppose that $x \in \left\{x \in \Rn | f_e(\alpha_k, \delta, \frac 1 2 \delta^2; x) \le 0 \right\}$, then
\begin{align*}
f_e(x) \le 0 \Longrightarrow 
(x - \delta e_1)^T\begin{bmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \alpha_k^{-2} \boldsymbol I \\
\end{bmatrix}(x - \delta e_1) \le \frac 1 2 \delta^2 
\Longrightarrow (t - \delta)^2 + \frac {1} {\alpha_k^2} \|s\|^2 \le \frac 1 2 \delta^2 \\
\Longrightarrow \|s\|^2 \le \alpha_k^2 \left[\frac 1 2 \delta^2 - (t - \delta)^2\right] 
= \alpha_k^2 \left[t^2 - 2(t - \frac 1 2 \delta)^2 \right] \le \alpha_k^2t^2
\Longrightarrow \|s\| \le \alpha_k t.
\end{align*}
Thus, $x \in\shiftedcone$.
\end{proof}


\begin{lemma}
\label{linear_mapping_works}
Let $\rotk$, $T_k$, $\unshiftedcone$, $\shiftedcone$ be defined as in
\cref{define_r}, \cref{define_affine_mapping}, \cref{defineunshiftedcone}, \cref{defineshiftedcone}.
Then $T_k(\unshiftedcone) = \shiftedcone$.
% and $T_k^{-1}(\shiftedcone) = \unshiftedcone$
\end{lemma}

\begin{proof}

Observe that
\begin{align*}
\begin{matrix}
\rotk e_1 = \uk,  & \rotk \uk = e_1, &  \rotk \rotk ^T = \rotk ^T\rotk = I, &  \text{and} \det(\rotk) = 1.
\end{matrix}
\end{align*}
Suppose that $x \in \unshiftedcone$.
Then there exists $t \ge 0$ and $s \in \Rn$ such that $x = \xk + t \uk+ s$ where $s^T \uk = 0$ and $\|s\| \le \alpha_k t$.
Then $T_k(x) = t\rotk\uk + \rotk s = te_1 + \rotk s$.
Observe that $(Rs)_1 = (\rotk s)^Te_1 = s^T\rotk^T(\rotk \uk) = s^T \uk = 0$.
Hence,
$T_k(x) = \begin{bmatrix}
t \\
\sigma
\end{bmatrix}$ where $\sigma \in \mathbb R ^ {n-1}$ satisfies $\|\sigma\| = \|s\| \le \alpha t$.
Thus, $T_k(x) \in \shiftedcone$.
Conversely, if $\begin{bmatrix}
t \\
\sigma
\end{bmatrix} \in \shiftedcone$, then let
$s = \rotk^T\begin{bmatrix}
0 \\
\sigma
\end{bmatrix}$
to see that
$x = T_k^{-1}\left(\begin{bmatrix}
t \\
\sigma
\end{bmatrix} \right)= \rotk^T\left(t e_1 + \begin{bmatrix}
0 \\
\sigma
\end{bmatrix}\right) = t \uk + s$ where 
$\|s\| = \|\sigma\| \le \alpha t$.
Hence $T_k^{-1}\left(\begin{bmatrix}
t \\
\sigma
\end{bmatrix}\right) \in \unshiftedcone$.
\end{proof}



\begin{lemma}
\label{ellipsoid_fits}
Let $\rotk$, $T_k$, $\unshiftedcone$, $\shiftedcone$, $P_k$ be defined as in
\cref{define_r}, \cref{define_affine_mapping}, \cref{defineunshiftedcone}, \cref{defineshiftedcone}, \cref{polyhedron_k}.

For each iteration $k$, there exists a $\deltaf > 0$ such that the ellipsoid
\begin{align}
\unshiftedellipsoid = \left\{x \in \Rn | f_e(\deltaf, \frac 1 2 \deltaf^2, \alpha_k, T_k(x) ) \le 0\right\} \label{definefeasibleellipsoid}
\end{align}
satisfies $\unshiftedellipsoid \subseteq P_k$.
\end{lemma}

\begin{proof}
Let $L$ be the shortest distance from $\xk$ to any point on a non-active constraint. 
Define $\alpha' = \sqrt{\left(1 + \alpha_k^2 \right) \left(1 + \frac 1 {\sqrt{2}}\right)}$, and let $\deltaf = \frac 1 {\alpha'} L$.
We see that if $x \in\unshiftedellipsoid$,
then by \cref{shifted_ellipsoid_in_cone} we have that $T_k(x) = \begin{bmatrix}t\\ \sigma\end{bmatrix} \in \shiftedcone$ for some $\sigma \in \mathbb R^{n-1}$, and
\begin{align*}
(x - \deltaf e_1)^T\begin{bmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \alpha_k^{-2} \boldsymbol I \\
\end{bmatrix}(x - \deltaf e_1) \le \frac 1 2 \deltaf^2 \\
\Longrightarrow (t - \deltaf)^2 + \frac {1} {\alpha_k^2} \|\sigma\|^2 \le \frac 1 2 \deltaf^2
\Longrightarrow (t - \deltaf)^2 \le \frac 1 2 \deltaf^2
\Longrightarrow t \le \left(1 + \frac 1 {\sqrt{2}}\right) \deltaf
\end{align*}
so that 
\begin{align*}
\|x\|^2 = t^2 + \|\sigma\|^2 \le \left(1 + \alpha_k^2 \right) t^2 \le \left(1 + \alpha_k^2 \right) \left(1 + \frac 1 {\sqrt{2}}\right) \deltaf^2 = {\alpha'}^2 \deltaf^2 \\
\Longrightarrow \|x\| \le \alpha' \deltaf \le L
\end{align*}
Thus, all points within $\unshiftedellipsoid$ are closer than the nearest point of a non-active constraint.
Combine this with \cref{unshiftedconeisfeasible} to see that $\unshiftedellipsoid \subseteq P_k$.
\end{proof}



\begin{lemma}
\label{ellipsoid_includes_origin}
For some iteration $k$, let $\rotk$, $T_k$, $\unshiftedcone$, $\shiftedcone$, $P_k$ be defined as in
\cref{define_r}, \cref{define_affine_mapping}, \cref{defineunshiftedcone}, \cref{defineshiftedcone}, \cref{polyhedron_k}.
Also, let $\deltaf > 0$ be defined as in \cref{ellipsoid_fits}.
\begin{align}
\scaledunshiftedellipsoid  = \left\{x \in \Rn | f_e(\deltaf, \deltaf^2, \alpha_k, T_k(x) ) \le 0\right\} \label{definescaledfeasibleellipsoid}
\end{align}
satisfies $\xk \in \unshiftedellipsoid$.
\end{lemma}

\begin{proof}
We have that
\begin{align*}
f_e(\deltaf, \deltaf^2, \alpha_k, T_k(\xk) ) =  
f_e(\deltaf, \deltaf^2, \alpha_k, 0 ) =  
(0 - \deltaf e_1)^T\begin{bmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \alpha_k^{-2} \boldsymbol I \\
\end{bmatrix}(0 - \deltaf e_1) = \deltaf^2 \le \deltaf^2.
\end{align*}
\end{proof}








% 
% 
% 
% 
% We will first define the ellipsoid and show some of its properties within the transformed space $C_2$ before mapping it to $C_1$.
% To this end, fix an arbitrary $\delta > 0$ and let 
% $f_{e}(x): \Rn \to \reals $ be defined by 
% \begin{align}
% f_{e}(x) = (x - \delta e_1)^T\begin{bmatrix}
% 1 & \boldsymbol0^T \\
% \boldsymbol 0 & \alpha^{-2} \boldsymbol I \\
% \end{bmatrix}(x - \delta e_1) - \frac 1 2 \delta^2
% \label{define_ellipsoid_function}
% \end{align} 
% and consider the ellipsoid $E_1 = \{x | f_{e}(x) \le 0\}$.
% We will show that $E_1 \subseteq C_2$.
% To this end, suppose $x = (t, s) \in E_1$.
% Firstly, note that
% \begin{align*}
% 2\big(t - \frac {\delta} 2\big)^2 \ge 0
% \Longrightarrow 2t\delta - \frac 1 2 \delta^2 \le 2t^2 
% \Longrightarrow \frac 1 2 \delta^2 - (t - \delta)^2 \le t^2. 
% \end{align*}
% \Longrightarrow \frac 1 2 \delta^2 -t^2  + 2t\delta - \delta^2 \le t^2 \\
% \Longrightarrow 0 \le t^2 - t\delta + \frac 1 4 \delta^2
%  \Longrightarrow 0 \le 2t^2 - 2t\delta + \frac 1 2 \delta^2\\

% We choose this mapping because if $x = x_0 + t u^{\star} + s \in C_1$,
% then $\|s\|\le \alpha t \Leftrightarrow \|Rs\| \le \alpha t$ and $0 = s^Tu^{\star} = s^T R^T R u^{\star} = (Rs)^T e_1$ imply that 
% $R(x - x_0 - \delta u^{\star}) = t Ru^{\star} + Rs = t e_1 + Rs \in C_2$.
% Thus, the affine mapping $T : \Rn \to \Rn$ defined by $T(x) = R(x - x_0 - \delta u^{\star})$ maps $C_1$ to $C_2$.
% Conversely, the same arguments show that $T^{-1}(x) = R^Tx + x_0 + \delta u^{\star}$ maps $C_2$ to $C_1$.

%  \in SO(n)
% u = [3957; 6294.9]
% u = u / norm(u)
% e = [1; 0.0]
% a = e + u
% r = 2 * a * a' / (a' * a) - eye(2)
% r * e
% r * u


% 
% Having proven that $E_1 \subseteq C_2$, it follows that $T^{-1}(E_1) \subseteq C_2$.
% However, $T^{-1}(E_1) = \{ x \in \Rn | (x - \delta u^{\star})^TQ(x-\delta u^{\star} \le \frac 1 2 \epsilon\}$ where

% 
% \begin{align*}
% E_2 = \bigg \{x \bigg | (x - x_0 - \delta u^{\star})^T\bigg(R^T\begin{bmatrix}
% 1 & \boldsymbol0^T \\
% \boldsymbol 0 & \alpha^{-2} \boldsymbol I \\
% \end{bmatrix}R\bigg)(x - x_0 - \delta u^{\star}) \le \frac 1 2 \delta^2 \bigg\}.
% \end{align*}
% We know that $x \in E_1 \Leftrightarrow T(x) = R(x - x_0 - \delta u^{\star}) \in E_2 \Longrightarrow T(x) \in C_2 \Longrightarrow x = T^{-1}\left(T(x)\right) \in C_1$.
% Thus, we know that the ellipsoid $E_2$ is contained within the active constraints, and can be scaled by $2$ to include $x_0$.

\begin{lemma}
\label{nontrivial_ellipsoid_exists}
For iteration $k$, if $\alpha_k > 0$, then there exists a suitable ellipsoid for iteration $k$.
\end{lemma}

\begin{proof}
Let 
$\rotk$,
be defined as in
\cref{define_r}
.
Also, let
$\deltaf$, $\scaledunshiftedellipsoid$
be defined as in 
\cref{definefeasibleellipsoid}
\cref{definescaledfeasibleellipsoid}
.

Let
\begin{align*}
\qk = \rotk^T\begin{bmatrix}
1 & \boldsymbol0^T \\
\boldsymbol 0 & \alpha_k^{-2} \boldsymbol I \\
\end{bmatrix}\rotk \\
c_k = \xk - \deltaf \uk \\
\epsilon = \delta^2 
\end{align*}

By \cref{ellipsoid_fits}, we know that $\unshiftedellipsoid \subseteq P_k$.
By \cref{ellipsoid_includes_origin}, we know that $\xk \in \scaledunshiftedellipsoid$ .
The condition number of $\sigma(\qk) = \frac{\max\{1, \alpha_k^{-2}\}}{\min\{1, \alpha_k^{-2}\}} = \alpha_k^{-2}$.
This is because $\det(\rotk) = 1$ means the condition number of $\qk$ is not affected $\rotk$.
\end{proof}



We use the following result shown \cite{billups.larson.ea:derivative-free}, Corollary 4.7.
We restate the theorem here, with the simplication that $f$ is deterministic function:

\begin{assumption}
\label{fully_quadratic_assumption}
Suppose that a set $S$ and a radius $\dmax$ are given.
Assume that $f$ is twice continuously differentiable with Lipshcitz continuous Hessian in an open domain containing the $\dmax$ neighborhood
$\cup_{x \in S} B(x; \dmax)$ of the set $S$.
\end{assumption}

\begin{lemma}
\label{change_radius} 
Let $Y$ be a poised set of $p$ points, and let $R = \max_{i}\|y^i - y^0\|$.
Let $f$ satisfy \cref{fully_quadratic_assumption} over some convex set $\Omega$, and let $m(x)$ denote the quadratic model of $f$ using \cref{reg}.
If $f$ is a Lipschitz continuous function with Lipschitz constant $L_g$, and $m_f(x)$ is a quadratic model of $f$.
Then, there exist constrants $\Lambda_1, \Lambda_2, \Lambda_3$ independent of $R$ such that for all $x \in B(y^0, R)$,
\begin{align*}
\|f(x) - m_f(x)\| \le 4\Lambda_1 R^3L \sqrt{p+1} \\
\|\nabla f(x) - \nabla m(x)\| \le 4\Lambda_2R^2  L \sqrt{p+1} \\
\|\nabla^2 f(x) - \nabla^2 m(x)\| \le 4\Lambda_3  RL \sqrt{p+1}
\end{align*}
\end{lemma}

We can now satisfy the accuracy condition.

\begin{theorem}
\label{accuracy_is_satisfied}
Suppose that \cref{interior_point}, \cref{fully_quadratic_assumption} hold. The accuracy condition \cref{accuracy} is satisfied for each iterate $k$.
Namely, there exists a $\kappa_{g}$ such that $\|\nabla m_f(\xk) - \nabla f(\xk)\| \le \kappa_g \dk$.
\end{theorem}

\begin{proof}
Fix an iterate $k$.
If there are no active constraints, then we can use \cref{trivial_ellipsoid_exists} to construct a suitable ellipsoid.
Otherwise, we can use \cref{alphas_are_bounded} to satisify the conditions of \cref{nontrivial_ellipsoid_exists}.
% $P = \{x \in \Rn |  \nabla c(\xk)^T x \le c(\xk), \xk - \dk \le x \le \xk + \dk \}$.
This provides two ellipsoids:
\begin{itemize}
\item $\unshiftedellipsoid = \{x \in \Rn | \left(x - c^{(k)} \right)^T \qk \left(x - c^{(k)}\right) \le \frac 1 2 {\delta_k}^2 \}$, $\unshiftedellipsoid \subset P_k$.
\item $\scaledunshiftedellipsoid = \{x \in \Rn | \left(x - c^{(k)}\right)^T \qk \left(x - c^{(k)}\right) \le {\delta_k}^2 \}$, $\xk \in \scaledunshiftedellipsoid$.
\end{itemize}
As in \cref{shifted_ellipsoid}, we can give $Q^{(k)} = LD^2L^T$ its eigen-decomposition, and define $\delta = \max_{x \in \unshiftedellipsoid} \|x - \mu^{(k)}\|$, 
so the transformation $T(x) = \delta D L^T(x - \mu^{(k)})$ maps $E^{(k)}$ to the $\delta$ ball.
As also described in \cref{shifted_ellipsoid}, we  create shifted functions
$\hat {m}_f(u) = m_f(T^{-1}(u))$ and
$\hat f (u) = f(T^{-1}(u))$.
After using \cref{model_improving_algorithm} to choose sample points, we know by \cref{quadratic_errors} that there exists a constants $\kappa_f, \kappa_g, \kappa_h$ such that for all $u \in B(0, \delta)$:
\begin{align*}
\left\| \hat {f}\left(u\right) -  \hat{m}_f\left(u\right) \right\|\le \kappa_f \delta^3 \\
\left\|\nabla \hat {f}\left(u\right) - \nabla \hat{m}_f\left(u\right) \right\|\le \kappa_g \delta^2 \\
\left\|\nabla^2 \hat {f}\left(u\right) - \nabla^2 \hat{m}_f\left(u\right) \right\|\le \kappa_h \delta
\end{align*}
We can then use \cref{change_radius} to conclude that there is another constant $\Lambda_2$ such that for all $u \in B(0, 2\delta)$:
\begin{align*}
\left\|\nabla \hat {f}\left(u\right) - \nabla \hat{m}_f\left(u\right) \right\|\le 4 \Lambda_2 \left(2\delta\right)^2 L \sqrt{p+1} = {\kappa'}_g\delta^2
\end{align*}
where $\kappa_{g}' = 16 \Lambda_2 L \sqrt{p+1}$.
Notice that Lemma 3.1 and Lemma 3.2 within \cite{doi:10.1080/10556788.2015.1026968} show that $\lim_{k\to\infty}\dk = 0$ without requiring the accuracy condition.
This is because Lemma 3.1 assumes that $\dk \le 1$ explicitly, while Lemma 3.2 uses the accuracy of the model's hessians.
This justifies the use of a $\dmax > 0$, such that $\dk \le \dmax\;\forall k \in \naturals$.
After using  \cref{alphas_are_bounded} to construct an $\epsilon_{\alpha} > 0$ and defining $\kappa''_{g} =  \frac{\kappa'_g}{\epsilon_{\alpha}}\dmax$, we see that
we can use  \cref{shifted_ellipsoid} to conclude that for all $x_0 \in \scaledunshiftedellipsoid$:
\begin{align*}
\left\|\nabla f\left(x_0 \right) - \nabla m_f\left(x_0\right)\right\| \le 
\kappa'_g  \dk^2 \sqrt{\kappa\left(\frac 2 {\delta_k} Q^{(k)}\right)}=  \kappa'_g \sqrt{\alpha_k^{-2}}\dk^2 \le \frac{\kappa'_g}{\alpha_k} \dk\dmax\le \kappa''_g\dk.
\end{align*}
In particular, $\xk \in \scaledunshiftedellipsoid$.
\end{proof}


Notice that although \cref{accuracy_is_satisfied} requires $\delta \le 1$, the authors of  show that $\dk \to 0$ within Lemma 3.1 and Lemma 3.2.
Within Lemma 3.1, $\dk \le 1 $ explicitly. 

\newpage


\subsection{Results}


\subsection{Sample Problem}
The first test was on a problem with simple constraints and a pathological objective.
We let $f(x) = \epsilon x + (1-\epsilon)(y - \alpha x \sin(\gamma x))^2$ for a fixed constant $\epsilon$, and set the constraints to be
$x_2 \le ax_1$, $x_2 \ge -ax_1$ for a fixed constant $a$.

We summarize the number of function evaluations and iterations taken here:
\begin{center}
\begin{tabular}{ c c c c c c c c }
Shape & Search & Num. Segments & Basis & Iterations & Evaluations \\
\hline
                spherical &   anywhere &       &     linear & 159  &   202  &  470 &  630 \\
                spherical &   anywhere &       &  quadratic & 164  &   277  &  467 &  805 \\
                spherical &       none &       &     linear &  77* &   122* &  255 &  387 \\
                spherical &       none &       &  quadratic &  74  &   149  &  250 &  561 \\
                spherical &    segment &     1 &     linear &  74  &   116  &  224 &  413 \\
                spherical &    segment &     1 &  quadratic &  74  &   164  &  224 &  525 \\
                spherical &    segment &     2 &     linear & 164  &   223  &  313 &  503 \\
                spherical &    segment &     2 &  quadratic & 152  &   259  &  313 &  657 \\
  circumscribed ellipsoid &       none &       &     linear &  41  &    50  &   41 &   55 \\
  circumscribed ellipsoid &       none &       &  quadratic &  41  &   104  &   41 &  105 \\
                ellipsoid &   anywhere &       &     linear &  65  &   109  &   67 &  110 \\
                ellipsoid &   anywhere &       &  quadratic &  66  &   170  &   67 &  185 \\
%                ellipsoid &  anywhere* &       &  quadratic &  61  &   157  &   60 &  155 \\
                ellipsoid &       none &       &     linear &  53  &    65  &   50 &   52 \\
                ellipsoid &       none &       &  quadratic &  53  &    88  &   50 &   75 \\
                ellipsoid &    segment &     1 &     linear &  55  &    70  &   58 &   75 \\
                ellipsoid &    segment &     1 &  quadratic &  55  &    97  &   58 &  104 \\
                ellipsoid &    segment &     2 &     linear &  67  &   144  &   68 &  121 \\
                ellipsoid &    segment &     2 &  quadratic &  67  &   196  &   64 &  159 \\
               polyhedral &       none &       &     linear &  37  &    43  &   38 &   46 \\
               polyhedral &       none &       &  quadratic &  37  &    82  &   38 &   89 \\
         scaled ellipsoid &   anywhere &       &     linear &  66  &   103  &   67 &  104 \\
         scaled ellipsoid &   anywhere &       &  quadratic &  68  &   156  &   67 &  169 \\
         scaled ellipsoid &    segment &     1 &     linear &  44  &    65  &   45 &   67 \\
         scaled ellipsoid &    segment &     1 &  quadratic &  44  &    94  &   45 &   93 \\
         scaled ellipsoid &    segment &     2 &     linear &  67  &   125  &   68 &  122 \\
         scaled ellipsoid &    segment &     2 &  quadratic &  67  &   189  &   63 &  146 \\
                  simplex & max volume &       &     linear &  41  &    44  &   41 &   45 \\
                  simplex & max volume &       &  quadratic &  41  &    94  &   41 &   84 \\

%                spherical &   anywhere &       &     linear &   159 &   202 \\
%                spherical &   anywhere &       &  quadratic &   164 &   277 \\
%                spherical &       none &       &     linear &    77* &   122* \\
%                spherical &       none &       &  quadratic &    74 &   149 \\
%                spherical &    segment &     1 &     linear &    74 &   116 \\
%                spherical &    segment &     1 &  quadratic &    74 &   164 \\
%                spherical &    segment &     2 &     linear &   164 &   223 \\
%                spherical &    segment &     2 &  quadratic &   152 &   259 \\
%  circumscribed ellipsoid &       none &       &     linear &    41 &    50 \\
%  circumscribed ellipsoid &       none &       &  quadratic &    41 &   104 \\
%                ellipsoid &   anywhere &       &     linear &    65 &   109 \\
%                ellipsoid &   anywhere &       &  quadratic &    66 &   170 \\
%                ellipsoid &  anywhere* &       &  quadratic &    61 &   157 \\
%                ellipsoid &       none &       &     linear &    53 &    65 \\
%                ellipsoid &       none &       &  quadratic &    53 &    88 \\
%                ellipsoid &    segment &     1 &     linear &    55 &    70 \\
%                ellipsoid &    segment &     1 &  quadratic &    55 &    97 \\
%                ellipsoid &    segment &     2 &     linear &    67 &   144 \\
%                ellipsoid &    segment &     2 &  quadratic &    67 &   196 \\
%               polyhedral &       none &       &     linear &    37 &    43 \\
%               polyhedral &       none &       &  quadratic &    37 &    82 \\
%         scaled ellipsoid &   anywhere &       &     linear &    66 &   103 \\
%         scaled ellipsoid &   anywhere &       &  quadratic &    68 &   156 \\
%         scaled ellipsoid &    segment &     1 &     linear &    44 &    65 \\
%         scaled ellipsoid &    segment &     1 &  quadratic &    44 &    94 \\
%         scaled ellipsoid &    segment &     2 &     linear &    67 &   125 \\
%         scaled ellipsoid &    segment &     2 &  quadratic &    67 &   189 \\
%                  simplex & max volume &       &     linear &    41 &    44 \\
%                  simplex & max volume &       &  quadratic &    41 &    94 \\

\end{tabular}
\end{center}

*The spherical trust region with no search for the center did not converge.

In general, the linear models converge more quickly than quadratic models.
We see that the method with fewest iterations and function evaluations is the linear polyhedral shape.
This is likely due to the fact that the polyhedral shape is allowed to search the entire outer trust region.
This also explains why the circumscribed ellipse and maximum volume simplex also perform well.
%We also notices that with a simple heuristic we were able to improve the ellipse slightly from 170 to 157.
Also, the scaled ellipsoid performs comparably to the unscaled version.

\subsection{Schittkowksi Test Problems for Nonlinear Optimization}


We tested these algorithms on several problems from the Hot-Schittkowski problem set \cite{Schittkowski:1987:MTE:27135}, \cite{Hock1980}.
We selected the problems that have linear constraints: 21, 24, 25, 35, 36, 44, 45, 76, 224, 231, 232, 250, 251.

% 37 was left out because it proved to be difficult.

We summarize the results here.
\begin{tiny}

\begin{center}
\begin{tabular}{ c c c c c c c c c c }
Algorithm & Prob. & n & Message & N. It. & N. Eval. & Ret. Min. & Min. & Solution & Minimizer \\
\hline
  circumscribed ellipse   &   21  &  2  & converged  &   24  &   71  &  -99.960   &  -99.960   & [2.00,0.00] & [2.00,0.00] \\
         ellipse          &   21  &  2  & converged  &   36  &   96  &  -99.960   &  -99.960   & [2.00,0.00] & [2.00,0.00] \\
    ellipse everywhere    &   21  &  2  & converged  &   24  &   82  &  -99.960   &  -99.960   & [2.00,0.00] & [2.00,0.00] \\
    ellipse segment 1     &   21  &  2  & converged  &   24  &   84  &  -99.960   &  -99.960   & [2.00,0.00] & [2.00,0.00] \\
    ellipse segment 2     &   21  &  2  & converged  &   24  &   85  &  -99.960   &  -99.960   & [2.00,0.00] & [2.00,0.00] \\
        polyhedral        &   21  &  2  & converged  &   26  &   75  &  -99.960   &  -99.960   & [2.00,-0.00] & [2.00,0.00] \\
  circumscribed ellipse   &  224  &  2  &   failed   &   16  &   56  &  -304.000  &  -304.000  & [4.00,4.00] & [4.00,4.00] \\
         ellipse          &  224  &  2  & converged  &   32  &   97  &  -304.000  &  -304.000  & [4.00,4.00] & [4.00,4.00] \\
    ellipse everywhere    &  224  &  2  & converged  &   24  &   94  &  -303.774  &  -304.000  & [3.73,4.27] & [4.00,4.00] \\
    ellipse segment 1     &  224  &  2  & converged  &   24  &   91  &  -303.774  &  -304.000  & [3.73,4.27] & [4.00,4.00] \\
    ellipse segment 2     &  224  &  2  & converged  &   23  &   89  &  -303.774  &  -304.000  & [3.73,4.27] & [4.00,4.00] \\
        polyhedral        &  224  &  2  & converged  &   17  &   64  &  -304.000  &  -304.000  & [4.00,4.00] & [4.00,4.00] \\
  circumscribed ellipse   &  231  &  2  & converged  &   14  &   44  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
         ellipse          &  231  &  2  & converged  &   99  &  193  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
    ellipse everywhere    &  231  &  2  & converged  &  181  &  336  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
    ellipse segment 1     &  231  &  2  & converged  &   78  &  162  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
    ellipse segment 2     &  231  &  2  & converged  &  173  &  321  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
        polyhedral        &  231  &  2  & converged  &   95  &  193  &   0.000    &   0.000    & [1.00,1.00] & [1.00,1.00] \\
  circumscribed ellipse   &  232  &  2  &   failed   &   15  &   35  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
         ellipse          &  232  &  2  & converged  &   34  &   91  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse everywhere    &  232  &  2  & converged  &   41  &  102  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse segment 1     &  232  &  2  & converged  &   34  &   91  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse segment 2     &  232  &  2  & converged  &   35  &   95  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
        polyhedral        &  232  &  2  & converged  &   15  &   47  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
  circumscribed ellipse   &   24  &  2  &   failed   &   15  &   35  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
         ellipse          &   24  &  2  & converged  &   34  &   90  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse everywhere    &   24  &  2  & converged  &   41  &  104  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse segment 1     &   24  &  2  & converged  &   34  &   91  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
    ellipse segment 2     &   24  &  2  & converged  &   35  &   95  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
        polyhedral        &   24  &  2  & converged  &   15  &   47  &   -1.000   &   -1.000   & [3.00,1.73] & [3.00,1.73] \\
  circumscribed ellipse   &  250  &  3  &   failed   &   24  &  103  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
         ellipse          &  250  &  3  & converged  &   53  &  207  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
    ellipse everywhere    &  250  &  3  &   failed   &   48  &  103  & -3298.196  & -3300.000  & [19.99,10.99,15.02] & [20.00,11.00,15.00] \\
    ellipse segment 1     &  250  &  3  &   failed   &   53  &  112  & -3299.243  & -3300.000  & [19.99,11.00,15.01] & [20.00,11.00,15.00] \\
    ellipse segment 2     &  250  &  3  &   failed   &   54  &  112  & -3299.082  & -3300.000  & [19.99,11.00,15.01] & [20.00,11.00,15.00] \\
    ellipse segment 3     &  250  &  3  &   failed   &   56  &  116  & -3299.504  & -3300.000  & [19.99,11.00,15.00] & [20.00,11.00,15.00] \\
        polyhedral        &  250  &  3  & converged  &   26  &  113  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
  circumscribed ellipse   &  251  &  3  &   failed   &   20  &   86  & -3456.000  & -3456.000  & [24.00,12.00,12.00] & [24.00,12.00,12.00] \\
         ellipse          &  251  &  3  &   failed   &   10  &   53  & -3454.018  & -3456.000  & [23.55,12.06,12.16] & [24.00,12.00,12.00] \\
    ellipse everywhere    &  251  &  3  &   failed   &   6   &   17  & -3209.710  & -3456.000  & [22.82,13.03,10.79] & [24.00,12.00,12.00] \\
    ellipse segment 1     &  251  &  3  &   failed   &   4   &   13  & -1698.807  & -3456.000  & [21.71,9.21,8.50] & [24.00,12.00,12.00] \\
    ellipse segment 2     &  251  &  3  &   failed   &   6   &   17  & -3210.341  & -3456.000  & [21.49,11.46,13.04] & [24.00,12.00,12.00] \\
    ellipse segment 3     &  251  &  3  &   failed   &   14  &   64  & -3449.803  & -3456.000  & [22.84,12.29,12.29] & [24.00,12.00,12.00] \\
        polyhedral        &  251  &  3  & converged  &   22  &  124  & -3456.000  & -3456.000  & [24.00,12.00,12.00] & [24.00,12.00,12.00] \\
  circumscribed ellipse   &   25  &  3  & converged  &  760  &  1472 &   0.000    &   0.000    & [52.92,24.90,1.52] & [50.00,25.00,1.50] \\
    ellipse everywhere    &   25  &  3  &   failed   &   1   &   1   &   32.835   &   0.000    & [100.00,12.50,3.00] & [50.00,25.00,1.50] \\
    ellipse segment 1     &   25  &  3  &   failed   &   1   &   1   &   32.835   &   0.000    & [100.00,12.50,3.00] & [50.00,25.00,1.50] \\
    ellipse segment 2     &   25  &  3  &   failed   &   1   &   1   &   32.835   &   0.000    & [100.00,12.50,3.00] & [50.00,25.00,1.50] \\
    ellipse segment 3     &   25  &  3  &   failed   &   1   &   1   &   32.835   &   0.000    & [100.00,12.50,3.00] & [50.00,25.00,1.50] \\
        polyhedral        &   25  &  3  & converged  &  1793 &  3396 &   0.000    &   0.000    & [50.94,24.97,1.51] & [50.00,25.00,1.50] \\
  circumscribed ellipse   &   35  &  3  &   failed   &  781  &  1028 &   0.111    &   0.111    & [1.33,0.78,0.44] & [1.33,0.78,0.44] \\
         ellipse          &   35  &  3  & converged  &   28  &  122  &   0.111    &   0.111    & [1.33,0.78,0.44] & [1.33,0.78,0.44] \\
    ellipse everywhere    &   35  &  3  &   failed   &   24  &   82  &   0.113    &   0.111    & [1.36,0.79,0.42] & [1.33,0.78,0.44] \\
    ellipse segment 1     &   35  &  3  &   failed   &   16  &   76  &   0.112    &   0.111    & [1.31,0.79,0.45] & [1.33,0.78,0.44] \\
    ellipse segment 2     &   35  &  3  &   failed   &   16  &   75  &   0.112    &   0.111    & [1.31,0.79,0.45] & [1.33,0.78,0.44] \\
    ellipse segment 3     &   35  &  3  &   failed   &   16  &   77  &   0.112    &   0.111    & [1.31,0.79,0.45] & [1.33,0.78,0.44] \\
        polyhedral        &   35  &  3  & converged  &   14  &  112  &   0.111    &   0.111    & [1.33,0.78,0.44] & [1.33,0.78,0.44] \\
  circumscribed ellipse   &   36  &  3  &   failed   &   19  &   81  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
         ellipse          &   36  &  3  & converged  &   53  &  202  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
    ellipse everywhere    &   36  &  3  &   failed   &   63  &  135  & -3299.808  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
    ellipse segment 1     &   36  &  3  &   failed   &   64  &  140  & -3299.951  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
    ellipse segment 2     &   36  &  3  &   failed   &   64  &  133  & -3299.918  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
    ellipse segment 3     &   36  &  3  &   failed   &   65  &  137  & -3299.870  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
        polyhedral        &   36  &  3  & converged  &   22  &  108  & -3300.000  & -3300.000  & [20.00,11.00,15.00] & [20.00,11.00,15.00] \\
  circumscribed ellipse   &   37  &  3  &   failed   &   27  &   98  & -3456.000  & -3456.000  & [24.00,12.00,12.00] & [24.00,12.00,12.00] \\
         ellipse          &   37  &  3  &   failed   &   15  &   65  & -3455.761  & -3456.000  & [23.94,12.01,12.02] & [24.00,12.00,12.00] \\
    ellipse everywhere    &   37  &  3  &   failed   &   36  &   88  & -3406.653  & -3456.000  & [27.34,10.93,11.40] & [24.00,12.00,12.00] \\
    ellipse segment 1     &   37  &  3  &   failed   &   30  &   82  & -3421.619  & -3456.000  & [21.29,12.62,12.73] & [24.00,12.00,12.00] \\
    ellipse segment 2     &   37  &  3  &   failed   &   36  &   85  & -3415.110  & -3456.000  & [21.05,12.70,12.78] & [24.00,12.00,12.00] \\
    ellipse segment 3     &   37  &  3  &   failed   &   28  &   75  & -3421.157  & -3456.000  & [21.31,12.55,12.79] & [24.00,12.00,12.00] \\
        polyhedral        &   37  &  3  & converged  &   28  &  139  & -3456.000  & -3456.000  & [24.00,12.00,12.00] & [24.00,12.00,12.00] \\
  circumscribed ellipse   &   44  &  4  &   failed   &   17  &  124  &  -13.000   &  -15.000   & [3.00,-0.00,4.00,0.00] & [0.00,3.00,0.00,4.00] \\
         ellipse          &   44  &  4  & converged  &   50  &  298  &  -15.000   &  -15.000   & [0.00,3.00,-0.00,4.00] & [0.00,3.00,0.00,4.00] \\
    ellipse everywhere    &   44  &  4  & converged  &  110  &  416  &  -15.000   &  -15.000   & [0.00,3.00,0.00,4.00] & [0.00,3.00,0.00,4.00] \\
    ellipse segment 1     &   44  &  4  & converged  &   50  &  262  &  -15.000   &  -15.000   & [-0.00,3.00,0.00,4.00] & [0.00,3.00,0.00,4.00] \\
    ellipse segment 2     &   44  &  4  & converged  &   71  &  304  &  -15.000   &  -15.000   & [-0.00,3.00,0.00,4.00] & [0.00,3.00,0.00,4.00] \\
    ellipse segment 3     &   44  &  4  &   failed   &   7   &   32  &  -10.672   &  -15.000   & [-0.00,2.55,0.36,3.41] & [0.00,3.00,0.00,4.00] \\
    ellipse segment 4     &   44  &  4  &   failed   &   1   &   1   &   -1.338   &  -15.000   & [1.44,0.98,1.80,1.80] & [0.00,3.00,0.00,4.00] \\
        polyhedral        &   44  &  4  & converged  &   15  &  134  &  -13.000   &  -15.000   & [3.00,-0.00,4.00,-0.00] & [0.00,3.00,0.00,4.00] \\
  circumscribed ellipse   &   45  &  5  &   failed   &   21  &  190  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
         ellipse          &   45  &  5  & converged  &   51  &  405  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse everywhere    &   45  &  5  & converged  &  414  &  1121 &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse segment 1     &   45  &  5  & converged  &   63  &  374  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse segment 2     &   45  &  5  & converged  &   82  &  404  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse segment 3     &   45  &  5  & converged  &  104  &  453  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse segment 4     &   45  &  5  & converged  &  130  &  497  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
    ellipse segment 5     &   45  &  5  & converged  &  158  &  478  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
        polyhedral        &   45  &  5  & converged  &   22  &  269  &   1.000    &   1.000    & [1.00,2.00,3.00,4.00,5.00] & [1.00,2.00,3.00,4.00,5.00] \\
  circumscribed ellipse   &   76  &  4  &   failed   &   15  &  111  &   -4.682   &   -4.682   & [0.27,2.09,-0.00,0.55] & [0.27,2.09,-0.00,0.55] \\
         ellipse          &   76  &  4  &   failed   &   17  &  137  &   -4.682   &   -4.682   & [0.27,2.09,0.00,0.54] & [0.27,2.09,-0.00,0.55] \\
    ellipse everywhere    &   76  &  4  &   failed   &   25  &  106  &   -4.604   &   -4.682   & [0.45,1.89,-0.00,0.77] & [0.27,2.09,-0.00,0.55] \\
    ellipse segment 1     &   76  &  4  &   failed   &   17  &  111  &   -4.682   &   -4.682   & [0.27,2.09,-0.00,0.54] & [0.27,2.09,-0.00,0.55] \\
    ellipse segment 2     &   76  &  4  &   failed   &   24  &  105  &   -4.680   &   -4.682   & [0.31,2.08,0.00,0.52] & [0.27,2.09,-0.00,0.55] \\
    ellipse segment 3     &   76  &  4  &   failed   &   25  &  106  &   -4.677   &   -4.682   & [0.34,2.07,0.00,0.51] & [0.27,2.09,-0.00,0.55] \\
    ellipse segment 4     &   76  &  4  &   failed   &   23  &  107  &   -4.674   &   -4.682   & [0.34,2.03,-0.00,0.60] & [0.27,2.09,-0.00,0.55] \\
        polyhedral        &   76  &  4  & converged  &   15  &  169  &   -4.682   &   -4.682   & [0.27,2.09,-0.00,0.55] & [0.27,2.09,-0.00,0.55]
\end{tabular}
\end{center}


\end{tiny}

In order to better evaluate the algorithms on the problems across in this test set, we use a performance profile developed in \cite{More:2009:BDO:1654367.1654371}.
Given a set of Solvers $\mathcal S$ that solved a set of problems $\mathcal P$ with the number of evaluations of solver $s$ on problem $p$ being $N(s, p)$, the performance ratio is defined to be $r(s, p) = \frac{N(s, p)}{\min_{s \in \mathcal S} N(s, p)}$.
If the algorithm does not complete, then the number of evaluations is set to $\infty$.
The performance profile of a solver $s$ and parameter $\alpha \in [0, \infty)$ is then the number of problems for which the performance ratio is less than or equal to $\alpha$: 

\begin{align}
\rho(s, \alpha) = \frac 1 {\|\mathcal P \|} \|p \in \mathcal P | r(s, p) \le \alpha\|.
\end{align}

The $y$ axis of a performance plot is the performance profile, and the $x$ axis is the parameter $\alpha$.
Note that algorithms with high performance profiles for small values of $alpha$ solved a large number of problems the most with the fewest evaluations, while algorithms that eventually reach high performance profiles with larger values of $\alpha$ solve a large set of problems.
The performance profile for the Hot-Schittkowski problem set is give in figure \cref{performance_profile}.


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/performance_profile_plot.png}
    \caption{Performance profile}
    \label{performance_profile}
\end{figure}



The line segment search with 5 segments does not solve many problems, this is because several of the problems have dimension less than $5$, so that it was not even ran on these.
Notice that the polyhedral search does very well.
We conjecture that this may not hold with modelled, nonlinear constraints.


\subsection{Summary}
We still experienced a problem with iterates coming too close to the boundary of the feasible region.
Another way of dealing with this is to shift the constraints closer to the current iterate.
Namely, we introduce a parameter $\upsilon$ to determine how far to scale the constraints.
Then, within the trust region subproblem, we add constraints of $Ax \le b\upsilon + (1-\upsilon) A \xk $.
Before doing this, the rows of $A$ are normalized.
This produces the buffered segment searches withing the results.


\subsection{Figure out where goes}

\color{red}
From here on, we will assume that the iterates $\xk$ are chosen according to \cref{constrained_dfo}.
This implies that each of the sample points used to construct $\mfk$ are output of \cref{model_improving_algorithm}.

Because \cref{lipschitz_gradient} and \cref{lipschitz_hessian} are satisfied, $f$ also satisfies \cref{introduction_3_1} and hence the assumptions for \cref{quadratic_errors}.
Notice that because $\kappa_f$, $\kappa_g$, $\kappa_h$ only depend on $p$, $L_h$, and $\Lambda$, these values do not depend on the iteration $k$:
using the same tolerance $\xi_{\text{min}}$ within \cref{model_improving_algorithm} implies a bound on $\Lambda$.
, and therefore $\mfk$ satisfies the requirements for \cref{quadratic_errors}.
is a fully quadratic model over $B_{\infty}(\xk, \dk)$.
\color{black}


 

\appendix

\subsection{Table of Notation}
\begin{longtable}{| p{.20\textwidth} | p{.80\textwidth} |}
$\xk$ & is the current iterate in iteration $k$\\
$\mfk$ & is the model of the objective $f$ during iteration $k$\\
$\mcik$ & is the model of the $i$-th constraint $c_i$ during iteration $k$\\
$\mck$ & is the model of the constraint $c$ during iteration $k$\\
$\dk$ & is the outer trust region radius in iteration $k$ \\
This & is some filler....... \\
$\domain$ & is the domain \\
$\real$ & is the real numbers \\
$f$ & is the objective function \\
$f_{\text{min}}$ & is a lower bound on the objective function \\
$\beta$ & is a bound on the hessian of the model functions \\
$c_i$ & are the constraints $\forall i \in \mathcal{I} \cup \mathcal{E} $ \\
$e_i$ & is the unit vector \\
$\phi_i$ & is a basis vector \\
$Y$ & is the set of sample points \\
$V$ & is a vander mode matrix \\
$y^i$ & is a sample point \\
$d$ & is the dimension of the space of model functions \\
$\lambda_i$ & are the weights of a linear combination \\
$\alpha_i$ & are the coefficients of a model function on its basis polynomials \\
$\phi_i$ & are basis polynomials \\
$p-1$ & is the size of the sample set \\
$l_i$ & is a lagrange polynomial \\
$\Lambda$ & is a constant bounding the poisedness of a sample set \\
$\kappa_{ef},\kappa_{eg},\kappa_{eh}$ & are constants used to bound the model's error \\
$\kappa_{f}$ & is a constant in the efficiency condition \\
$\kappa_{g}$ & is a constant in the accuracy condition \\
$\trialk$ & is the trial point in iteration $k$ \\
$\chik$ & is the criticality measure in iteration $k$ \\
$\outertrk$ & is the outer trust region in iteration $k$ \\
$\feasible$ & is the feasible region \\
$\feasible$ & is the feasible region during iteration $k$ \\
% $\innerfritr$ & is the feasible region intersect the inner trust region \\
$\outerfritr$ & is the feasible region intersect the outer trust region \\
$s$ & is the decision variable within the trust region subproblem \\
$B_k(c; \Delta)$ & is the ball of radius $\Delta$ centered at point $c$ in the $k$ norm\\
& $B_k(c;\Delta) = \{ x \in \mathbb{R}^n : \| x - c\|_k \le \Delta \}$ \\
$\Delta$ & is the trust region radius \\
$\rho$ & measures actual improvement over the predicted improvement \\
$\gamma_1, \gamma_2$ &  are bounds on $\rho$ \\
$\omega_{\text{dec}}, \omega_{\text{inc}}$ & are scalars used to manipulate the trust region radius \\
$\tau$ & is a tolerance \\
$\mathcal{F}^k$ & is the feasible region \\
$f^k$ & is the function value \\
$g^k$ & is the gradient of the model \\
$A$ & is the jacobian of the constraint model functions \\
$\xi_{\text{min}}$ & is a tolerance within the LU pivoting algorithm \\
$T$ & is an affine transformation that brings the trust region back to the origin \\
$Q$ & is the semi-definite matrix defining the affine transformation $T$ \\
$L$ & is a cholesky factorization of $Q$ \\
$L$ & is the Lipschitz constant of $f$ \\
$\mu^k$ & is the center of the ellipse \\
$\ellipsek$ is the ellipse during iteration $k$ \\
$\pi$ & is a scaling factor while finding the ellipse \\
$d$ & are the differences between the center of the ellipse and where the ellipse intersect the constraints? \\
$M$ & is an upper bound \\
$P$ & is a polyhedron \\
$\delta_{i,j}$ & is the kronecker delta function, $\delta_{i,i} = 1$, $\delta_{i,j} = 0$ if $i\ne j$ \\
$\tau_{\xi}$ & is a threshold for the criticallity measure \\
$\tau_{\Delta}$ & is a threshold for the trust region radius
\label{tab:TableOfNotation}
\end{longtable}

\newpage


\bibliography{thesis}
\bibliographystyle{ieeetr}

\end{document}


