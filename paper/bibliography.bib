@article{More:2009:BDO:1654367.1654371,
 author = {Mor{\'e}, Jorge J. and Wild, Stefan M.},
 title = {Benchmarking Derivative-Free Optimization Algorithms},
 journal = {SIAM J. on Optimization},
 issue_date = {March 2009},
 volume = {20},
 number = {1},
 month = mar,
 year = {2009},
 issn = {1052-6234},
 pages = {172--191},
 numpages = {20},
 url = {http://dx.doi.org/10.1137/080724083},
 doi = {10.1137/080724083},
 acmid = {1654371},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {benchmarking, computational budget, derivative-free optimization, deterministic simulations, performance evaluation},
} 

[download] 

@book{Schittkowski:1987:MTE:27135,
 editor = {Schittkowski, Klaus},
 title = {More Test Examples for Nonlinear Programming Codes},
 year = {1987},
 isbn = {0387171827},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@Article{Hock1980,
author="Hock, W.
and Schittkowski, K.",
title="Test examples for nonlinear programming codes",
journal="Journal of Optimization Theory and Applications",
year="1980",
month="Jan",
day="01",
volume="30",
number="1",
pages="127--129",
abstract="The increasing importance of nonlinear programming software requires an enlarged set of test examples. The purpose of this note is to point out how an interested mathematical programmer could obtain computer programs of more than 120 constrained nonlinear programming problems which have been used in the past to test and compare optimization codes.",
issn="1573-2878",
doi="10.1007/BF00934594",
url="https://doi.org/10.1007/BF00934594"
}





@article{Conejo:2013:GCT:2620806.2621814,
 author = {Conejo, P. D. and Karas, E. W. and Pedroso, L. G. and Ribeiro, A. A. and Sachine, M.},
 title = {Global Convergence of Trust-region Algorithms for Convex Constrained Minimization Without Derivatives},
 journal = {Appl. Math. Comput.},
 issue_date = {September, 2013},
 volume = {220},
 month = sep,
 year = {2013},
 issn = {0096-3003},
 pages = {324--330},
 numpages = {7},
 url = {http://dx.doi.org/10.1016/j.amc.2013.06.041},
 doi = {10.1016/j.amc.2013.06.041},
 acmid = {2621814},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Convex constrained optimization, Derivative-free optimization, Trust region},
} 

@book{Conn:2000:TM:357813,
 author = {Conn, Andrew R. and Gould, Nicholas I. M. and Toint, Philippe L.},
 title = {Trust-region Methods},
 year = {2000},
 isbn = {0-89871-460-5},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
} 


@article{doi:10.1137/151005683,
author = {Garmanjani, R. and Júdice, D. and Vicente, L.},
title = {Trust-Region Methods Without Using Derivatives: Worst Case Complexity and the NonSmooth Case},
journal = {SIAM Journal on Optimization},
volume = {26},
number = {4},
pages = {1987-2011},
year = {2016},
doi = {10.1137/151005683},

URL = { 
        https://doi.org/10.1137/151005683
    
},
eprint = { 
        https://doi.org/10.1137/151005683
    
}

}


@Article{Ciarlet1971,
author="Ciarlet, P. G. and Wagschal, C.",
title="Multipoint Taylor formulas and applications to the finite element method",
journal="Numerische Mathematik",
year="1971",
month="Feb",
day="01",
volume="17",
number="1",
pages="84--100",
issn="0945-3245",
doi="10.1007/BF01395869",
url="https://doi.org/10.1007/BF01395869"
}

@Article{Ciarlet1972,
author="Ciarlet, P. G. and Raviart, P. A.",
title="General lagrange and hermite interpolation in Rn with applications to finite element methods",
journal="Archive for Rational Mechanics and Analysis",
year="1972",
month="Jan",
day="01",
volume="46",
number="3",
pages="177--199",
issn="1432-0673",
doi="10.1007/BF00252458",
url="https://doi.org/10.1007/BF00252458"
}




@inproceedings{Audet2016APB,
  title={A progressive barrier derivative-free trust-region algorithm for constrained optimization},
  author={Charles Audet and S{\'e}bastien Le Digabel},
  year={2016}
}





@article{Troltzsch2016,
	abstract = {
      In this paper, we present a new model-based trust-region derivative-free optimization algorithm which can handle nonlinear equality constraints by applying a sequential quadratic programming (SQP) approach. The SQP methodology is one of the best known and most efficient frameworks to solve equality-constrained optimization problems in gradient-based optimization [see e.g. Lalee et al. (SIAM J Optim 8:682–706, 1998), Schittkowski (Optim Lett 5:283–296, 2011), Schittkowski and Yuan (Wiley encyclopedia of operations research and management science, Wiley, New York, 2010)]. Our derivative-free optimization (DFO) algorithm constructs local polynomial interpolation-based models of the objective and constraint functions and computes steps by solving QP sub-problems inside a region using the standard trust-region methodology. As it is crucial for such model-based methods to maintain a good geometry of the set of interpolation points, our algorithm exploits a self-correcting property of the interpolation set geometry. To deal with the trust-region constraint which is intrinsic to the approach of self-correcting geometry, the method of Byrd and Omojokun is applied. Moreover, we will show how the implementation of such a method can be enhanced to outperform well-known DFO packages on smooth equality-constrained optimization problems. Numerical experiments are carried out on a set of test problems from the CUTEst library and on a simulation-based engineering design problem.
   },
	affiliation = {German Aerospace Center (DLR)},
	author = {Tröltzsch, Anke},
	copyright = {Springer-Verlag Berlin Heidelberg},
	doi = {10.1007/s11590-014-0830-y},
	journal = {Optimization Letters},
	keywords = {Derivative-free optimization; Nonlinear optimization; Trust region; Equality constraints; SQP; Numerical experiments},
	language = {English},
	number = {2},
	pages = {383-399},
	title = {A sequential quadratic programming algorithm for equality-constrained optimization without derivatives},
	volume = {10},
	year = {2016},
}










@article{doi:10.1080/02331934.2016.1263629,
author = {P. S. Ferreira and E. W. Karas and M. Sachine and F. N. C. Sobral},
title = {Global convergence of a derivative-free inexact restoration filter algorithm for nonlinear programming},
journal = {Optimization},
volume = {66},
number = {2},
pages = {271-292},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/02331934.2016.1263629},

URL = { 
        https://doi.org/10.1080/02331934.2016.1263629
    
},
eprint = { 
        https://doi.org/10.1080/02331934.2016.1263629
    
}

}












@article{infeasiblestarting,
author = {Bajaj, Ishan and Iyer, Shachit and Hasan, M.M.Faruque},
year = {2017},
month = {12},
pages = {},
title = {A Trust Region-based Two Phase Algorithm for Constrained Black-box and Grey-box Optimization with Infeasible Initial Point},
booktitle = {Computers & Chemical Engineering}
}














@article{doi:10.1080/10556780802409296,
author = { Giovanni   Fasano  and  José   Luis   Morales  and  Jorge   Nocedal },
title = {On the geometry phase in model-based algorithms for derivative-free optimization},
journal = {Optimization Methods and Software},
volume = {24},
number = {1},
pages = {145-154},
year  = {2009},
publisher = {Taylor & Francis},
doi = {10.1080/10556780802409296},

URL = { 
        https://doi.org/10.1080/10556780802409296
    
},
eprint = { 
        https://doi.org/10.1080/10556780802409296
    
}

}









@article{doi:10.1080/10556788.2015.1026968,
author = {P.D. Conejo and E.W. Karas and L.G. Pedroso},
title = {A trust-region derivative-free algorithm for constrained optimization},
journal = {Optimization Methods and Software},
volume = {30},
number = {6},
pages = {1126-1145},
year  = {2015},
publisher = {Taylor & Francis},
doi = {10.1080/10556788.2015.1026968},

URL = { 
        https://doi.org/10.1080/10556788.2015.1026968
    
},
eprint = { 
        https://doi.org/10.1080/10556788.2015.1026968
    
}

}







@article{doi:10.1093/imanum/drx043,
author = {Gratton, Serge and Royer, Clément W and Vicente, Luís N and Zhang, Zaikun},
title = {Complexity and global rates of trust-region methods based on probabilistic models},
journal = {IMA Journal of Numerical Analysis},
volume = {38},
number = {3},
pages = {1579-1597},
year = {2018},
doi = {10.1093/imanum/drx043},
URL = {http://dx.doi.org/10.1093/imanum/drx043},
eprint = {/oup/backfile/content_public/journal/imajna/38/3/10.1093_imanum_drx043/3/drx043.pdf}
}





@Article{Beyhaghi2017,
author="Beyhaghi, Pooriya
and Bewley, Thomas",
title="Implementation of Cartesian grids to accelerate Delaunay-based derivative-free optimization",
journal="Journal of Global Optimization",
year="2017",
month="Dec",
day="01",
volume="69",
number="4",
pages="927--949",
abstract="This paper introduces a modification of our original Delaunay-based optimization algorithm (developed in JOGO DOI:10.1007/s10898-015-0384-2) that reduces the number of function evaluations on the boundary of feasibility as compared with the original algorithm. A weaknesses we have identified with the original algorithm is the sometimes faulty behavior of the generated uncertainty function near the boundary of feasibility, which leads to more function evaluations along the boundary of feasibility than might otherwise be necessary. To address this issue, a second search function is introduced which has improved behavior near the boundary of the search domain. Additionally, the datapoints are quantized onto a Cartesian grid, which is successively refined, over the search domain. These two modifications lead to a significant reduction of datapoints accumulating on the boundary of feasibility, and faster overall convergence.",
issn="1573-2916",
doi="10.1007/s10898-017-0548-3",
url="https://doi.org/10.1007/s10898-017-0548-3"
}



@inproceedings{Golovin:2017:GVS:3097983.3098043,
 author = {Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D.},
 title = {Google Vizier: A Service for Black-Box Optimization},
 booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '17},
 year = {2017},
 isbn = {978-1-4503-4887-4},
 location = {Halifax, NS, Canada},
 pages = {1487--1495},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3097983.3098043},
 doi = {10.1145/3097983.3098043},
 acmid = {3098043},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bayesian inference, black-box optimization, gaussian process, machine learning},
} 




@Article{Kamandi2017,
author="Kamandi, Ahmad
and Amini, Keyvan
and Ahookhosh, Masoud",
title="An improved adaptive trust-region algorithm",
journal="Optimization Letters",
year="2017",
month="Mar",
day="01",
volume="11",
number="3",
pages="555--569",
abstract="This paper gives a variant trust-region method, where its radius is automatically adjusted by using the model information gathered at the current and preceding iterations. The primary aim is to decrease the number of function evaluations and solving subproblems, which increases the efficiency of the trust-region method. The next aim is to update the new radius for large-scale problems without imposing too much computational cost to the scheme. Global convergence to first-order stationary points is proved under classical assumptions. Preliminary numerical experiments on a set of test problems from the CUTEst collection show that the presented method is promising for solving unconstrained optimization problems.",
issn="1862-4480",
doi="10.1007/s11590-016-1018-4",
url="https://doi.org/10.1007/s11590-016-1018-4"
}




  	
@article{1742-6596-874-1-012062,
  author={N Neveu and J Larson and J G Power and L Spentzouris},
  title={Photoinjector optimization using a derivative-free, model-based trust-region algorithm for the Argonne Wakefield Accelerator},
  journal={Journal of Physics: Conference Series},
  volume={874},
  number={1},
  pages={012062},
  url={http://stacks.iop.org/1742-6596/874/i=1/a=012062},
  year={2017},
  abstract={Model-based, derivative-free, trust-region algorithms are increasingly popular for optimizing computationally expensive numerical simulations. A strength of such methods is their efficient use of function evaluations. In this paper, we use one such algorithm to optimize the beam dynamics in two cases of interest at the Argonne Wakefield Accelerator (AWA) facility. First, we minimize the emittance of a 1 nC electron bunch produced by the AWA rf photocathode gun by adjusting three parameters: rf gun phase, solenoid strength, and laser radius. The algorithm converges to a set of parameters that yield an emittance of 1.08 μm. Second, we expand the number of optimization parameters to model the complete AWA rf photoinjector (the gun and six accelerating cavities) at 40 nC. The optimization algorithm is used in a Pareto study that compares the trade-off between emittance and bunch length for the AWA 70MeV photoinjector.}
}
	

@unpublished{KS2018,
author = "N.B.Kovachki and A.M.Stuart", 
title = "Ensemble Kalman Inversion: A Derivative-Free Technique For Machine Learning Tasks", 
note = "submitted", 
}



@INPROCEEDINGS{8247938, 
author={D. D. Linz and Z. B. Zabinsky and S. Kiatsupaibul and R. L. Smith}, 
booktitle={2017 Winter Simulation Conference (WSC)}, 
title={A computational comparison of simulation optimization methods using single observations within a shrinking ball on noisy black-box functions with mixed integer and continuous domains}, 
year={2017}, 
volume={}, 
number={}, 
pages={2045-2056}, 
abstract={We focus on simulation optimization algorithms that are designed to accommodate noisy black-box functions on mixed integer/continuous domains. There are several approaches used to account for noise which include aggregating multiple function replications from sample points and a newer method of aggregating single replications within a “shrinking ball.” We examine a range of algorithms, including, simulated annealing, interacting particle, covariance-matrix adaption evolutionary strategy, and particle swarm optimization to compare the effectiveness in generating optimal solutions using averaged function replications versus a shrinking ball approximation. We explore problems in mixed integer/continuous domains. Six test functions are examined with 10 and 20 dimensions, with integer restrictions enforced on 0%, 50%, and 100% of the dimensions, and with noise ranging from 10% to 20% of function output. This study demonstrates the relative effectiveness of using the shrinking ball approach, demonstrating that its use typically enhances solver performance for the tested optimization methods.}, 
keywords={approximation theory;covariance matrices;evolutionary computation;integer programming;particle swarm optimisation;simulated annealing;covariance-matrix adaption evolutionary strategy;particle swarm optimization;optimal solutions;averaged function replications;shrinking ball approximation;mixed integer/continuous domains;test functions;integer restrictions;function output;shrinking ball approach;tested optimization methods;computational comparison;simulation optimization methods;single observations;black-box functions;simulation optimization algorithms;multiple function replications;simulated annealing;particle interaction;Modeling;Simulated annealing;Benchmark testing;Estimation;Approximation algorithms;Particle swarm optimization}, 
doi={10.1109/WSC.2017.8247938}, 
ISSN={1558-4305}, 
month={Dec},}




@article{doi:10.1002/aic.16364,
author = {Eason, John P. and Biegler, Lorenz T.},
title = {Advanced trust region optimization strategies for glass box/black box models},
journal = {AIChE Journal},
volume = {64},
number = {11},
pages = {3934-3943},
keywords = {Simulation, process, optimization, adsorption/gas, mathematical modeling},
doi = {10.1002/aic.16364},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.16364},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/aic.16364},
abstract = {We present an improved trust region filter (TRF) method for optimization of combined glass box/black box systems. Glass box systems refer to models that are easily expressed in an algebraic modeling language, providing cheap and accurate derivative information. By contrast, black box systems may be computationally expensive and derivatives are unavailable. The TRF method, as first introduced in our previous work (Eason and Biegler, AIChE J. 2016; 62:3124–3136), is able to handle hybrid systems containing both glass and black box components, which can frequently arise in chemical engineering, for example, when a multiphase reactor model is included in a flow sheet optimization problem. We discuss several recent modifications in the algorithm such as the sampling region, which maintains the algorithm's global convergence properties without requiring the trust region to shrink to zero in the limit. To benchmark the development of this optimization method, a test set of problems is generated based on modified problems from the CUTEr and COPS sets. The modified algorithm demonstrates improved performance using the test problem set. Finally, the algorithm is implemented within the Pyomo environment and demonstrated on a rigorous process optimization case study for carbon capture. © 2018 American Institute of Chemical Engineers AIChE J, 64: 3934–3943, 2018}
}

@book{AuHa2017,
	Author		= {C. Audet and W. Hare},
	Title			= {{Derivative-Free and Blackbox Optimization}},
	Series		= {{Springer Series in Operations Research and Financial Engineering}},
	Year			= {2017},
	Publisher 	= {Springer International Publishing},
	Address   = {Berlin},
	Pages		= {302},
	DOI 		= {10.1007/978-3-319-68913-5}
}




@Article{Verderio2017,
author="Verd{\'e}rio, Adriano
and Karas, Elizabeth W.
and Pedroso, Lucas G.
and Scheinberg, Katya",
title="On the construction of quadratic models for derivative-free trust-region algorithms",
journal="EURO Journal on Computational Optimization",
year="2017",
month="Dec",
day="01",
volume="5",
number="4",
pages="501--527",
abstract="We consider derivative-free trust-region algorithms based on sampling approaches for convex constrained problems and discuss two conditions on the quadratic models for ensuring their global convergence. The first condition requires the poisedness of the sample sets, as usual in this context, while the other one is related to the error between the model and the objective function at the sample points. Although the second condition trivially holds if the model is constructed by polynomial interpolation, since in this case the model coincides with the objective function at the sample set, we show that it also holds for models constructed by support vector regression. These two conditions imply that the error between the gradient of the trust-region model and the objective function is of the order of {\$}{\$}{\backslash}delta {\_}k{\$}{\$}$\delta$k, where {\$}{\$}{\backslash}delta {\_}k{\$}{\$}$\delta$kcontrols the diameter of the sample set. This allows proving the global convergence of a trust-region algorithm that uses two radii, {\$}{\$}{\backslash}delta {\_}k{\$}{\$}$\delta$kand the trust-region radius. Preliminary numerical experiments are presented for minimizing functions with and without noise.",
issn="2192-4414",
doi="10.1007/s13675-017-0081-7",
url="https://doi.org/10.1007/s13675-017-0081-7"
}


@Article{Gao2017,
author="Gao, Tian
and Li, Jinglai",
title="A derivative-free trust-region algorithm for reliability-based optimization",
journal="Structural and Multidisciplinary Optimization",
year="2017",
month="Apr",
day="01",
volume="55",
number="4",
pages="1535--1539",
abstract="In this note, we present a derivative-free trust-region (TR) algorithm for reliability based optimization (RBO) problems. The proposed algorithm consists of solving a set of subproblems, in which simple surrogate models of the reliability constraints are constructed and used in solving the subproblems. Taking advantage of the special structure of the RBO problems, we employ a sample reweighting method to evaluate the failure probabilities, which constructs the surrogate for the reliability constraints by performing only a single full reliability evaluation in each iteration. With numerical experiments, we illustrate that the proposed algorithm is competitive against existing methods.",
issn="1615-1488",
doi="10.1007/s00158-016-1587-y",
url="https://doi.org/10.1007/s00158-016-1587-y"
}




@Article{Cheng2017,
author="Cheng, Zuofu
and Shaffer, Eric
and Yeh, Raine
and Zagaris, George
and Olson, Luke",
title="Efficient parallel optimization of volume meshes on heterogeneous computing systems",
journal="Engineering with Computers",
year="2017",
month="Oct",
day="01",
volume="33",
number="4",
pages="717--726",
abstract="We describe a parallel algorithmic framework for optimizing the shape of elements in a simplicial volume mesh. Using fine-grained parallelism and asymmetric multiprocessing on multi-core CPU and modern graphics processing unit hardware simultaneously, we achieve speedups of more than tenfold over current state-of-the-art serial methods. In addition, improved mesh quality is obtained by optimizing both the surface and the interior vertex positions in a single pass, using feature preservation to maintain fidelity to the original mesh geometry. The framework is flexible in terms of the core numerical optimization method employed, and we provide performance results for both gradient-based and derivative-free optimization methods.",
issn="1435-5663",
doi="10.1007/s00366-014-0393-7",
url="https://doi.org/10.1007/s00366-014-0393-7"
}



@Article{Martínez2013,
author="Mart{\'i}nez, J. M.
and Sobral, F. N. C.",
title="Constrained derivative-free optimization on thin domains",
journal="Journal of Global Optimization",
year="2013",
month="Jul",
day="01",
volume="56",
number="3",
pages="1217--1232",
abstract="Many derivative-free methods for constrained problems are not efficient for minimizing functions on ``thin'' domains. Other algorithms, like those based on Augmented Lagrangians, deal with thin constraints using penalty-like strategies. When the constraints are computationally inexpensive but highly nonlinear, these methods spend many potentially expensive objective function evaluations motivated by the difficulties in improving feasibility. An algorithm that handles this case efficiently is proposed in this paper. The main iteration is split into two steps: restoration and minimization. In the restoration step, the aim is to decrease infeasibility without evaluating the objective function. In the minimization step, the objective function f is minimized on a relaxed feasible set. A global minimization result will be proved and computational experiments showing the advantages of this approach will be presented.",
issn="1573-2916",
doi="10.1007/s10898-012-9944-x",
url="https://doi.org/10.1007/s10898-012-9944-x"
}



@article{AMAIOUA201813,
title = "Efficient solution of quadratically constrained quadratic subproblems within the mesh adaptive direct search algorithm",
journal = "European Journal of Operational Research",
volume = "268",
number = "1",
pages = "13 - 24",
year = "2018",
issn = "0377-2217",
doi = "https://doi.org/10.1016/j.ejor.2017.10.058",
url = "http://www.sciencedirect.com/science/article/pii/S0377221717309876",
author = "Nadir Amaioua and Charles Audet and Andrew R. Conn and Sébastien Le Digabel",
keywords = "Nonlinear programming, Derivative-free optimization, Quadratic programming, Trust-region subproblem, Mesh adaptive direct search",
abstract = "The mesh adaptive direct search algorithm (MADS) is an iterative method for constrained blackbox optimization problems. One of the optional MADS features is a versatile search step in which quadratic models are built leading to a series of quadratically constrained quadratic subproblems. This work explores different algorithms that exploit the structure of the quadratic models: the first one applies an l1-exact penalty function, the second uses an augmented Lagrangian and the third one combines the former two, resulting in a new algorithm. It is notable that this latter approach is uniquely suitable for quadratically constrained quadratic problems. These methods are implemented within the NOMAD software package and their impact are assessed through computational experiments on 65 analytical test problems and 4 simulation-based engineering applications."
}




@Article{Amaran2014,
author="Amaran, Satyajith
and Sahinidis, Nikolaos V.
and Sharda, Bikram
and Bury, Scott J.",
title="Simulation optimization: a review of algorithms and applications",
journal="4OR",
year="2014",
month="Dec",
day="01",
volume="12",
number="4",
pages="301--333",
abstract="Simulation optimization refers to the optimization of an objective function subject to constraints, both of which can be evaluated through a stochastic simulation. To address specific features of a particular simulation---discrete or continuous decisions, expensive or cheap simulations, single or multiple outputs, homogeneous or heterogeneous noise---various algorithms have been proposed in the literature. As one can imagine, there exist several competing algorithms for each of these classes of problems. This document emphasizes the difficulties in simulation optimization as compared to algebraic model-based mathematical programming makes reference to state-of-the-art algorithms in the field, examines and contrasts the different approaches used, reviews some of the diverse applications that have been tackled by these methods, and speculates on future directions in the field.",
issn="1614-2411",
doi="10.1007/s10288-014-0275-2",
url="https://doi.org/10.1007/s10288-014-0275-2"
}



@inproceedings{Costa2014RBFOptA,
  title={RBFOpt : an open-source library for black-box optimization with costly function evaluations},
  author={Alberto Costa and Giacomo Nannicini},
  year={2014}
}








@article{doi:10.1137/15M1031679,
author = {Maggiar, A. and Wächter, A. and Dolinskaya, I. and Staum, J.},
title = {A Derivative-Free Trust-Region Algorithm for the Optimization of Functions Smoothed via Gaussian Convolution Using Adaptive Multiple Importance Sampling},
journal = {SIAM Journal on Optimization},
volume = {28},
number = {2},
pages = {1478-1507},
year = {2018},
doi = {10.1137/15M1031679},

URL = { 
        https://doi.org/10.1137/15M1031679
    
},
eprint = { 
        https://doi.org/10.1137/15M1031679
    
}

}


@Article{Gao2018,
author="Gao, Jing
and Cao, Jian",
title="A class of derivative-free trust-region methods with interior backtracking technique for nonlinear optimization problems subject to linear inequality constraints",
journal="Journal of Inequalities and Applications",
year="2018",
month="May",
day="09",
volume="2018",
number="1",
pages="108",
abstract="This paper focuses on a class of nonlinear optimization subject to linear inequality constraints with unavailable-derivative objective functions. We propose a derivative-free trust-region methods with interior backtracking technique for this optimization. The proposed algorithm has four properties. Firstly, the derivative-free strategy is applied to reduce the algorithm's requirement for first- or second-order derivatives information. Secondly, an interior backtracking technique ensures not only to reduce the number of iterations for solving trust-region subproblem but also the global convergence to standard stationary points. Thirdly, the local convergence rate is analyzed under some reasonable assumptions. Finally, numerical experiments demonstrate that the new algorithm is effective.",
issn="1029-242X",
doi="10.1186/s13660-018-1698-7",
url="https://doi.org/10.1186/s13660-018-1698-7"
}



@article{PLOSKAS201816,
title = "Optimization of circuitry arrangements for heat exchangers using derivative-free optimization",
journal = "Chemical Engineering Research and Design",
volume = "131",
pages = "16 - 28",
year = "2018",
note = "Energy Systems Engineering",
issn = "0263-8762",
doi = "https://doi.org/10.1016/j.cherd.2017.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0263876217303027",
author = "Nikolaos Ploskas and Christopher Laughman and Arvind U. Raghunathan and Nikolaos V. Sahinidis",
keywords = "Heat exchanger design, Refrigerant circuitry, Optimization, Derivative-free algorithms"
}







@inbook{doi:10.1137/1.9781611974683.ch37,
author = {Ana Luísa Custódio and Katya Scheinberg and Luis Nunes Vicente},
title = {Chapter 37: Methodologies and Software for Derivative-Free Optimization},
booktitle = {Advances and Trends in Optimization with Engineering Applications},
chapter = {},
pages = {495-506},
doi = {10.1137/1.9781611974683.ch37},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611974683.ch37},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611974683.ch37}
}




@Article{Powell2015,
author="Powell, M. J. D.",
title="On fast trust region methods for quadratic models with linear constraints",
journal="Mathematical Programming Computation",
year="2015",
month="Sep",
day="01",
volume="7",
number="3",
pages="237--267",
abstract="Quadratic models {\$}{\$}Q{\_}k ( {\backslash}underline{\{}x{\}}), {\backslash}underline{\{}x{\}}{\backslash}in {\backslash}mathcal{\{}R{\}}^n{\$}{\$}Qk(x̲),x̲∈Rn, of the objective function {\$}{\$}F ( {\backslash}underline{\{}x{\}}), {\backslash}underline{\{}x{\}}{\backslash}in {\backslash}mathcal{\{}R{\}}^n{\$}{\$}F(x̲),x̲∈Rn, are used by many successful iterative algorithms for minimization, where k is the iteration number. Given the vector of variables {\$}{\$}{\backslash}underline{\{}x{\}}{\_}k {\backslash}in {\backslash}mathcal{\{}R{\}}^n{\$}{\$}x̲k∈Rn, a new vector {\$}{\$}{\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}}{\$}{\$}x̲k+1may be calculated that satisfies {\$}{\$}Q{\_}k ( {\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}} ) < Q{\_}k ( {\backslash}underline{\{}x{\}}{\_}k ){\$}{\$}Qk(x̲k+1)<Qk(x̲k), in the hope that it provides the reduction {\$}{\$}F ( {\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}} ) < F ( {\backslash}underline{\{}x{\}}{\_}k ){\$}{\$}F(x̲k+1)<F(x̲k). Trust region methods include a bound of the form {\$}{\$}{\backslash}Vert {\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}} - {\backslash}underline{\{}x{\}}{\_}k {\backslash}Vert {\backslash}le {\backslash}Delta {\_}k{\$}{\$}{\textbardbl}x̲k+1-x̲k{\textbardbl}≤$\Delta$k. Also we allow general linear constraints on the variables that have to hold at {\$}{\$}{\backslash}underline{\{}x{\}}{\_}k{\$}{\$}x̲kand at {\$}{\$}{\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}}{\$}{\$}x̲k+1. We consider the construction of {\$}{\$}{\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}}{\$}{\$}x̲k+1, using only of magnitude {\$}{\$}n^2{\$}{\$}n2operations on a typical iteration when n is large. The linear constraints are treated by active sets, which may be updated during an iteration, and which decrease the number of degrees of freedom in the variables temporarily, by restricting {\$}{\$}{\backslash}underline{\{}x{\}}{\$}{\$}x̲to an affine subset of {\$}{\$}{\backslash}mathcal{\{}R{\}}^n{\$}{\$}Rn. Conjugate gradient and Krylov subspace methods are addressed for adjusting the reduced variables, but the resultant steps are expressed in terms of the original variables. Termination conditions are given that are intended to combine suitable reductions in {\$}{\$}Q{\_}k ( {\backslash}cdot ){\$}{\$}Qk({\textperiodcentered})with a sufficiently small number of steps. The reason for our work is that {\$}{\$}{\backslash}underline{\{}x{\}}{\_}{\{}k+1{\}}{\$}{\$}x̲k+1is required in the LINCOA software of the author, which is designed for linearly constrained optimization without derivatives when there are hundreds of variables. Our studies go beyond the final version of LINCOA, however, which employs conjugate gradients with termination at the trust region boundary. In particular, we find that, if an active set is updated at a point that is not the trust region centre, then the Krylov method may terminate too early due to a degeneracy. An extension to the conjugate gradient method for searching round the trust region boundary receives attention too, but it was also rejected from LINCOA, because of poor numerical results. The given techniques of LINCOA seem to be adequate in practice.",
issn="1867-2957",
doi="10.1007/s12532-015-0084-4",
url="https://doi.org/10.1007/s12532-015-0084-4"
}







@Article{Kieslich2018,
author="Kieslich, Chris A.
and Boukouvala, Fani
and Floudas, Christodoulos A.",
title="Optimization of black-box problems using Smolyak grids and polynomial approximations",
journal="Journal of Global Optimization",
year="2018",
month="Aug",
day="01",
volume="71",
number="4",
pages="845--869",
abstract="A surrogate-based optimization method is presented, which aims to locate the global optimum of box-constrained problems using input--output data. The method starts with a global search of the n-dimensional space, using a Smolyak (Sparse) grid which is constructed using Chebyshev extrema in the one-dimensional space. The collected samples are used to fit polynomial interpolants, which are used as surrogates towards the search for the global optimum. The proposed algorithm adaptively refines the grid by collecting new points in promising regions, and iteratively refines the search space around the incumbent sample until the search domain reaches a minimum hyper-volume and convergence has been attained. The algorithm is tested on a large set of benchmark problems with up to thirty dimensions and its performance is compared to a recent algorithm for global optimization of grey-box problems using quadratic, kriging and radial basis functions. It is shown that the proposed algorithm has a consistently reliable performance for the vast majority of test problems, and this is attributed to the use of Chebyshev-based Sparse Grids and polynomial interpolants, which have not gained significant attention in surrogate-based optimization thus far.",
issn="1573-2916",
doi="10.1007/s10898-018-0643-0",
url="https://doi.org/10.1007/s10898-018-0643-0"
}





@article {DUMMY:Biegler,
author = {Eason, John P. and Biegler, Lorenz T.},
title = {A trust region filter method for glass box/black box optimization},
journal = {AIChE Journal},
volume = {62},
number = {9},
issn = {1547-5905},
url = {http://dx.doi.org/10.1002/aic.15325},
doi = {10.1002/aic.15325},
pages = {3124--3136},
keywords = {mathematical modeling, multiscale modeling, optimization, nonlinear programming, trust region methods},
year = {2016},
}
@TECHREPORT{DUMMY:Fletcher,
    author = {Roger Fletcher and Sven Leyffer and Roger Fletcher and Sven Leyffer},
    title = {A brief history of filter methods},
    institution = {},
    year = {2006}
}
@article{DUMMY:Brekelman,
title = "Constrained optimization involving expensive function evaluations: A sequential approach ",
journal = "European Journal of Operational Research ",
volume = "160",
number = "1",
pages = "121 - 138",
year = "2005",
note = "Applications of Mathematical Programming Models ",
issn = "0377-2217",
doi = "http://dx.doi.org/10.1016/j.ejor.2003.10.009",
url = "http://www.sciencedirect.com/science/article/pii/S0377221703007094",
author = "Ruud Brekelmans and Lonneke Driessen and Herbert Hamers and Dick den Hertog",
keywords = "Nonlinear programming",
keywords = "Derivative free optimization",
keywords = "Trust region",
keywords = "Filter ",
abstract = "This paper presents a new sequential method for constrained nonlinear optimization problems. The principal characteristics of these problems are very time consuming function evaluations and the absence of derivative information. Such problems are common in design optimization, where time consuming function evaluations are carried out by simulation tools (e.g., FEM, CFD). Classical optimization methods, based on derivatives, are not applicable because often derivative information is not available and is too expensive to approximate through finite differencing. The algorithm first creates an experimental design. In the design points the underlying functions are evaluated. Local linear approximations of the real model are obtained with help of weighted regression techniques. The approximating model is then optimized within a trust region to find the best feasible objective improving point. This trust region moves along the most promising direction, which is determined on the basis of the evaluated objective values and constraint violations combined in a filter criterion. If the geometry of the points that determine the local approximations becomes bad, i.e. the points are located in such a way that they result in a bad approximation of the actual model, then we evaluate a geometry improving instead of an objective improving point. In each iteration a new local linear approximation is built, and either a new point is evaluated (objective or geometry improving) or the trust region is decreased. Convergence of the algorithm is guided by the size of this trust region. The focus of the approach is on getting good solutions with a limited number of function evaluations. "
}

@inproceedings{DUMMY:CombineTrustAndLine,
 author         = {J. Nocedal and Y. Yuan},
 title          = {Combining trust region and line search techniques},
 abstract       = {We propose an algorithm for nonlinear optimization that
                   employs both trust region techniques and line searches.
                   Unlike traditional trust region methods, our algorithm does
                   not resolve the subproblem if the trial step results in an
                   increase in the objective function, but instead performs a
                   backtracking line search from the failed point.
                   Backtracking can be done along a straight line or along a
                   curved path. We show that the new algorithm preserves the
                   strong convergence properties of trust region methods.
                   Numerical results are also presented.},
 summary        = {An algorithm for nonlinear optimization that employs both
                   trust-region techniques and linesearches is proposed. This
                   algorithm does not resolve the subproblem if the trial step
                   results in an increase in the objective function, but
                   instead performs a backtracking linesearch from the failed
                   point. Backtracking can be done along a straight line or
                   along a curved path. It is shown that the algorithm
                   preserves the strong convergence properties of trust-region
                   methods. Numerical results are presented.}}
@article{DUMMY:linesearch_global,
  author    = {Andreas W{\"{a}}chter and
               Lorenz T. Biegler},
  title     = {Line Search Filter Methods for Nonlinear Programming: Motivation and
               Global Convergence},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {16},
  number    = {1},
  pages     = {1--31},
  year      = {2005},
  url       = {http://dx.doi.org/10.1137/S1052623403426556},
  doi       = {10.1137/S1052623403426556},
  timestamp = {Fri, 25 Jun 2010 01:00:00 +0200},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/journals/siamjo/WachterB05},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@article{DUMMY:linesearch_local,
  author    = {Andreas W{\"{a}}chter and
               Lorenz T. Biegler},
  title     = {Line Search Filter Methods for Nonlinear Programming: Local Convergence},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {16},
  number    = {1},
  pages     = {32--48},
  year      = {2005},
  url       = {http://dx.doi.org/10.1137/S1052623403426544},
  doi       = {10.1137/S1052623403426544},
  timestamp = {Fri, 25 Jun 2010 01:00:00 +0200},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/journals/siamjo/WachterB05a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{DUMMY:intro_book,
 author = {Conn, Andrew R. and Scheinberg, Katya and Vicente, Luis N.},
 title = {Introduction to Derivative-Free Optimization},
 year = {2009},
 isbn = {0898716683, 9780898716689},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
} 
@article{DUMMY:trust_funnel_dfo,
  author    = {R. Sampaio and L. Toint},
  title     = {A TRUST-FUNNEL METHOD FOR NONLINEAR OPTIMIZATION PROBLEMS WITH GENERAL NONLINEAR CONSTRAINTS AND ITS APPLICATION TO DERIVATIVE-FREE OPTIMIZATION, most information in this cite is wrong},
  journal   = {{NAXYS} Namur Center for Complex Systems},
  volume    = {61},
  number    = {5000},
  pages     = {1--31},
  year      = {2015},
  url       = {http://www.unamur.be/sciences/naxys},
  doi       = {10.1137/S1052623403426556},
  timestamp = {Mon, 26 Jan 2015 01:00:00 +0200},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/journals/siamjo/WachterB05},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@Article{DUMMY:original_filter,
author="Gould, N. I. M.
and Toint, Ph. L.",
title="Nonlinear programming without a penalty function or a filter",
journal="Mathematical Programming",
year="2010",
volume="122",
number="1",
pages="155--196",
abstract="A new method is introduced for solving equality constrained nonlinear optimization problems. This method does not use a penalty function, nor a filter, and yet can be proved to be globally convergent to first-order stationary points. It uses different trust-regions to cope with the nonlinearities of the objective function and the constraints, and allows inexact SQP steps that do not lie exactly in the nullspace of the local Jacobian. Preliminary numerical experiments on CUTEr problems indicate that the method performs well.",
issn="1436-4646",
doi="10.1007/s10107-008-0244-7",
url="http://dx.doi.org/10.1007/s10107-008-0244-7"
}


@article{DUMMY:sqp_filter,
title = "Sequential quadratic programming for large-scale nonlinear optimization ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "124",
number = "1–2",
pages = "123 - 137",
year = "2000",
note = "Numerical Analysis 2000. Vol. IV: Optimization and Nonlinear Equations ",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/S0377-0427(00)00429-5",
url = "http://www.sciencedirect.com/science/article/pii/S0377042700004295",
author = "Paul T. Boggs and Jon W. Tolle",
keywords = "Sequential quadratic programming",
keywords = "Nonlinear optimization",
keywords = "Newton methods",
keywords = "Interior-point methods",
keywords = "Local",
keywords = "Trust-region methods convergence",
keywords = "Global convergence ",
abstract = "The sequential quadratic programming (SQP) algorithm has been one of the most successful general methods for solving nonlinear constrained optimization problems. We provide an introduction to the general method and show its relationship to recent developments in interior-point approaches, emphasizing large-scale aspects. "
}



@Article{DUMMY:Colson2004,
author="Colson, Beno{\'i}t",
title="Trust-region algorithms for derivative-free optimization and nonlinear bilevel programming",
journal="Quarterly Journal of the Belgian, French and Italian Operations Research Societies",
year="2004",
volume="2",
number="1",
pages="85--88",
abstract="We briefly describe the contents of the author's PhD thesis (see Colson 2003) discussed on July 2003 at the University of Namur (Belgium) and supervised by Philippe L. Toint. The contributions presented in this thesis are the development of trust-region methods for solving two particular classes of mathematical programs, namely derivative-free optimization (DFO) problems and nonlinear bilevel programming problems. The thesis is written in English and is available via the author.",
issn="1619-4500",
doi="10.1007/s10288-003-0020-8",
url="http://dx.doi.org/10.1007/s10288-003-0020-8"
}



@article{DUMMY:SQPFilter,
title = "Global convergence of a trust-region SQP-filter algorithm for general nonlinear programming",
abstract = "A trust-region SQP-filter algorithm of the type introduced by Fletcher and Leyffer [Math. Program., 91 (2002), pp. 239-269] that decomposes the step into its normal and tangential components allows for an approximate solution of the quadratic subproblem and incorporates the safeguarding tests described in Fletcher, Leyffer, and Toint [On the Global Convergence of an SLP-Filter Algorithm, Technical Report 98/13, Department of Mathematics, University of Namur, Namur, Belgium, 1998; On the Global Convergence of a Filter-SQP Algorithm, Technical Report 00/15, Department of Mathematics, University of Namur, Namur, Belgium, 2000] is considered. It is proved that, under reasonable conditions and for every possible choice of the starting point, the sequence of iterates has at least one first-order critical accumulation point.",
keywords = "Convergence theory, Filter methods, Nonlinear optimization, Sequential quadratic programming",
author = "Roger Fletcher and Gould, {Nicholas I M} and Sven Leyffer and Toint, {Philippe L.} and Andreas Wächter",
year = "2003",
doi = "10.1137/S1052623499357258",
volume = "13",
pages = "635--659",
journal = "SIAM Journal on Optimization",
issn = "1052-6234",
publisher = "Society for Industrial and Applied Mathematics Publications",
number = "3",
}

@Article{DUMMY:Rios2013,
author="Rios, Luis Miguel
and Sahinidis, Nikolaos V.",
title="Derivative-free optimization: a review of algorithms and comparison of software implementations",
journal="Journal of Global Optimization",
year="2013",
volume="56",
number="3",
pages="1247--1293",
abstract="This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution.",
issn="1573-2916",
doi="10.1007/s10898-012-9951-y",
url="http://dx.doi.org/10.1007/s10898-012-9951-y"
}

@Inbook{DUMMY:PowellRadialBasis,
author="Powell, M. J. D.",
editor="M{\"u}ller, Manfred W.
and Buhmann, Martin D.
and Mache, Detlef H.
and Felten, Michael",
title="Recent research at Cambridge on radial basis functions",
bookTitle="New Developments in Approximation Theory: 2nd International Dortmund Meeting (IDoMAT) '98, Germany, February 23--27, 1998",
year="1999",
publisher="Birkh{\"a}user Basel",
address="Basel",
pages="215--232",
isbn="978-3-0348-8696-3",
doi="10.1007/978-3-0348-8696-3_14",
url="http://dx.doi.org/10.1007/978-3-0348-8696-3_14"
}



@report{DUMMY:leastsquares,
author = {Wild, S M},
number = {ANL/MCS-P5120-0414},
title = {Solving Derivative-Free Nonlinear Least Squares with {POUNDERS}},
month = {April},
year = {2014 (Revised June 2015)},
type = {Preprint},
institution = {Argonne National Laboratory}
}


@article{DUMMY:typesofconstraints,
	title = {A Taxonomy of Constraints in Simulation-Based Optimization},
	year = {2015},
	abstract = {<p>The types of constraints encountered in black-box and simulation-based optimization problems differ significantly from those treated in nonlinear programming. We introduce a character- ization of constraints to address this situation. We provide formal definitions for several constraint classes and present illustrative examples in the context of the resulting taxonomy. This taxonomy, denoted QRAK, is useful for modeling and problem formulation, as well as optimization software development and deployment. It can also be used as the basis for a dialog with practitioners in moving problems to increasingly solvable branches of optimization.<br />
	<br />
	\&nbsp;</p>
},
	author = {S. Le Digabel and S. M. Wild}
}






@article{DUMMY:FasanoLLR14,
  author    = {Giovanni Fasano and
               Giampaolo Liuzzi and
               Stefano Lucidi and
               Francesco Rinaldi},
  title     = {A Linesearch-Based Derivative-Free Approach for Nonsmooth Constrained
               Optimization},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {24},
  number    = {3},
  pages     = {959--992},
  year      = {2014},
  url       = {https://doi.org/10.1137/130940037},
  doi       = {10.1137/130940037},
  timestamp = {Thu, 08 Jun 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/siamjo/FasanoLLR14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DUMMY:filterpattern,
  author    = {M. A. Abramson and 
				C. Audet and 
				G. Couture and
				J. E. Dennis Jr.,},
  title     = {Filter pattern search algorithms for mixed variable constrained optimization problems},
  journal   = {Pacific Journal of Optimization},
  volume    = {17},
  pages     = {477--500},
  year      = {2007}
}








@article{DUMMY:activeset1,
author = { Serge   Gratton  and  Philippe   L.   Toint  and  Anke   Tröltzsch },
title = {An active-set trust-region method for derivative-free nonlinear bound-constrained optimization},
journal = {Optimization Methods and Software},
volume = {26},
number = {4-5},
pages = {873-894},
year = {2011},
doi = {10.1080/10556788.2010.549231},

URL = { 
        http://dx.doi.org/10.1080/10556788.2010.549231
    
},
eprint = { 
        http://dx.doi.org/10.1080/10556788.2010.549231
    
}

}


@article{DUMMY:LiuzziLS10,
  added-at = {2010-12-06T00:00:00.000+0100},
  author = {Liuzzi, Giampaolo and Lucidi, Stefano and Sciandrone, Marco},
  biburl = {http://www.bibsonomy.org/bibtex/2b8da39c824411b7b8da53228fa2a6894/dblp},
  ee = {http://dx.doi.org/10.1137/090750639},
  interhash = {9c9d7e996fdbd11a7bce2b364a5e32f5},
  intrahash = {b8da39c824411b7b8da53228fa2a6894},
  journal = {SIAM Journal on Optimization},
  keywords = {dblp},
  number = 5,
  pages = {2614-2635},
  timestamp = {2010-12-07T11:33:56.000+0100},
  title = {Sequential Penalty Derivative-Free Methods for Nonlinear Constrained Optimization.},
  url = {http://dblp.uni-trier.de/db/journals/siamjo/siamjo20.html#LiuzziLS10},
  volume = 20,
  year = 2010
}



@misc{DUMMY:augmented,
author = {Charles Audet and Sebastien Le Digabel and Mathilde Peyrega},
title = {A derivative-free trust-region augmented Lagrangian algorithm},
year = {2016},
URL = { http://www.optimization-online.org/DB_HTML/2016/07/5530.html }
}



@article{Khachiyan1993,
    author="Khachiyan, Leonid G.
and Todd, Michael J.",
    title="On the complexity of approximating the maximal inscribed ellipsoid for a polytope",
    journal="Mathematical Programming",
    year="1993",
    month="Aug",
    day="01",
    volume="61",
    number="1",
    pages="137--159",
    abstract="We give a new polynomial bound on the complexity of approximating the maximal inscribed ellipsoid for a polytope.",
    issn="1436-4646",
    doi="10.1007/BF01582144",
    url="https://doi.org/10.1007/BF01582144"
}




@article{DUMMY:review,
author="Rios, Luis Miguel
and Sahinidis, Nikolaos V.",
title="Derivative-free optimization: a review of algorithms and comparison of software implementations",
journal="Journal of Global Optimization",
year="2013",
volume="56",
number="3",
pages="1247--1293",
abstract="This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution.",
issn="1573-2916",
doi="10.1007/s10898-012-9951-y",
url="http://dx.doi.org/10.1007/s10898-012-9951-y"
}





@misc{DUMMY:review2,
author = {A.L. Custodio and K. Scheinberg and L.N. Vicente},
title = {Methodologies and Software for Derivative-free Optimization},
year = {2017},
URL = { https://www.mat.uc.pt/~lnv/papers/dfo-survey.pdf }
}

@Book{ConnGoulToin00,
  Title                    = {Trust-Region Methods},
  Author                   = {Andrew R. Conn and Nicholas I. M. Gould and {\relax Ph}ilippe L. Toint},
  Publisher                = {SIAM},
  Year                     = {2000},
  Address                  = {Philadelphia, PA, USA}
}

